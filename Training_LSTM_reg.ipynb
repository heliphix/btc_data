{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from commons import mean_absolute_percentage_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HH_FAAlRXx"
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"notebooks/datasets/reg_seven.csv\"\n",
    "data = pd.read_csv(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty30rsi</th>\n",
       "      <th>difficulty90var</th>\n",
       "      <th>fee_to_reward90rsiUSD</th>\n",
       "      <th>hashrate30var</th>\n",
       "      <th>median_transaction_fee7rocUSD</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>price30smaUSD</th>\n",
       "      <th>price3wmaUSD</th>\n",
       "      <th>price7wmaUSD</th>\n",
       "      <th>sentinusd90emaUSD</th>\n",
       "      <th>size90trx</th>\n",
       "      <th>top100cap</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.889</td>\n",
       "      <td>1.168546e+12</td>\n",
       "      <td>49.775</td>\n",
       "      <td>9.266842e+25</td>\n",
       "      <td>36.980</td>\n",
       "      <td>7220.0</td>\n",
       "      <td>56.481</td>\n",
       "      <td>91.616</td>\n",
       "      <td>88.156</td>\n",
       "      <td>68391477</td>\n",
       "      <td>0.334</td>\n",
       "      <td>19.962</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>94.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.889</td>\n",
       "      <td>1.243755e+12</td>\n",
       "      <td>50.838</td>\n",
       "      <td>9.644142e+25</td>\n",
       "      <td>50.270</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>58.991</td>\n",
       "      <td>100.288</td>\n",
       "      <td>93.861</td>\n",
       "      <td>73007549</td>\n",
       "      <td>0.331</td>\n",
       "      <td>20.024</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>107.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.889</td>\n",
       "      <td>1.315554e+12</td>\n",
       "      <td>51.407</td>\n",
       "      <td>1.004435e+26</td>\n",
       "      <td>51.448</td>\n",
       "      <td>8852.0</td>\n",
       "      <td>61.879</td>\n",
       "      <td>111.703</td>\n",
       "      <td>101.342</td>\n",
       "      <td>77645623</td>\n",
       "      <td>0.329</td>\n",
       "      <td>19.987</td>\n",
       "      <td>4478.0</td>\n",
       "      <td>120.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.889</td>\n",
       "      <td>1.383943e+12</td>\n",
       "      <td>52.170</td>\n",
       "      <td>9.733186e+25</td>\n",
       "      <td>44.093</td>\n",
       "      <td>8777.0</td>\n",
       "      <td>64.777</td>\n",
       "      <td>119.740</td>\n",
       "      <td>108.257</td>\n",
       "      <td>82154725</td>\n",
       "      <td>0.327</td>\n",
       "      <td>19.990</td>\n",
       "      <td>4249.0</td>\n",
       "      <td>123.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.186</td>\n",
       "      <td>1.468007e+12</td>\n",
       "      <td>50.982</td>\n",
       "      <td>9.145296e+25</td>\n",
       "      <td>48.589</td>\n",
       "      <td>9950.0</td>\n",
       "      <td>67.766</td>\n",
       "      <td>125.520</td>\n",
       "      <td>115.097</td>\n",
       "      <td>86170134</td>\n",
       "      <td>0.326</td>\n",
       "      <td>19.833</td>\n",
       "      <td>4348.0</td>\n",
       "      <td>128.664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difficulty30rsi  difficulty90var  fee_to_reward90rsiUSD  hashrate30var  \\\n",
       "0           97.889     1.168546e+12                 49.775   9.266842e+25   \n",
       "1           97.889     1.243755e+12                 50.838   9.644142e+25   \n",
       "2           97.889     1.315554e+12                 51.407   1.004435e+26   \n",
       "3           97.889     1.383943e+12                 52.170   9.733186e+25   \n",
       "4           98.186     1.468007e+12                 50.982   9.145296e+25   \n",
       "\n",
       "   median_transaction_fee7rocUSD  mining_profitability  price30smaUSD  \\\n",
       "0                         36.980                7220.0         56.481   \n",
       "1                         50.270                7990.0         58.991   \n",
       "2                         51.448                8852.0         61.879   \n",
       "3                         44.093                8777.0         64.777   \n",
       "4                         48.589                9950.0         67.766   \n",
       "\n",
       "   price3wmaUSD  price7wmaUSD  sentinusd90emaUSD  size90trx  top100cap  \\\n",
       "0        91.616        88.156           68391477      0.334     19.962   \n",
       "1       100.288        93.861           73007549      0.331     20.024   \n",
       "2       111.703       101.342           77645623      0.329     19.987   \n",
       "3       119.740       108.257           82154725      0.327     19.990   \n",
       "4       125.520       115.097           86170134      0.326     19.833   \n",
       "\n",
       "   transactionvalueUSD  priceUSD  \n",
       "0               2592.0    94.715  \n",
       "1               4400.0   107.749  \n",
       "2               4478.0   120.003  \n",
       "3               4249.0   123.562  \n",
       "4               4348.0   128.664  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2466, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSzHTpuzmScU"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=0.2, train_size=0.8, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1972, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(['robust',RobustScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(['mixmax',MinMaxScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=Pipeline(estimators,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDojXgA7mpWa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing robust, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing mixmax, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "X_train=scale.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wNcl2z_JKkM"
   },
   "outputs": [],
   "source": [
    "y_train=y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.reshape(y_train, (y_train.shape[0],1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.reshape(y_test,(y_test.shape[0],1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVCJxdebqmOr"
   },
   "source": [
    "# **Model Architecture + Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "adam=optimizers.adam(lr=lr_schedule(0),amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"logcosh\", optimizer=adam, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6"
   },
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('trained_models/LSTM_reg_seven_new.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIJPsArMr8cs",
    "outputId": "91137564-8bb8-496c-c827-829e240a789a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mudassir/btcpaper/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1972 samples, validate on 494 samples\n",
      "Epoch 1/5000\n",
      "1972/1972 [==============================] - 6s 3ms/step - loss: 2971.6613 - mae: 2972.3540 - val_loss: 2952.9614 - val_mae: 2953.6545\n",
      "Epoch 2/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 2509.6507 - mae: 2510.3433 - val_loss: 2384.3314 - val_mae: 2385.0247\n",
      "Epoch 3/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 1873.5358 - mae: 1874.2291 - val_loss: 1128.6280 - val_mae: 1129.3213\n",
      "Epoch 4/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 638.3509 - mae: 639.0435 - val_loss: 499.6657 - val_mae: 500.3587\n",
      "Epoch 5/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 442.3088 - mae: 442.9995 - val_loss: 424.0711 - val_mae: 424.7608\n",
      "Epoch 6/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 381.6811 - mae: 382.3708 - val_loss: 348.3630 - val_mae: 349.0516\n",
      "Epoch 7/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 327.6817 - mae: 328.3733 - val_loss: 294.6914 - val_mae: 295.3809\n",
      "Epoch 8/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 289.7958 - mae: 290.4861 - val_loss: 256.8039 - val_mae: 257.4932\n",
      "Epoch 9/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 257.7125 - mae: 258.4033 - val_loss: 232.9470 - val_mae: 233.6373\n",
      "Epoch 10/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 240.1813 - mae: 240.8718 - val_loss: 205.0763 - val_mae: 205.7666\n",
      "Epoch 11/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 218.0243 - mae: 218.7139 - val_loss: 193.8465 - val_mae: 194.5380\n",
      "Epoch 12/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 201.9796 - mae: 202.6695 - val_loss: 176.6607 - val_mae: 177.3486\n",
      "Epoch 13/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 194.1589 - mae: 194.8474 - val_loss: 163.0311 - val_mae: 163.7204\n",
      "Epoch 14/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 184.9593 - mae: 185.6484 - val_loss: 157.8174 - val_mae: 158.5067\n",
      "Epoch 15/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 170.9599 - mae: 171.6484 - val_loss: 160.7732 - val_mae: 161.4633\n",
      "Epoch 16/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 164.9866 - mae: 165.6742 - val_loss: 150.0030 - val_mae: 150.6918\n",
      "Epoch 17/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 161.0162 - mae: 161.7014 - val_loss: 145.6382 - val_mae: 146.3290\n",
      "Epoch 18/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 162.4758 - mae: 163.1626 - val_loss: 150.5256 - val_mae: 151.2158\n",
      "Epoch 19/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 152.5457 - mae: 153.2318 - val_loss: 131.8277 - val_mae: 132.5160\n",
      "Epoch 20/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 147.8682 - mae: 148.5533 - val_loss: 130.3817 - val_mae: 131.0657\n",
      "Epoch 21/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 146.9985 - mae: 147.6841 - val_loss: 136.0407 - val_mae: 136.7292\n",
      "Epoch 22/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 141.0168 - mae: 141.7003 - val_loss: 125.6847 - val_mae: 126.3697\n",
      "Epoch 23/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 140.2556 - mae: 140.9390 - val_loss: 128.8889 - val_mae: 129.5753\n",
      "Epoch 24/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 134.5488 - mae: 135.2339 - val_loss: 120.1001 - val_mae: 120.7850\n",
      "Epoch 25/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 134.6150 - mae: 135.2990 - val_loss: 122.6319 - val_mae: 123.3193\n",
      "Epoch 26/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 133.1268 - mae: 133.8099 - val_loss: 120.5252 - val_mae: 121.2133\n",
      "Epoch 27/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 127.1419 - mae: 127.8237 - val_loss: 121.3956 - val_mae: 122.0701\n",
      "Epoch 28/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 122.4205 - mae: 123.1034 - val_loss: 117.1282 - val_mae: 117.8114\n",
      "Epoch 29/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 120.9951 - mae: 121.6770 - val_loss: 117.6010 - val_mae: 118.2786\n",
      "Epoch 30/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 118.1150 - mae: 118.7975 - val_loss: 112.4032 - val_mae: 113.0841\n",
      "Epoch 31/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 116.3903 - mae: 117.0740 - val_loss: 113.9657 - val_mae: 114.6492\n",
      "Epoch 32/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 115.3284 - mae: 116.0113 - val_loss: 113.3848 - val_mae: 114.0750\n",
      "Epoch 33/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 117.9427 - mae: 118.6238 - val_loss: 112.4821 - val_mae: 113.1675\n",
      "Epoch 34/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 111.3627 - mae: 112.0448 - val_loss: 114.6002 - val_mae: 115.2908\n",
      "Epoch 35/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 111.4931 - mae: 112.1757 - val_loss: 104.8115 - val_mae: 105.4912\n",
      "Epoch 36/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 106.4203 - mae: 107.0994 - val_loss: 105.7466 - val_mae: 106.4243\n",
      "Epoch 37/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 103.6732 - mae: 104.3508 - val_loss: 106.9287 - val_mae: 107.6188\n",
      "Epoch 38/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 103.4141 - mae: 104.0927 - val_loss: 104.3498 - val_mae: 105.0338\n",
      "Epoch 39/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 101.0751 - mae: 101.7521 - val_loss: 99.2635 - val_mae: 99.9464\n",
      "Epoch 40/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 101.5071 - mae: 102.1863 - val_loss: 97.1845 - val_mae: 97.8634\n",
      "Epoch 41/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 98.1563 - mae: 98.8359 - val_loss: 102.5966 - val_mae: 103.2750\n",
      "Epoch 42/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 99.2738 - mae: 99.9517 - val_loss: 95.4252 - val_mae: 96.1037\n",
      "Epoch 43/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 98.5834 - mae: 99.2621 - val_loss: 94.2275 - val_mae: 94.9035\n",
      "Epoch 44/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 96.4021 - mae: 97.0791 - val_loss: 101.5567 - val_mae: 102.2372\n",
      "Epoch 45/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 93.9935 - mae: 94.6738 - val_loss: 94.4873 - val_mae: 95.1705\n",
      "Epoch 46/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 96.8056 - mae: 97.4900 - val_loss: 93.1217 - val_mae: 93.8020\n",
      "Epoch 47/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 93.9375 - mae: 94.6197 - val_loss: 90.8676 - val_mae: 91.5450\n",
      "Epoch 48/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 91.5765 - mae: 92.2553 - val_loss: 89.7156 - val_mae: 90.4002\n",
      "Epoch 49/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 90.5143 - mae: 91.1938 - val_loss: 108.1665 - val_mae: 108.8458\n",
      "Epoch 50/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 91.6750 - mae: 92.3560 - val_loss: 85.5535 - val_mae: 86.2362\n",
      "Epoch 51/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 89.3774 - mae: 90.0567 - val_loss: 93.1347 - val_mae: 93.8230\n",
      "Epoch 52/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 88.6295 - mae: 89.3116 - val_loss: 88.9447 - val_mae: 89.6296\n",
      "Epoch 53/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 87.6579 - mae: 88.3366 - val_loss: 90.0754 - val_mae: 90.7475\n",
      "Epoch 54/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 84.4489 - mae: 85.1249 - val_loss: 84.2927 - val_mae: 84.9688\n",
      "Epoch 55/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 83.7824 - mae: 84.4600 - val_loss: 88.4980 - val_mae: 89.1714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 85.5631 - mae: 86.2421 - val_loss: 86.5778 - val_mae: 87.2610\n",
      "Epoch 57/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 82.5259 - mae: 83.2056 - val_loss: 84.3335 - val_mae: 85.0097\n",
      "Epoch 58/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 85.1028 - mae: 85.7822 - val_loss: 80.1287 - val_mae: 80.8017\n",
      "Epoch 59/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 83.3269 - mae: 84.0016 - val_loss: 92.9185 - val_mae: 93.6047\n",
      "Epoch 60/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 85.1113 - mae: 85.7911 - val_loss: 83.6543 - val_mae: 84.3341\n",
      "Epoch 61/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 82.2403 - mae: 82.9165 - val_loss: 80.4554 - val_mae: 81.1303\n",
      "Epoch 62/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 81.5240 - mae: 82.2023 - val_loss: 79.3284 - val_mae: 80.0066\n",
      "Epoch 63/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 80.0931 - mae: 80.7692 - val_loss: 81.8460 - val_mae: 82.5311\n",
      "Epoch 64/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 80.1522 - mae: 80.8318 - val_loss: 77.3318 - val_mae: 78.0114\n",
      "Epoch 65/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 79.8897 - mae: 80.5660 - val_loss: 79.8456 - val_mae: 80.5316\n",
      "Epoch 66/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 81.4272 - mae: 82.1043 - val_loss: 76.5512 - val_mae: 77.2340\n",
      "Epoch 67/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 78.4622 - mae: 79.1365 - val_loss: 76.6492 - val_mae: 77.3181\n",
      "Epoch 68/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 78.4763 - mae: 79.1509 - val_loss: 75.3356 - val_mae: 76.0172\n",
      "Epoch 69/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 77.6581 - mae: 78.3325 - val_loss: 79.8224 - val_mae: 80.4939\n",
      "Epoch 70/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 76.3584 - mae: 77.0338 - val_loss: 73.9964 - val_mae: 74.6711\n",
      "Epoch 71/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 75.8738 - mae: 76.5508 - val_loss: 75.8274 - val_mae: 76.4998\n",
      "Epoch 72/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 75.9800 - mae: 76.6572 - val_loss: 76.2218 - val_mae: 76.9027\n",
      "Epoch 73/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 75.5962 - mae: 76.2679 - val_loss: 72.5701 - val_mae: 73.2461\n",
      "Epoch 74/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 75.3002 - mae: 75.9798 - val_loss: 72.6399 - val_mae: 73.3145\n",
      "Epoch 75/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 78.7723 - mae: 79.4520 - val_loss: 84.6854 - val_mae: 85.3713\n",
      "Epoch 76/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 74.0748 - mae: 74.7491 - val_loss: 75.0563 - val_mae: 75.7323\n",
      "Epoch 77/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 75.1910 - mae: 75.8713 - val_loss: 69.6404 - val_mae: 70.3229\n",
      "Epoch 78/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 73.2898 - mae: 73.9677 - val_loss: 71.1330 - val_mae: 71.8064\n",
      "Epoch 79/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 73.1152 - mae: 73.7910 - val_loss: 72.8157 - val_mae: 73.4959\n",
      "Epoch 80/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 71.9089 - mae: 72.5787 - val_loss: 78.6234 - val_mae: 79.2965\n",
      "Epoch 81/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 72.9076 - mae: 73.5836 - val_loss: 68.9936 - val_mae: 69.6670\n",
      "Epoch 82/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 73.5124 - mae: 74.1877 - val_loss: 73.2883 - val_mae: 73.9639\n",
      "Epoch 83/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 74.3937 - mae: 75.0736 - val_loss: 76.4356 - val_mae: 77.1184\n",
      "Epoch 84/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 73.6034 - mae: 74.2826 - val_loss: 77.3635 - val_mae: 78.0422\n",
      "Epoch 85/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 71.7624 - mae: 72.4367 - val_loss: 67.4288 - val_mae: 68.0965\n",
      "Epoch 86/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 72.2203 - mae: 72.8947 - val_loss: 71.3668 - val_mae: 72.0478\n",
      "Epoch 87/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 71.8788 - mae: 72.5576 - val_loss: 68.6861 - val_mae: 69.3664\n",
      "Epoch 88/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 72.1075 - mae: 72.7859 - val_loss: 71.3712 - val_mae: 72.0536\n",
      "Epoch 89/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 71.5259 - mae: 72.1993 - val_loss: 69.1287 - val_mae: 69.8120\n",
      "Epoch 90/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 71.0639 - mae: 71.7413 - val_loss: 66.4303 - val_mae: 67.1027\n",
      "Epoch 91/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.7396 - mae: 70.4146 - val_loss: 65.4226 - val_mae: 66.0913\n",
      "Epoch 92/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.4555 - mae: 70.1303 - val_loss: 67.2931 - val_mae: 67.9667\n",
      "Epoch 93/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 70.1157 - mae: 70.7895 - val_loss: 69.0719 - val_mae: 69.7474\n",
      "Epoch 94/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 71.5614 - mae: 72.2413 - val_loss: 65.4783 - val_mae: 66.1551\n",
      "Epoch 95/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 72.7209 - mae: 73.4022 - val_loss: 72.5817 - val_mae: 73.2634\n",
      "Epoch 96/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 74.6841 - mae: 75.3647 - val_loss: 67.4253 - val_mae: 68.0920\n",
      "Epoch 97/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.9087 - mae: 70.5835 - val_loss: 65.2458 - val_mae: 65.9141\n",
      "Epoch 98/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.0890 - mae: 68.7651 - val_loss: 70.5714 - val_mae: 71.2505\n",
      "Epoch 99/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.9159 - mae: 69.5898 - val_loss: 62.4065 - val_mae: 63.0823\n",
      "Epoch 100/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.7051 - mae: 69.3823 - val_loss: 66.1004 - val_mae: 66.7858\n",
      "Epoch 101/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 73.1563 - mae: 73.8352 - val_loss: 65.6492 - val_mae: 66.3224\n",
      "Epoch 102/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.5581 - mae: 69.2317 - val_loss: 65.9247 - val_mae: 66.6110\n",
      "Epoch 103/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.7150 - mae: 69.3916 - val_loss: 72.1149 - val_mae: 72.7850\n",
      "Epoch 104/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.5553 - mae: 70.2298 - val_loss: 62.4342 - val_mae: 63.1107\n",
      "Epoch 105/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 70.3747 - mae: 71.0549 - val_loss: 73.0381 - val_mae: 73.7281\n",
      "Epoch 106/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.7282 - mae: 70.4031 - val_loss: 65.5037 - val_mae: 66.1828\n",
      "Epoch 107/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.7754 - mae: 67.4487 - val_loss: 64.6202 - val_mae: 65.2919\n",
      "Epoch 108/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 70.3516 - mae: 71.0295 - val_loss: 70.6814 - val_mae: 71.3676\n",
      "Epoch 109/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 69.3100 - mae: 69.9901 - val_loss: 64.4658 - val_mae: 65.1413\n",
      "Epoch 110/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.3304 - mae: 70.0060 - val_loss: 60.6139 - val_mae: 61.2837\n",
      "Epoch 111/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 66.5560 - mae: 67.2315 - val_loss: 75.1713 - val_mae: 75.8564\n",
      "Epoch 112/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 67.7996 - mae: 68.4776 - val_loss: 63.0221 - val_mae: 63.7018\n",
      "Epoch 113/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 67.8529 - mae: 68.5327 - val_loss: 62.8284 - val_mae: 63.5033\n",
      "Epoch 114/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972/1972 [==============================] - 5s 2ms/step - loss: 67.6710 - mae: 68.3444 - val_loss: 66.3836 - val_mae: 67.0694\n",
      "Epoch 115/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.6277 - mae: 67.3004 - val_loss: 61.5330 - val_mae: 62.2052\n",
      "Epoch 116/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 72.0082 - mae: 72.6908 - val_loss: 71.5091 - val_mae: 72.1973\n",
      "Epoch 117/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 67.8308 - mae: 68.5030 - val_loss: 61.6767 - val_mae: 62.3550\n",
      "Epoch 118/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.5342 - mae: 67.2111 - val_loss: 69.0474 - val_mae: 69.7250\n",
      "Epoch 119/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 68.4048 - mae: 69.0798 - val_loss: 68.7217 - val_mae: 69.4100\n",
      "Epoch 120/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.7777 - mae: 67.4543 - val_loss: 60.3682 - val_mae: 61.0383\n",
      "Epoch 121/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.0497 - mae: 68.7264 - val_loss: 67.2441 - val_mae: 67.9326\n",
      "Epoch 122/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 71.6940 - mae: 72.3781 - val_loss: 69.6912 - val_mae: 70.3701\n",
      "Epoch 123/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.0293 - mae: 66.7017 - val_loss: 64.0057 - val_mae: 64.6902\n",
      "Epoch 124/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.2456 - mae: 66.9195 - val_loss: 59.9343 - val_mae: 60.6101\n",
      "Epoch 125/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.8344 - mae: 65.5060 - val_loss: 59.3454 - val_mae: 60.0222\n",
      "Epoch 126/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.7779 - mae: 65.4506 - val_loss: 68.6252 - val_mae: 69.3130\n",
      "Epoch 127/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.6328 - mae: 69.3143 - val_loss: 63.2447 - val_mae: 63.9289\n",
      "Epoch 128/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 67.1297 - mae: 67.8028 - val_loss: 66.2235 - val_mae: 66.9032\n",
      "Epoch 129/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.1437 - mae: 66.8178 - val_loss: 64.6570 - val_mae: 65.3386\n",
      "Epoch 130/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 67.0659 - mae: 67.7460 - val_loss: 74.0618 - val_mae: 74.7476\n",
      "Epoch 131/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.2235 - mae: 69.9063 - val_loss: 58.0975 - val_mae: 58.7730\n",
      "Epoch 132/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 67.4275 - mae: 68.1031 - val_loss: 66.4694 - val_mae: 67.1486\n",
      "Epoch 133/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 68.0313 - mae: 68.7118 - val_loss: 65.5860 - val_mae: 66.2723\n",
      "Epoch 134/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.6658 - mae: 67.3458 - val_loss: 62.1636 - val_mae: 62.8333\n",
      "Epoch 135/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 66.6010 - mae: 67.2767 - val_loss: 61.5514 - val_mae: 62.2389\n",
      "Epoch 136/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.7245 - mae: 65.3972 - val_loss: 59.4651 - val_mae: 60.1347\n",
      "Epoch 137/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 65.5693 - mae: 66.2442 - val_loss: 62.7616 - val_mae: 63.4413\n",
      "Epoch 138/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.9249 - mae: 65.6031 - val_loss: 60.1932 - val_mae: 60.8669\n",
      "Epoch 139/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 65.3171 - mae: 65.9865 - val_loss: 59.9186 - val_mae: 60.5934\n",
      "Epoch 140/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.6911 - mae: 65.3645 - val_loss: 60.1709 - val_mae: 60.8473\n",
      "Epoch 141/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.9195 - mae: 64.5926 - val_loss: 60.2715 - val_mae: 60.9368\n",
      "Epoch 142/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 65.4533 - mae: 66.1274 - val_loss: 56.8767 - val_mae: 57.5420\n",
      "Epoch 143/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.8281 - mae: 64.4972 - val_loss: 59.5343 - val_mae: 60.1976\n",
      "Epoch 144/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.2899 - mae: 64.9672 - val_loss: 68.3783 - val_mae: 69.0599\n",
      "Epoch 145/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 65.9972 - mae: 66.6730 - val_loss: 61.0410 - val_mae: 61.7181\n",
      "Epoch 146/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.9453 - mae: 64.6159 - val_loss: 67.5133 - val_mae: 68.1965\n",
      "Epoch 147/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 69.1775 - mae: 69.8591 - val_loss: 68.6427 - val_mae: 69.3338\n",
      "Epoch 148/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.2260 - mae: 63.8949 - val_loss: 57.4053 - val_mae: 58.0784\n",
      "Epoch 149/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.5210 - mae: 63.1925 - val_loss: 58.0809 - val_mae: 58.7554\n",
      "Epoch 150/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.5687 - mae: 65.2454 - val_loss: 60.2104 - val_mae: 60.8955\n",
      "Epoch 151/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.3586 - mae: 64.0351 - val_loss: 64.9691 - val_mae: 65.6574\n",
      "Epoch 152/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 65.1534 - mae: 65.8309 - val_loss: 56.6221 - val_mae: 57.2973\n",
      "Epoch 153/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.1261 - mae: 63.7957 - val_loss: 58.9670 - val_mae: 59.6348\n",
      "Epoch 154/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.5008 - mae: 64.1721 - val_loss: 58.1001 - val_mae: 58.7681\n",
      "Epoch 155/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.0770 - mae: 63.7539 - val_loss: 56.2355 - val_mae: 56.9097\n",
      "Epoch 156/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.3260 - mae: 65.0017 - val_loss: 57.6608 - val_mae: 58.3314\n",
      "Epoch 157/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.6347 - mae: 65.3126 - val_loss: 60.7222 - val_mae: 61.4004\n",
      "Epoch 158/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.3630 - mae: 65.0406 - val_loss: 57.1923 - val_mae: 57.8701\n",
      "Epoch 159/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.8160 - mae: 62.4885 - val_loss: 57.5719 - val_mae: 58.2466\n",
      "Epoch 160/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.7348 - mae: 62.4086 - val_loss: 59.3042 - val_mae: 59.9720\n",
      "Epoch 161/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.8327 - mae: 63.5070 - val_loss: 57.0152 - val_mae: 57.6868\n",
      "Epoch 162/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.4994 - mae: 64.1732 - val_loss: 57.2441 - val_mae: 57.9233\n",
      "Epoch 163/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.4271 - mae: 63.0988 - val_loss: 57.0869 - val_mae: 57.7596\n",
      "Epoch 164/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.6363 - mae: 63.3105 - val_loss: 66.1325 - val_mae: 66.8191\n",
      "Epoch 165/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.1478 - mae: 63.8171 - val_loss: 62.5437 - val_mae: 63.2317\n",
      "Epoch 166/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.5357 - mae: 65.2116 - val_loss: 65.7351 - val_mae: 66.4255\n",
      "Epoch 167/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.7246 - mae: 62.3944 - val_loss: 58.2295 - val_mae: 58.9112\n",
      "Epoch 168/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.2683 - mae: 63.9420 - val_loss: 61.6980 - val_mae: 62.3770\n",
      "Epoch 169/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.1933 - mae: 62.8640 - val_loss: 56.6419 - val_mae: 57.3141\n",
      "Epoch 170/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.5929 - mae: 64.2663 - val_loss: 56.6306 - val_mae: 57.3023\n",
      "Epoch 171/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.3385 - mae: 62.0070 - val_loss: 56.8247 - val_mae: 57.4984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.8372 - mae: 62.5105 - val_loss: 58.3634 - val_mae: 59.0455\n",
      "Epoch 173/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.7328 - mae: 63.4049 - val_loss: 56.6611 - val_mae: 57.3228\n",
      "Epoch 174/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 65.8253 - mae: 66.5024 - val_loss: 56.6734 - val_mae: 57.3496\n",
      "Epoch 175/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.0754 - mae: 63.7512 - val_loss: 57.1366 - val_mae: 57.8176\n",
      "Epoch 176/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.8332 - mae: 63.5120 - val_loss: 61.8902 - val_mae: 62.5773\n",
      "Epoch 177/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.0912 - mae: 64.7687 - val_loss: 57.5802 - val_mae: 58.2643\n",
      "Epoch 178/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.5174 - mae: 63.1902 - val_loss: 64.5061 - val_mae: 65.1841\n",
      "Epoch 179/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.9351 - mae: 63.6119 - val_loss: 57.7363 - val_mae: 58.4110\n",
      "Epoch 180/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.7978 - mae: 61.4715 - val_loss: 62.2250 - val_mae: 62.8962\n",
      "Epoch 181/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.9773 - mae: 61.6468 - val_loss: 56.1388 - val_mae: 56.8127\n",
      "Epoch 182/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.8028 - mae: 61.4777 - val_loss: 56.2408 - val_mae: 56.9072\n",
      "Epoch 183/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.1684 - mae: 62.8448 - val_loss: 59.4387 - val_mae: 60.1255\n",
      "Epoch 184/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.5828 - mae: 62.2569 - val_loss: 59.1327 - val_mae: 59.8179\n",
      "Epoch 185/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 64.4588 - mae: 65.1347 - val_loss: 61.4520 - val_mae: 62.1297\n",
      "Epoch 186/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.7556 - mae: 62.4330 - val_loss: 67.7204 - val_mae: 68.4110\n",
      "Epoch 187/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.3736 - mae: 63.0543 - val_loss: 58.4694 - val_mae: 59.1502\n",
      "Epoch 188/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.7117 - mae: 60.3790 - val_loss: 58.3095 - val_mae: 58.9919\n",
      "Epoch 189/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.4735 - mae: 60.1435 - val_loss: 59.4121 - val_mae: 60.0841\n",
      "Epoch 190/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.9149 - mae: 60.5830 - val_loss: 55.8057 - val_mae: 56.4711\n",
      "Epoch 191/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.2168 - mae: 60.8770 - val_loss: 61.0048 - val_mae: 61.6916\n",
      "Epoch 192/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.2919 - mae: 61.9650 - val_loss: 58.4822 - val_mae: 59.1521\n",
      "Epoch 193/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.9751 - mae: 61.6442 - val_loss: 56.4687 - val_mae: 57.1430\n",
      "Epoch 194/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.4339 - mae: 61.1093 - val_loss: 55.7603 - val_mae: 56.4249\n",
      "Epoch 195/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.2987 - mae: 60.9688 - val_loss: 55.3366 - val_mae: 56.0088\n",
      "Epoch 196/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.0233 - mae: 62.6995 - val_loss: 57.8499 - val_mae: 58.5123\n",
      "Epoch 197/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.5623 - mae: 62.2375 - val_loss: 57.3075 - val_mae: 57.9906\n",
      "Epoch 198/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.0530 - mae: 62.7265 - val_loss: 68.0410 - val_mae: 68.7224\n",
      "Epoch 199/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.3144 - mae: 63.9897 - val_loss: 57.1391 - val_mae: 57.8105\n",
      "Epoch 200/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.8810 - mae: 61.5546 - val_loss: 64.0445 - val_mae: 64.7222\n",
      "Epoch 201/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.8029 - mae: 60.4742 - val_loss: 54.4909 - val_mae: 55.1567\n",
      "Epoch 202/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.8512 - mae: 59.5237 - val_loss: 56.5443 - val_mae: 57.2157\n",
      "Epoch 203/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.4366 - mae: 60.1088 - val_loss: 53.9744 - val_mae: 54.6409\n",
      "Epoch 204/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.1027 - mae: 60.7806 - val_loss: 55.8996 - val_mae: 56.5659\n",
      "Epoch 205/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.9304 - mae: 60.6029 - val_loss: 58.7480 - val_mae: 59.4226\n",
      "Epoch 206/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.8619 - mae: 61.5368 - val_loss: 56.6722 - val_mae: 57.3369\n",
      "Epoch 207/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.5605 - mae: 61.2362 - val_loss: 55.0026 - val_mae: 55.6709\n",
      "Epoch 208/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.8263 - mae: 58.4881 - val_loss: 59.2593 - val_mae: 59.9329\n",
      "Epoch 209/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.3843 - mae: 64.0595 - val_loss: 62.2627 - val_mae: 62.9389\n",
      "Epoch 210/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.1610 - mae: 59.8319 - val_loss: 57.6018 - val_mae: 58.2743\n",
      "Epoch 211/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.6431 - mae: 61.3158 - val_loss: 53.8386 - val_mae: 54.5122\n",
      "Epoch 212/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.6334 - mae: 60.3013 - val_loss: 65.0307 - val_mae: 65.7172\n",
      "Epoch 213/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.0750 - mae: 60.7488 - val_loss: 54.5460 - val_mae: 55.2168\n",
      "Epoch 214/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.1576 - mae: 60.8312 - val_loss: 53.7867 - val_mae: 54.4493\n",
      "Epoch 215/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.2649 - mae: 60.9416 - val_loss: 60.2913 - val_mae: 60.9642\n",
      "Epoch 216/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.7830 - mae: 59.4571 - val_loss: 60.8591 - val_mae: 61.5438\n",
      "Epoch 217/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.9641 - mae: 62.6360 - val_loss: 53.3992 - val_mae: 54.0633\n",
      "Epoch 218/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.3700 - mae: 59.0379 - val_loss: 58.2078 - val_mae: 58.8903\n",
      "Epoch 219/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.4497 - mae: 60.1258 - val_loss: 55.6773 - val_mae: 56.3617\n",
      "Epoch 220/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.3615 - mae: 60.0321 - val_loss: 54.4677 - val_mae: 55.1511\n",
      "Epoch 221/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.0397 - mae: 59.7123 - val_loss: 56.6569 - val_mae: 57.3215\n",
      "Epoch 222/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.6620 - mae: 58.3291 - val_loss: 56.3405 - val_mae: 57.0166\n",
      "Epoch 223/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 62.0400 - mae: 62.7170 - val_loss: 57.0476 - val_mae: 57.7174\n",
      "Epoch 224/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.6024 - mae: 59.2713 - val_loss: 56.6474 - val_mae: 57.3136\n",
      "Epoch 225/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.0819 - mae: 59.7573 - val_loss: 53.2005 - val_mae: 53.8655\n",
      "Epoch 226/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.9224 - mae: 62.5967 - val_loss: 55.1815 - val_mae: 55.8565\n",
      "Epoch 227/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 63.0962 - mae: 63.7753 - val_loss: 67.7268 - val_mae: 68.4133\n",
      "Epoch 228/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.3818 - mae: 60.0532 - val_loss: 55.5909 - val_mae: 56.2639\n",
      "Epoch 229/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.9751 - mae: 59.6484 - val_loss: 56.4616 - val_mae: 57.1391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.7863 - mae: 62.4659 - val_loss: 59.4315 - val_mae: 60.1062\n",
      "Epoch 231/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.2062 - mae: 58.8718 - val_loss: 59.9719 - val_mae: 60.6376\n",
      "Epoch 232/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.2707 - mae: 60.9428 - val_loss: 53.1964 - val_mae: 53.8719\n",
      "Epoch 233/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.1422 - mae: 59.8166 - val_loss: 52.7507 - val_mae: 53.4135\n",
      "Epoch 234/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.4029 - mae: 59.0768 - val_loss: 57.6240 - val_mae: 58.3044\n",
      "Epoch 235/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.5470 - mae: 61.2198 - val_loss: 53.3551 - val_mae: 54.0227\n",
      "Epoch 236/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.0666 - mae: 59.7393 - val_loss: 54.1528 - val_mae: 54.8294\n",
      "Epoch 237/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 61.4796 - mae: 62.1533 - val_loss: 55.8006 - val_mae: 56.4799\n",
      "Epoch 238/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.1116 - mae: 58.7859 - val_loss: 53.8591 - val_mae: 54.5283\n",
      "Epoch 239/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 58.0522 - mae: 58.7237 - val_loss: 52.7903 - val_mae: 53.4528\n",
      "Epoch 240/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 57.7585 - mae: 58.4259 - val_loss: 56.9750 - val_mae: 57.6586\n",
      "Epoch 241/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.8564 - mae: 59.5272 - val_loss: 67.2550 - val_mae: 67.9426\n",
      "Epoch 242/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.9960 - mae: 62.6783 - val_loss: 55.9757 - val_mae: 56.6623\n",
      "Epoch 243/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.4399 - mae: 61.1171 - val_loss: 57.6988 - val_mae: 58.3751\n",
      "Epoch 244/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 61.8189 - mae: 62.4958 - val_loss: 57.1385 - val_mae: 57.8134\n",
      "Epoch 245/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.3325 - mae: 60.0041 - val_loss: 53.2359 - val_mae: 53.9058\n",
      "Epoch 246/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 57.9993 - mae: 58.6743 - val_loss: 57.5714 - val_mae: 58.2411\n",
      "Epoch 247/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 62.0624 - mae: 62.7379 - val_loss: 55.1105 - val_mae: 55.7889\n",
      "Epoch 248/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.1006 - mae: 58.7746 - val_loss: 54.3449 - val_mae: 55.0104\n",
      "Epoch 249/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.0155 - mae: 57.6842 - val_loss: 52.1339 - val_mae: 52.7972\n",
      "Epoch 250/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.1056 - mae: 58.7728 - val_loss: 53.5497 - val_mae: 54.2234\n",
      "Epoch 251/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.4864 - mae: 58.1525 - val_loss: 53.5393 - val_mae: 54.2006\n",
      "Epoch 252/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.3181 - mae: 57.9819 - val_loss: 52.2741 - val_mae: 52.9512\n",
      "Epoch 253/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 56.8648 - mae: 57.5388 - val_loss: 54.4115 - val_mae: 55.0920\n",
      "Epoch 254/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.9438 - mae: 59.6226 - val_loss: 60.0837 - val_mae: 60.7481\n",
      "Epoch 255/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.7598 - mae: 61.4366 - val_loss: 55.0081 - val_mae: 55.6924\n",
      "Epoch 256/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.1181 - mae: 58.7898 - val_loss: 52.8467 - val_mae: 53.5154\n",
      "Epoch 257/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.4892 - mae: 58.1596 - val_loss: 53.9704 - val_mae: 54.6479\n",
      "Epoch 258/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.2010 - mae: 58.8734 - val_loss: 56.1983 - val_mae: 56.8553\n",
      "Epoch 259/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.3513 - mae: 60.0271 - val_loss: 52.4765 - val_mae: 53.1448\n",
      "Epoch 260/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.2355 - mae: 57.9049 - val_loss: 59.7160 - val_mae: 60.3911\n",
      "Epoch 261/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.8464 - mae: 59.5272 - val_loss: 55.2800 - val_mae: 55.9631\n",
      "Epoch 262/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.0812 - mae: 58.7562 - val_loss: 52.0745 - val_mae: 52.7372\n",
      "Epoch 263/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.8671 - mae: 61.5394 - val_loss: 57.7716 - val_mae: 58.4577\n",
      "Epoch 264/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.5697 - mae: 60.2426 - val_loss: 53.9649 - val_mae: 54.6368\n",
      "Epoch 265/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.6610 - mae: 57.3332 - val_loss: 52.4982 - val_mae: 53.1647\n",
      "Epoch 266/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.8637 - mae: 57.5353 - val_loss: 55.8191 - val_mae: 56.4942\n",
      "Epoch 267/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.4898 - mae: 57.1610 - val_loss: 54.0624 - val_mae: 54.7374\n",
      "Epoch 268/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.0626 - mae: 59.7353 - val_loss: 72.4962 - val_mae: 73.1779\n",
      "Epoch 269/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.0938 - mae: 60.7735 - val_loss: 55.4116 - val_mae: 56.0947\n",
      "Epoch 270/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.3737 - mae: 59.0512 - val_loss: 52.6647 - val_mae: 53.3302\n",
      "Epoch 271/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.2254 - mae: 58.8984 - val_loss: 52.1344 - val_mae: 52.7978\n",
      "Epoch 272/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.5263 - mae: 60.1994 - val_loss: 58.2441 - val_mae: 58.9310\n",
      "Epoch 273/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.1034 - mae: 58.7815 - val_loss: 55.8315 - val_mae: 56.5103\n",
      "Epoch 274/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.2065 - mae: 57.8802 - val_loss: 55.8064 - val_mae: 56.4830\n",
      "Epoch 275/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.3493 - mae: 59.0269 - val_loss: 55.5966 - val_mae: 56.2797\n",
      "Epoch 276/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.1198 - mae: 57.7924 - val_loss: 51.6094 - val_mae: 52.2839\n",
      "Epoch 277/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.5024 - mae: 58.1751 - val_loss: 56.9796 - val_mae: 57.6720\n",
      "Epoch 278/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.8349 - mae: 57.5033 - val_loss: 51.5047 - val_mae: 52.1636\n",
      "Epoch 279/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.3780 - mae: 58.0479 - val_loss: 54.9511 - val_mae: 55.6319\n",
      "Epoch 280/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.8389 - mae: 56.5100 - val_loss: 55.0973 - val_mae: 55.7763\n",
      "Epoch 281/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.6269 - mae: 56.2949 - val_loss: 56.1178 - val_mae: 56.7924\n",
      "Epoch 282/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.9309 - mae: 55.5937 - val_loss: 51.2159 - val_mae: 51.8919\n",
      "Epoch 283/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.1729 - mae: 57.8466 - val_loss: 52.1671 - val_mae: 52.8479\n",
      "Epoch 284/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.7590 - mae: 56.4243 - val_loss: 58.4784 - val_mae: 59.1685\n",
      "Epoch 285/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.3428 - mae: 59.0210 - val_loss: 51.9663 - val_mae: 52.6271\n",
      "Epoch 286/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.1073 - mae: 57.7762 - val_loss: 54.1089 - val_mae: 54.7917\n",
      "Epoch 287/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.8559 - mae: 55.5227 - val_loss: 51.0839 - val_mae: 51.7537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.4735 - mae: 56.1447 - val_loss: 52.0442 - val_mae: 52.7102\n",
      "Epoch 289/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.3332 - mae: 57.0060 - val_loss: 52.2159 - val_mae: 52.8897\n",
      "Epoch 290/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.7843 - mae: 56.4493 - val_loss: 53.2803 - val_mae: 53.9392\n",
      "Epoch 291/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.1188 - mae: 56.7904 - val_loss: 52.0349 - val_mae: 52.7132\n",
      "Epoch 292/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.1177 - mae: 58.7903 - val_loss: 53.9941 - val_mae: 54.6563\n",
      "Epoch 293/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 56.5883 - mae: 57.2633 - val_loss: 55.7144 - val_mae: 56.3984\n",
      "Epoch 294/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 57.1496 - mae: 57.8287 - val_loss: 54.7366 - val_mae: 55.4183\n",
      "Epoch 295/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 55.3684 - mae: 56.0351 - val_loss: 50.4858 - val_mae: 51.1468\n",
      "Epoch 296/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.6216 - mae: 57.2981 - val_loss: 50.6074 - val_mae: 51.2666\n",
      "Epoch 297/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 54.5988 - mae: 55.2631 - val_loss: 51.3279 - val_mae: 52.0051\n",
      "Epoch 298/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 54.7023 - mae: 55.3671 - val_loss: 51.2661 - val_mae: 51.9323\n",
      "Epoch 299/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 58.0817 - mae: 58.7583 - val_loss: 58.4411 - val_mae: 59.1303\n",
      "Epoch 300/5000\n",
      "1972/1972 [==============================] - 5s 3ms/step - loss: 58.5834 - mae: 59.2620 - val_loss: 51.6079 - val_mae: 52.2678\n",
      "Epoch 301/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.0724 - mae: 56.7431 - val_loss: 52.6853 - val_mae: 53.3646\n",
      "Epoch 302/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.3345 - mae: 57.0090 - val_loss: 51.5564 - val_mae: 52.2296\n",
      "Epoch 303/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.8035 - mae: 55.4766 - val_loss: 50.9562 - val_mae: 51.6320\n",
      "Epoch 304/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.1458 - mae: 56.8216 - val_loss: 55.1291 - val_mae: 55.8069\n",
      "Epoch 305/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.5944 - mae: 58.2665 - val_loss: 55.0303 - val_mae: 55.7175\n",
      "Epoch 306/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.0597 - mae: 57.7354 - val_loss: 52.0646 - val_mae: 52.7411\n",
      "Epoch 307/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 60.4877 - mae: 61.1692 - val_loss: 60.9462 - val_mae: 61.6357\n",
      "Epoch 308/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 59.5537 - mae: 60.2317 - val_loss: 51.7550 - val_mae: 52.4349\n",
      "Epoch 309/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.9831 - mae: 56.6537 - val_loss: 51.6439 - val_mae: 52.3109\n",
      "Epoch 310/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.3805 - mae: 56.0491 - val_loss: 51.7035 - val_mae: 52.3800\n",
      "Epoch 311/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.5116 - mae: 56.1847 - val_loss: 50.8936 - val_mae: 51.5527\n",
      "Epoch 312/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.3397 - mae: 55.0060 - val_loss: 49.2816 - val_mae: 49.9359\n",
      "Epoch 313/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.3246 - mae: 54.9914 - val_loss: 53.0044 - val_mae: 53.6640\n",
      "Epoch 314/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.1911 - mae: 55.8568 - val_loss: 53.0727 - val_mae: 53.7578\n",
      "Epoch 315/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.3666 - mae: 57.0454 - val_loss: 49.8447 - val_mae: 50.5155\n",
      "Epoch 316/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.4323 - mae: 55.0984 - val_loss: 50.9305 - val_mae: 51.6092\n",
      "Epoch 317/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.2838 - mae: 55.9546 - val_loss: 56.2831 - val_mae: 56.9672\n",
      "Epoch 318/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.2557 - mae: 55.9278 - val_loss: 52.7611 - val_mae: 53.4136\n",
      "Epoch 319/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.1679 - mae: 57.8396 - val_loss: 49.0843 - val_mae: 49.7455\n",
      "Epoch 320/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.3175 - mae: 54.9890 - val_loss: 49.9709 - val_mae: 50.6396\n",
      "Epoch 321/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.1843 - mae: 54.8525 - val_loss: 49.9393 - val_mae: 50.6140\n",
      "Epoch 322/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.6280 - mae: 56.2981 - val_loss: 50.6263 - val_mae: 51.2933\n",
      "Epoch 323/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.1196 - mae: 54.7868 - val_loss: 48.8938 - val_mae: 49.5532\n",
      "Epoch 324/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 53.9949 - mae: 54.6605 - val_loss: 50.0823 - val_mae: 50.7487\n",
      "Epoch 325/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.0304 - mae: 54.7025 - val_loss: 56.0321 - val_mae: 56.7020\n",
      "Epoch 326/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.2651 - mae: 54.9343 - val_loss: 50.7671 - val_mae: 51.4389\n",
      "Epoch 327/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.6794 - mae: 57.3544 - val_loss: 49.4288 - val_mae: 50.0838\n",
      "Epoch 328/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.0920 - mae: 54.7615 - val_loss: 51.0728 - val_mae: 51.7543\n",
      "Epoch 329/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 57.9708 - mae: 58.6532 - val_loss: 52.0945 - val_mae: 52.7711\n",
      "Epoch 330/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.1091 - mae: 54.7803 - val_loss: 48.9810 - val_mae: 49.6523\n",
      "Epoch 331/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.0021 - mae: 56.6735 - val_loss: 57.8021 - val_mae: 58.4800\n",
      "Epoch 332/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.4944 - mae: 57.1640 - val_loss: 51.7531 - val_mae: 52.4263\n",
      "Epoch 333/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.9814 - mae: 56.6572 - val_loss: 49.7885 - val_mae: 50.4612\n",
      "Epoch 334/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 53.6896 - mae: 54.3521 - val_loss: 50.4376 - val_mae: 51.0956\n",
      "Epoch 335/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 55.3475 - mae: 56.0211 - val_loss: 51.1974 - val_mae: 51.8778\n",
      "Epoch 336/5000\n",
      "1972/1972 [==============================] - 5s 3ms/step - loss: 54.8054 - mae: 55.4767 - val_loss: 51.2438 - val_mae: 51.9164\n",
      "Epoch 337/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 56.0833 - mae: 56.7602 - val_loss: 49.2141 - val_mae: 49.8742\n",
      "Epoch 338/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 56.0176 - mae: 56.6944 - val_loss: 50.7615 - val_mae: 51.4232\n",
      "Epoch 339/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.3777 - mae: 55.0419 - val_loss: 52.4388 - val_mae: 53.0909\n",
      "Epoch 340/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 54.0261 - mae: 54.6891 - val_loss: 53.6081 - val_mae: 54.2661\n",
      "Epoch 341/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 56.0371 - mae: 56.7064 - val_loss: 48.8889 - val_mae: 49.5534\n",
      "Epoch 342/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.4479 - mae: 55.1216 - val_loss: 51.0459 - val_mae: 51.7080\n",
      "Epoch 343/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.0723 - mae: 54.7398 - val_loss: 49.0388 - val_mae: 49.6981\n",
      "Epoch 344/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 53.0618 - mae: 53.7309 - val_loss: 50.1171 - val_mae: 50.7975\n",
      "Epoch 345/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.3065 - mae: 55.9826 - val_loss: 51.3773 - val_mae: 52.0488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.3597 - mae: 57.0379 - val_loss: 49.7037 - val_mae: 50.3654\n",
      "Epoch 347/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.0248 - mae: 54.6921 - val_loss: 58.7028 - val_mae: 59.3919\n",
      "Epoch 348/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.4601 - mae: 54.1317 - val_loss: 48.5960 - val_mae: 49.2679\n",
      "Epoch 349/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.4963 - mae: 54.1686 - val_loss: 50.9571 - val_mae: 51.6407\n",
      "Epoch 350/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.6506 - mae: 54.3235 - val_loss: 48.5748 - val_mae: 49.2508\n",
      "Epoch 351/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.0895 - mae: 53.7530 - val_loss: 50.2636 - val_mae: 50.9321\n",
      "Epoch 352/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.1628 - mae: 54.8326 - val_loss: 50.8000 - val_mae: 51.4791\n",
      "Epoch 353/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.9101 - mae: 57.5905 - val_loss: 50.1997 - val_mae: 50.8694\n",
      "Epoch 354/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 53.7576 - mae: 54.4314 - val_loss: 49.7150 - val_mae: 50.3843\n",
      "Epoch 355/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.8371 - mae: 53.5012 - val_loss: 50.9622 - val_mae: 51.6377\n",
      "Epoch 356/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.0775 - mae: 54.7480 - val_loss: 52.7757 - val_mae: 53.4622\n",
      "Epoch 357/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.1117 - mae: 54.7824 - val_loss: 51.1271 - val_mae: 51.8082\n",
      "Epoch 358/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.1100 - mae: 55.7865 - val_loss: 47.9040 - val_mae: 48.5718\n",
      "Epoch 359/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.2171 - mae: 54.8858 - val_loss: 53.3579 - val_mae: 54.0461\n",
      "Epoch 360/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.1825 - mae: 55.8509 - val_loss: 53.0939 - val_mae: 53.7484\n",
      "Epoch 361/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.8846 - mae: 54.5587 - val_loss: 54.4431 - val_mae: 55.1332\n",
      "Epoch 362/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.0385 - mae: 53.7113 - val_loss: 54.7385 - val_mae: 55.4260\n",
      "Epoch 363/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.8893 - mae: 56.5695 - val_loss: 52.5044 - val_mae: 53.1812\n",
      "Epoch 364/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.9771 - mae: 53.6467 - val_loss: 50.2866 - val_mae: 50.9374\n",
      "Epoch 365/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.1701 - mae: 53.8422 - val_loss: 59.5143 - val_mae: 60.1886\n",
      "Epoch 366/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.8503 - mae: 53.5208 - val_loss: 48.5405 - val_mae: 49.2110\n",
      "Epoch 367/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 53.3396 - mae: 54.0054 - val_loss: 48.7445 - val_mae: 49.4156\n",
      "Epoch 368/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.8419 - mae: 54.5165 - val_loss: 55.2920 - val_mae: 55.9817\n",
      "Epoch 369/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.4524 - mae: 54.1287 - val_loss: 53.2262 - val_mae: 53.9027\n",
      "Epoch 370/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.2322 - mae: 52.9026 - val_loss: 51.1710 - val_mae: 51.8510\n",
      "Epoch 371/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.4652 - mae: 55.1449 - val_loss: 50.3581 - val_mae: 51.0399\n",
      "Epoch 372/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.8600 - mae: 56.5395 - val_loss: 52.9303 - val_mae: 53.5921\n",
      "Epoch 373/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 53.3368 - mae: 54.0060 - val_loss: 56.8401 - val_mae: 57.5159\n",
      "Epoch 374/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 54.7275 - mae: 55.4057 - val_loss: 47.1799 - val_mae: 47.8438\n",
      "Epoch 375/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.8897 - mae: 53.5571 - val_loss: 47.5007 - val_mae: 48.1698\n",
      "Epoch 376/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 55.5455 - mae: 56.2229 - val_loss: 49.6696 - val_mae: 50.3465\n",
      "Epoch 377/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.8739 - mae: 54.5445 - val_loss: 48.3162 - val_mae: 48.9676\n",
      "Epoch 378/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.1060 - mae: 52.7716 - val_loss: 47.2345 - val_mae: 47.9018\n",
      "Epoch 379/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.3953 - mae: 53.0633 - val_loss: 48.4586 - val_mae: 49.1202\n",
      "Epoch 380/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.9557 - mae: 54.6282 - val_loss: 50.1939 - val_mae: 50.8734\n",
      "Epoch 381/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.4165 - mae: 55.0907 - val_loss: 53.0266 - val_mae: 53.7152\n",
      "Epoch 382/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.6937 - mae: 53.3624 - val_loss: 47.1405 - val_mae: 47.8042\n",
      "Epoch 383/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.9736 - mae: 52.6458 - val_loss: 46.4563 - val_mae: 47.1080\n",
      "Epoch 384/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.7080 - mae: 53.3822 - val_loss: 51.1341 - val_mae: 51.8233\n",
      "Epoch 385/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.1020 - mae: 56.7799 - val_loss: 49.7247 - val_mae: 50.4089\n",
      "Epoch 386/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.6556 - mae: 54.3283 - val_loss: 46.1943 - val_mae: 46.8536\n",
      "Epoch 387/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.4662 - mae: 52.1305 - val_loss: 51.2822 - val_mae: 51.9710\n",
      "Epoch 388/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 52.2418 - mae: 52.9103 - val_loss: 57.8338 - val_mae: 58.5220\n",
      "Epoch 389/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.5466 - mae: 53.2149 - val_loss: 47.8726 - val_mae: 48.5457\n",
      "Epoch 390/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.5204 - mae: 53.1861 - val_loss: 46.4173 - val_mae: 47.0817\n",
      "Epoch 391/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 51.4332 - mae: 52.1025 - val_loss: 46.3385 - val_mae: 46.9861\n",
      "Epoch 392/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.8531 - mae: 52.5230 - val_loss: 52.3681 - val_mae: 53.0545\n",
      "Epoch 393/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.6105 - mae: 54.2861 - val_loss: 57.8824 - val_mae: 58.5575\n",
      "Epoch 394/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.6233 - mae: 52.2884 - val_loss: 46.8210 - val_mae: 47.4807\n",
      "Epoch 395/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.0895 - mae: 53.7632 - val_loss: 52.2687 - val_mae: 52.9561\n",
      "Epoch 396/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.9217 - mae: 52.5867 - val_loss: 48.8298 - val_mae: 49.5078\n",
      "Epoch 397/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.3184 - mae: 54.9888 - val_loss: 52.1895 - val_mae: 52.8784\n",
      "Epoch 398/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 52.8970 - mae: 53.5638 - val_loss: 48.0181 - val_mae: 48.6962\n",
      "Epoch 399/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.8847 - mae: 51.5559 - val_loss: 48.8399 - val_mae: 49.5019\n",
      "Epoch 400/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.5290 - mae: 54.2026 - val_loss: 47.2674 - val_mae: 47.9307\n",
      "Epoch 401/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.9149 - mae: 52.5815 - val_loss: 50.6305 - val_mae: 51.3178\n",
      "Epoch 402/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.9549 - mae: 52.6258 - val_loss: 47.9863 - val_mae: 48.6644\n",
      "Epoch 403/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1538 - mae: 51.8189 - val_loss: 47.4799 - val_mae: 48.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.9417 - mae: 52.6121 - val_loss: 49.6817 - val_mae: 50.3383\n",
      "Epoch 405/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.0660 - mae: 52.7372 - val_loss: 55.4269 - val_mae: 56.1168\n",
      "Epoch 406/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.3752 - mae: 54.0558 - val_loss: 54.3811 - val_mae: 55.0695\n",
      "Epoch 407/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.2869 - mae: 54.9603 - val_loss: 46.9342 - val_mae: 47.5960\n",
      "Epoch 408/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.4429 - mae: 52.1107 - val_loss: 46.6215 - val_mae: 47.2838\n",
      "Epoch 409/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.5631 - mae: 52.2298 - val_loss: 51.5115 - val_mae: 52.1983\n",
      "Epoch 410/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 56.0664 - mae: 56.7458 - val_loss: 59.2209 - val_mae: 59.9076\n",
      "Epoch 411/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.6837 - mae: 52.3571 - val_loss: 48.7861 - val_mae: 49.4597\n",
      "Epoch 412/5000\n",
      "1972/1972 [==============================] - 5s 3ms/step - loss: 53.1032 - mae: 53.7762 - val_loss: 53.1504 - val_mae: 53.8371\n",
      "Epoch 413/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.2596 - mae: 51.9290 - val_loss: 48.1289 - val_mae: 48.7988\n",
      "Epoch 414/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1319 - mae: 51.7983 - val_loss: 48.0993 - val_mae: 48.7588\n",
      "Epoch 415/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.5509 - mae: 52.2157 - val_loss: 45.9915 - val_mae: 46.6465\n",
      "Epoch 416/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.8843 - mae: 52.5491 - val_loss: 47.5503 - val_mae: 48.2223\n",
      "Epoch 417/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.6143 - mae: 53.2836 - val_loss: 46.0017 - val_mae: 46.6567\n",
      "Epoch 418/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.7214 - mae: 53.3931 - val_loss: 46.0728 - val_mae: 46.7512\n",
      "Epoch 419/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.3078 - mae: 51.9756 - val_loss: 47.5985 - val_mae: 48.2588\n",
      "Epoch 420/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.7693 - mae: 54.4458 - val_loss: 47.7421 - val_mae: 48.4080\n",
      "Epoch 421/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.0284 - mae: 51.6994 - val_loss: 50.0957 - val_mae: 50.7560\n",
      "Epoch 422/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.6818 - mae: 52.3590 - val_loss: 49.2065 - val_mae: 49.8701\n",
      "Epoch 423/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.4478 - mae: 52.1089 - val_loss: 45.4280 - val_mae: 46.0964\n",
      "Epoch 424/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.9781 - mae: 53.6446 - val_loss: 50.9597 - val_mae: 51.6425\n",
      "Epoch 425/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.6456 - mae: 52.3184 - val_loss: 47.1524 - val_mae: 47.8192\n",
      "Epoch 426/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.3946 - mae: 53.0635 - val_loss: 48.7633 - val_mae: 49.4381\n",
      "Epoch 427/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.3299 - mae: 51.0028 - val_loss: 46.0420 - val_mae: 46.7130\n",
      "Epoch 428/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1148 - mae: 51.7802 - val_loss: 44.4477 - val_mae: 45.0926\n",
      "Epoch 429/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.2383 - mae: 50.9022 - val_loss: 48.8016 - val_mae: 49.4783\n",
      "Epoch 430/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.8907 - mae: 53.5680 - val_loss: 45.9104 - val_mae: 46.5812\n",
      "Epoch 431/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.6039 - mae: 53.2794 - val_loss: 50.5672 - val_mae: 51.2269\n",
      "Epoch 432/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.7740 - mae: 52.4488 - val_loss: 48.7332 - val_mae: 49.4189\n",
      "Epoch 433/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.8972 - mae: 53.5751 - val_loss: 46.4702 - val_mae: 47.1414\n",
      "Epoch 434/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 53.1939 - mae: 53.8674 - val_loss: 51.4934 - val_mae: 52.1493\n",
      "Epoch 435/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 54.0422 - mae: 54.7134 - val_loss: 50.0621 - val_mae: 50.7423\n",
      "Epoch 436/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.6728 - mae: 51.3388 - val_loss: 46.9052 - val_mae: 47.5895\n",
      "Epoch 437/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.8467 - mae: 51.5188 - val_loss: 46.6662 - val_mae: 47.3425\n",
      "Epoch 438/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.3684 - mae: 51.0352 - val_loss: 44.1860 - val_mae: 44.8376\n",
      "Epoch 439/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.1325 - mae: 50.8044 - val_loss: 44.3132 - val_mae: 44.9721\n",
      "Epoch 440/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.6593 - mae: 51.3274 - val_loss: 46.4638 - val_mae: 47.1138\n",
      "Epoch 441/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.2466 - mae: 49.9059 - val_loss: 45.4572 - val_mae: 46.1271\n",
      "Epoch 442/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.3908 - mae: 52.0654 - val_loss: 46.9277 - val_mae: 47.6087\n",
      "Epoch 443/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.2036 - mae: 51.8750 - val_loss: 48.6914 - val_mae: 49.3655\n",
      "Epoch 444/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1613 - mae: 51.8334 - val_loss: 50.4913 - val_mae: 51.1771\n",
      "Epoch 445/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.4748 - mae: 52.1442 - val_loss: 45.7704 - val_mae: 46.4400\n",
      "Epoch 446/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.6119 - mae: 50.2810 - val_loss: 49.1660 - val_mae: 49.8330\n",
      "Epoch 447/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.4559 - mae: 51.1263 - val_loss: 60.7550 - val_mae: 61.4409\n",
      "Epoch 448/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1850 - mae: 51.8533 - val_loss: 47.3150 - val_mae: 48.0057\n",
      "Epoch 449/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.4963 - mae: 53.1753 - val_loss: 46.5003 - val_mae: 47.1791\n",
      "Epoch 450/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.1021 - mae: 49.7648 - val_loss: 46.7339 - val_mae: 47.4087\n",
      "Epoch 451/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.0709 - mae: 50.7381 - val_loss: 56.7426 - val_mae: 57.4072\n",
      "Epoch 452/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.6947 - mae: 52.3662 - val_loss: 47.8242 - val_mae: 48.4986\n",
      "Epoch 453/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.6582 - mae: 50.3256 - val_loss: 50.2595 - val_mae: 50.9474\n",
      "Epoch 454/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.0146 - mae: 52.6917 - val_loss: 45.2828 - val_mae: 45.9618\n",
      "Epoch 455/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.3327 - mae: 50.0000 - val_loss: 49.4821 - val_mae: 50.1505\n",
      "Epoch 456/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.6047 - mae: 53.2701 - val_loss: 55.1305 - val_mae: 55.8096\n",
      "Epoch 457/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.4857 - mae: 51.1597 - val_loss: 44.2193 - val_mae: 44.8721\n",
      "Epoch 458/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.8163 - mae: 50.4804 - val_loss: 46.1943 - val_mae: 46.8749\n",
      "Epoch 459/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.7330 - mae: 51.4110 - val_loss: 49.6106 - val_mae: 50.2933\n",
      "Epoch 460/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.8834 - mae: 53.5577 - val_loss: 48.9587 - val_mae: 49.6350\n",
      "Epoch 461/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.4062 - mae: 50.0736 - val_loss: 57.5153 - val_mae: 58.1764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1564 - mae: 51.8229 - val_loss: 47.2134 - val_mae: 47.8911\n",
      "Epoch 463/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.9048 - mae: 49.5669 - val_loss: 46.0471 - val_mae: 46.7282\n",
      "Epoch 464/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.8309 - mae: 49.5001 - val_loss: 49.5936 - val_mae: 50.2739\n",
      "Epoch 465/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.4751 - mae: 49.1415 - val_loss: 44.3115 - val_mae: 44.9615\n",
      "Epoch 466/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.7318 - mae: 51.4040 - val_loss: 50.4639 - val_mae: 51.1283\n",
      "Epoch 467/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1604 - mae: 51.8244 - val_loss: 43.4123 - val_mae: 44.0732\n",
      "Epoch 468/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.7044 - mae: 51.3827 - val_loss: 45.9622 - val_mae: 46.6346\n",
      "Epoch 469/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.6411 - mae: 51.3125 - val_loss: 43.3291 - val_mae: 43.9812\n",
      "Epoch 470/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.8465 - mae: 52.5235 - val_loss: 48.5081 - val_mae: 49.1709\n",
      "Epoch 471/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.7601 - mae: 53.4377 - val_loss: 49.2422 - val_mae: 49.9209\n",
      "Epoch 472/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.9916 - mae: 52.6691 - val_loss: 44.3554 - val_mae: 45.0300\n",
      "Epoch 473/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.6157 - mae: 51.2789 - val_loss: 44.9434 - val_mae: 45.6224\n",
      "Epoch 474/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.1002 - mae: 49.7683 - val_loss: 44.3845 - val_mae: 45.0497\n",
      "Epoch 475/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.4743 - mae: 48.1363 - val_loss: 47.5055 - val_mae: 48.1790\n",
      "Epoch 476/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.2496 - mae: 49.9177 - val_loss: 45.5524 - val_mae: 46.2326\n",
      "Epoch 477/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.4302 - mae: 50.1025 - val_loss: 43.9243 - val_mae: 44.5954\n",
      "Epoch 478/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.9218 - mae: 52.5899 - val_loss: 73.7921 - val_mae: 74.4758\n",
      "Epoch 479/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.6078 - mae: 53.2807 - val_loss: 50.4666 - val_mae: 51.1470\n",
      "Epoch 480/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.7860 - mae: 50.4634 - val_loss: 43.2813 - val_mae: 43.9320\n",
      "Epoch 481/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.1236 - mae: 51.7959 - val_loss: 43.7107 - val_mae: 44.3677\n",
      "Epoch 482/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.4844 - mae: 51.1608 - val_loss: 46.7757 - val_mae: 47.4502\n",
      "Epoch 483/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.9190 - mae: 50.5858 - val_loss: 43.7740 - val_mae: 44.4463\n",
      "Epoch 484/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.4840 - mae: 50.1483 - val_loss: 48.7590 - val_mae: 49.4442\n",
      "Epoch 485/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.3667 - mae: 53.0480 - val_loss: 53.7880 - val_mae: 54.4767\n",
      "Epoch 486/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.2989 - mae: 50.9733 - val_loss: 48.9258 - val_mae: 49.6102\n",
      "Epoch 487/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.8748 - mae: 49.5395 - val_loss: 43.0479 - val_mae: 43.7135\n",
      "Epoch 488/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.8514 - mae: 49.5225 - val_loss: 47.8452 - val_mae: 48.5352\n",
      "Epoch 489/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 53.3718 - mae: 54.0514 - val_loss: 48.1287 - val_mae: 48.8157\n",
      "Epoch 490/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.2075 - mae: 51.8838 - val_loss: 46.9229 - val_mae: 47.6106\n",
      "Epoch 491/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.6675 - mae: 49.3336 - val_loss: 44.2079 - val_mae: 44.8694\n",
      "Epoch 492/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.3753 - mae: 50.0437 - val_loss: 42.2466 - val_mae: 42.9005\n",
      "Epoch 493/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.4908 - mae: 50.1647 - val_loss: 46.8465 - val_mae: 47.5165\n",
      "Epoch 494/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.3445 - mae: 51.0205 - val_loss: 45.3469 - val_mae: 46.0313\n",
      "Epoch 495/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.3830 - mae: 49.0467 - val_loss: 44.8487 - val_mae: 45.5309\n",
      "Epoch 496/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 52.5116 - mae: 53.1907 - val_loss: 52.2837 - val_mae: 52.9635\n",
      "Epoch 497/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.9701 - mae: 50.6479 - val_loss: 43.5089 - val_mae: 44.1687\n",
      "Epoch 498/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 48.4136 - mae: 49.0801 - val_loss: 42.5958 - val_mae: 43.2513\n",
      "Epoch 499/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 48.0243 - mae: 48.6891 - val_loss: 45.8258 - val_mae: 46.4995\n",
      "Epoch 500/5000\n",
      "1972/1972 [==============================] - 5s 3ms/step - loss: 49.2909 - mae: 49.9604 - val_loss: 43.1618 - val_mae: 43.8391\n",
      "Epoch 501/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 47.9807 - mae: 48.6524 - val_loss: 45.8368 - val_mae: 46.5067\n",
      "Epoch 502/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.1898 - mae: 48.8623 - val_loss: 43.2348 - val_mae: 43.8939\n",
      "Epoch 503/5000\n",
      "1972/1972 [==============================] - 5s 3ms/step - loss: 48.1737 - mae: 48.8393 - val_loss: 44.0622 - val_mae: 44.7160\n",
      "Epoch 504/5000\n",
      "1972/1972 [==============================] - 5s 3ms/step - loss: 48.3819 - mae: 49.0530 - val_loss: 42.2128 - val_mae: 42.8750\n",
      "Epoch 505/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.7720 - mae: 48.4375 - val_loss: 44.7604 - val_mae: 45.4313\n",
      "Epoch 506/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.2721 - mae: 48.9417 - val_loss: 46.2559 - val_mae: 46.9387\n",
      "Epoch 507/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 47.9248 - mae: 48.5883 - val_loss: 42.4003 - val_mae: 43.0464\n",
      "Epoch 508/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.1690 - mae: 49.8421 - val_loss: 50.6975 - val_mae: 51.3504\n",
      "Epoch 509/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.3250 - mae: 49.9880 - val_loss: 45.4256 - val_mae: 46.1009\n",
      "Epoch 510/5000\n",
      "1972/1972 [==============================] - 5s 3ms/step - loss: 49.5978 - mae: 50.2705 - val_loss: 47.6434 - val_mae: 48.3275\n",
      "Epoch 511/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.4706 - mae: 51.1496 - val_loss: 47.2161 - val_mae: 47.8803\n",
      "Epoch 512/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.2494 - mae: 48.9167 - val_loss: 43.2868 - val_mae: 43.9574\n",
      "Epoch 513/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.9575 - mae: 48.6232 - val_loss: 48.8802 - val_mae: 49.5575\n",
      "Epoch 514/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.0669 - mae: 48.7362 - val_loss: 52.1558 - val_mae: 52.8449\n",
      "Epoch 515/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.0091 - mae: 50.6778 - val_loss: 49.4953 - val_mae: 50.1637\n",
      "Epoch 516/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.7915 - mae: 48.4577 - val_loss: 49.8571 - val_mae: 50.5467\n",
      "Epoch 517/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.0605 - mae: 49.7322 - val_loss: 51.6064 - val_mae: 52.2953\n",
      "Epoch 518/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.2224 - mae: 48.8919 - val_loss: 51.2629 - val_mae: 51.9489\n",
      "Epoch 519/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.9008 - mae: 49.5707 - val_loss: 52.5323 - val_mae: 53.1917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.2666 - mae: 48.9346 - val_loss: 43.5832 - val_mae: 44.2517\n",
      "Epoch 521/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.8679 - mae: 48.5274 - val_loss: 42.0332 - val_mae: 42.6985\n",
      "Epoch 522/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.6600 - mae: 48.3289 - val_loss: 43.2032 - val_mae: 43.8663\n",
      "Epoch 523/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.0089 - mae: 47.6768 - val_loss: 42.3765 - val_mae: 43.0466\n",
      "Epoch 524/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.6313 - mae: 49.3003 - val_loss: 49.1735 - val_mae: 49.8560\n",
      "Epoch 525/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.6106 - mae: 50.2871 - val_loss: 49.2569 - val_mae: 49.9467\n",
      "Epoch 526/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.8295 - mae: 48.4969 - val_loss: 41.4893 - val_mae: 42.1414\n",
      "Epoch 527/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.4419 - mae: 49.1102 - val_loss: 46.1870 - val_mae: 46.8659\n",
      "Epoch 528/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.4404 - mae: 49.1109 - val_loss: 45.5067 - val_mae: 46.1779\n",
      "Epoch 529/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.0039 - mae: 48.6686 - val_loss: 43.8262 - val_mae: 44.5066\n",
      "Epoch 530/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.8961 - mae: 50.5741 - val_loss: 45.5160 - val_mae: 46.1888\n",
      "Epoch 531/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.7278 - mae: 48.3915 - val_loss: 43.4438 - val_mae: 44.1212\n",
      "Epoch 532/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.8962 - mae: 48.5723 - val_loss: 44.3807 - val_mae: 45.0619\n",
      "Epoch 533/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.0460 - mae: 47.7100 - val_loss: 48.7372 - val_mae: 49.4172\n",
      "Epoch 534/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 51.7708 - mae: 52.4490 - val_loss: 42.9414 - val_mae: 43.5971\n",
      "Epoch 535/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.5577 - mae: 49.2288 - val_loss: 46.6569 - val_mae: 47.3458\n",
      "Epoch 536/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.3669 - mae: 50.0357 - val_loss: 41.2608 - val_mae: 41.9194\n",
      "Epoch 537/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.0531 - mae: 47.7249 - val_loss: 45.0258 - val_mae: 45.7067\n",
      "Epoch 538/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.5946 - mae: 50.2684 - val_loss: 44.4466 - val_mae: 45.1264\n",
      "Epoch 539/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.5259 - mae: 48.1982 - val_loss: 41.4927 - val_mae: 42.1551\n",
      "Epoch 540/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.3958 - mae: 47.0590 - val_loss: 41.4721 - val_mae: 42.1293\n",
      "Epoch 541/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.0741 - mae: 47.7439 - val_loss: 43.8625 - val_mae: 44.5149\n",
      "Epoch 542/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.6866 - mae: 47.3489 - val_loss: 46.6501 - val_mae: 47.3195\n",
      "Epoch 543/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.6952 - mae: 49.3671 - val_loss: 42.7135 - val_mae: 43.3698\n",
      "Epoch 544/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.7160 - mae: 48.3818 - val_loss: 43.7939 - val_mae: 44.4789\n",
      "Epoch 545/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.5365 - mae: 47.1983 - val_loss: 44.2895 - val_mae: 44.9702\n",
      "Epoch 546/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.5435 - mae: 48.2119 - val_loss: 40.7880 - val_mae: 41.4444\n",
      "Epoch 547/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.5044 - mae: 47.1714 - val_loss: 44.2012 - val_mae: 44.8568\n",
      "Epoch 548/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.1482 - mae: 48.8093 - val_loss: 43.8822 - val_mae: 44.5435\n",
      "Epoch 549/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.6519 - mae: 48.3141 - val_loss: 49.9823 - val_mae: 50.6699\n",
      "Epoch 550/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.8806 - mae: 49.5514 - val_loss: 45.6899 - val_mae: 46.3776\n",
      "Epoch 551/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.1488 - mae: 48.8206 - val_loss: 44.1690 - val_mae: 44.8283\n",
      "Epoch 552/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.5575 - mae: 49.2325 - val_loss: 45.2243 - val_mae: 45.8952\n",
      "Epoch 553/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.4155 - mae: 49.0833 - val_loss: 48.2802 - val_mae: 48.9681\n",
      "Epoch 554/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.9160 - mae: 51.5932 - val_loss: 42.9235 - val_mae: 43.5782\n",
      "Epoch 555/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.8309 - mae: 49.5004 - val_loss: 42.4869 - val_mae: 43.1658\n",
      "Epoch 556/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.3620 - mae: 48.0320 - val_loss: 43.6510 - val_mae: 44.3208\n",
      "Epoch 557/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.7700 - mae: 47.4354 - val_loss: 48.3612 - val_mae: 49.0460\n",
      "Epoch 558/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.7415 - mae: 48.4090 - val_loss: 48.6762 - val_mae: 49.3589\n",
      "Epoch 559/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.6467 - mae: 50.3240 - val_loss: 40.3510 - val_mae: 41.0001\n",
      "Epoch 560/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.6610 - mae: 48.3361 - val_loss: 41.9336 - val_mae: 42.6026\n",
      "Epoch 561/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.8925 - mae: 47.5635 - val_loss: 41.8815 - val_mae: 42.5612\n",
      "Epoch 562/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.6701 - mae: 47.3385 - val_loss: 41.1000 - val_mae: 41.7621\n",
      "Epoch 563/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.3687 - mae: 47.0298 - val_loss: 44.8643 - val_mae: 45.5320\n",
      "Epoch 564/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9653 - mae: 46.6311 - val_loss: 40.7827 - val_mae: 41.4436\n",
      "Epoch 565/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.2981 - mae: 48.9678 - val_loss: 41.1820 - val_mae: 41.8574\n",
      "Epoch 566/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.6139 - mae: 46.2796 - val_loss: 42.4624 - val_mae: 43.1341\n",
      "Epoch 567/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.9939 - mae: 47.6641 - val_loss: 42.2575 - val_mae: 42.9273\n",
      "Epoch 568/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.0968 - mae: 46.7613 - val_loss: 41.4928 - val_mae: 42.1446\n",
      "Epoch 569/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.9092 - mae: 47.5761 - val_loss: 41.3843 - val_mae: 42.0427\n",
      "Epoch 570/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.3670 - mae: 48.0324 - val_loss: 41.8850 - val_mae: 42.5465\n",
      "Epoch 571/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.4406 - mae: 47.1073 - val_loss: 41.4432 - val_mae: 42.1243\n",
      "Epoch 572/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.4978 - mae: 48.1652 - val_loss: 52.3798 - val_mae: 53.0658\n",
      "Epoch 573/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.3677 - mae: 49.0354 - val_loss: 46.5422 - val_mae: 47.1995\n",
      "Epoch 574/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.8135 - mae: 51.4914 - val_loss: 46.8929 - val_mae: 47.5780\n",
      "Epoch 575/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.8929 - mae: 50.5687 - val_loss: 51.6020 - val_mae: 52.2915\n",
      "Epoch 576/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.0420 - mae: 48.7161 - val_loss: 51.0629 - val_mae: 51.7552\n",
      "Epoch 577/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.7258 - mae: 50.4015 - val_loss: 40.4827 - val_mae: 41.1534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.4510 - mae: 47.1229 - val_loss: 40.6501 - val_mae: 41.3048\n",
      "Epoch 579/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.2418 - mae: 48.9165 - val_loss: 41.2328 - val_mae: 41.8942\n",
      "Epoch 580/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.7822 - mae: 47.4530 - val_loss: 43.1791 - val_mae: 43.8542\n",
      "Epoch 581/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.7312 - mae: 48.4083 - val_loss: 47.0739 - val_mae: 47.7607\n",
      "Epoch 582/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.0264 - mae: 46.6902 - val_loss: 40.5960 - val_mae: 41.2632\n",
      "Epoch 583/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.2826 - mae: 47.9556 - val_loss: 45.3520 - val_mae: 46.0309\n",
      "Epoch 584/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.1442 - mae: 48.8202 - val_loss: 41.1035 - val_mae: 41.7788\n",
      "Epoch 585/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.3803 - mae: 46.0470 - val_loss: 52.2163 - val_mae: 52.8989\n",
      "Epoch 586/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.6694 - mae: 49.3471 - val_loss: 43.3655 - val_mae: 44.0466\n",
      "Epoch 587/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.6887 - mae: 51.3664 - val_loss: 49.9635 - val_mae: 50.6456\n",
      "Epoch 588/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.4294 - mae: 50.1038 - val_loss: 49.9325 - val_mae: 50.6197\n",
      "Epoch 589/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.4401 - mae: 48.1165 - val_loss: 45.0675 - val_mae: 45.7552\n",
      "Epoch 590/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.5563 - mae: 47.2280 - val_loss: 40.6421 - val_mae: 41.3044\n",
      "Epoch 591/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.3393 - mae: 49.0174 - val_loss: 47.1905 - val_mae: 47.8717\n",
      "Epoch 592/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.2600 - mae: 47.9299 - val_loss: 38.9987 - val_mae: 39.6560\n",
      "Epoch 593/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.2415 - mae: 45.9117 - val_loss: 48.4899 - val_mae: 49.1686\n",
      "Epoch 594/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9036 - mae: 46.5710 - val_loss: 40.9439 - val_mae: 41.6022\n",
      "Epoch 595/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.4995 - mae: 48.1712 - val_loss: 41.3020 - val_mae: 41.9666\n",
      "Epoch 596/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.8055 - mae: 47.4698 - val_loss: 44.8745 - val_mae: 45.5550\n",
      "Epoch 597/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.4645 - mae: 47.1350 - val_loss: 48.8967 - val_mae: 49.5841\n",
      "Epoch 598/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.0826 - mae: 47.7518 - val_loss: 39.7719 - val_mae: 40.4350\n",
      "Epoch 599/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.6693 - mae: 48.3397 - val_loss: 39.7482 - val_mae: 40.4089\n",
      "Epoch 600/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.6552 - mae: 47.3258 - val_loss: 40.6342 - val_mae: 41.2972\n",
      "Epoch 601/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.5535 - mae: 47.2222 - val_loss: 38.7819 - val_mae: 39.4401\n",
      "Epoch 602/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.4252 - mae: 47.0914 - val_loss: 40.5947 - val_mae: 41.2396\n",
      "Epoch 603/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.1808 - mae: 45.8510 - val_loss: 39.9925 - val_mae: 40.6595\n",
      "Epoch 604/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9315 - mae: 46.6023 - val_loss: 41.7461 - val_mae: 42.4291\n",
      "Epoch 605/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.1662 - mae: 48.8384 - val_loss: 48.2417 - val_mae: 48.9200\n",
      "Epoch 606/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.2141 - mae: 45.8812 - val_loss: 39.4669 - val_mae: 40.1261\n",
      "Epoch 607/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.4630 - mae: 49.1412 - val_loss: 47.6503 - val_mae: 48.3401\n",
      "Epoch 608/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.8085 - mae: 50.4838 - val_loss: 44.8363 - val_mae: 45.5163\n",
      "Epoch 609/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.7059 - mae: 48.3834 - val_loss: 40.9312 - val_mae: 41.5918\n",
      "Epoch 610/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.5323 - mae: 49.2065 - val_loss: 39.3696 - val_mae: 40.0206\n",
      "Epoch 611/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9318 - mae: 45.6008 - val_loss: 45.6619 - val_mae: 46.3246\n",
      "Epoch 612/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.6907 - mae: 47.3547 - val_loss: 40.0293 - val_mae: 40.6980\n",
      "Epoch 613/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.7381 - mae: 46.4027 - val_loss: 39.3799 - val_mae: 40.0409\n",
      "Epoch 614/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.7396 - mae: 46.3983 - val_loss: 39.7998 - val_mae: 40.4706\n",
      "Epoch 615/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.2290 - mae: 48.8994 - val_loss: 40.7647 - val_mae: 41.4389\n",
      "Epoch 616/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.5018 - mae: 47.1731 - val_loss: 42.0727 - val_mae: 42.7613\n",
      "Epoch 617/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.8691 - mae: 46.5403 - val_loss: 40.5864 - val_mae: 41.2624\n",
      "Epoch 618/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.8560 - mae: 47.5286 - val_loss: 44.5393 - val_mae: 45.2290\n",
      "Epoch 619/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.1218 - mae: 49.8004 - val_loss: 42.8844 - val_mae: 43.5530\n",
      "Epoch 620/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9633 - mae: 46.6356 - val_loss: 39.1031 - val_mae: 39.7567\n",
      "Epoch 621/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9446 - mae: 45.6111 - val_loss: 42.0986 - val_mae: 42.7790\n",
      "Epoch 622/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.5886 - mae: 49.2704 - val_loss: 39.8939 - val_mae: 40.5645\n",
      "Epoch 623/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.7465 - mae: 45.4154 - val_loss: 42.9923 - val_mae: 43.6784\n",
      "Epoch 624/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.1887 - mae: 46.8610 - val_loss: 42.9124 - val_mae: 43.5663\n",
      "Epoch 625/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.8133 - mae: 47.4897 - val_loss: 40.3403 - val_mae: 41.0112\n",
      "Epoch 626/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9185 - mae: 45.5874 - val_loss: 40.4474 - val_mae: 41.1243\n",
      "Epoch 627/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.6757 - mae: 46.3436 - val_loss: 40.8346 - val_mae: 41.5170\n",
      "Epoch 628/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.3278 - mae: 44.9922 - val_loss: 39.0997 - val_mae: 39.7523\n",
      "Epoch 629/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.8113 - mae: 47.4826 - val_loss: 49.0493 - val_mae: 49.7302\n",
      "Epoch 630/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.7938 - mae: 47.4661 - val_loss: 39.4059 - val_mae: 40.0572\n",
      "Epoch 631/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.3306 - mae: 45.9994 - val_loss: 46.1793 - val_mae: 46.8680\n",
      "Epoch 632/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.9756 - mae: 48.6507 - val_loss: 40.4282 - val_mae: 41.1095\n",
      "Epoch 633/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.3233 - mae: 44.9893 - val_loss: 42.2007 - val_mae: 42.8819\n",
      "Epoch 634/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.8640 - mae: 47.5357 - val_loss: 40.4490 - val_mae: 41.1284\n",
      "Epoch 635/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.1960 - mae: 46.8627 - val_loss: 45.9042 - val_mae: 46.5547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.4653 - mae: 47.1412 - val_loss: 47.4771 - val_mae: 48.1658\n",
      "Epoch 637/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.4443 - mae: 48.1212 - val_loss: 38.7390 - val_mae: 39.4070\n",
      "Epoch 638/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.1919 - mae: 44.8562 - val_loss: 38.9221 - val_mae: 39.5926\n",
      "Epoch 639/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.7656 - mae: 45.4346 - val_loss: 54.4843 - val_mae: 55.1711\n",
      "Epoch 640/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.6929 - mae: 47.3684 - val_loss: 40.8752 - val_mae: 41.5543\n",
      "Epoch 641/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.4003 - mae: 47.0795 - val_loss: 41.8466 - val_mae: 42.5063\n",
      "Epoch 642/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.6784 - mae: 44.3413 - val_loss: 39.9965 - val_mae: 40.6536\n",
      "Epoch 643/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.0210 - mae: 45.6919 - val_loss: 42.7363 - val_mae: 43.4179\n",
      "Epoch 644/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.1459 - mae: 44.8160 - val_loss: 44.0988 - val_mae: 44.7856\n",
      "Epoch 645/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.5289 - mae: 46.2027 - val_loss: 42.5678 - val_mae: 43.2513\n",
      "Epoch 646/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9161 - mae: 46.5876 - val_loss: 41.2650 - val_mae: 41.9402\n",
      "Epoch 647/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.4645 - mae: 45.1327 - val_loss: 40.5324 - val_mae: 41.2036\n",
      "Epoch 648/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.6726 - mae: 47.3474 - val_loss: 46.8663 - val_mae: 47.5449\n",
      "Epoch 649/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.6284 - mae: 44.2860 - val_loss: 41.0881 - val_mae: 41.7509\n",
      "Epoch 650/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 49.1786 - mae: 49.8601 - val_loss: 39.6912 - val_mae: 40.3466\n",
      "Epoch 651/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.6052 - mae: 46.2778 - val_loss: 40.2037 - val_mae: 40.8835\n",
      "Epoch 652/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.3643 - mae: 47.0419 - val_loss: 40.7335 - val_mae: 41.4078\n",
      "Epoch 653/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.2851 - mae: 45.9578 - val_loss: 45.3117 - val_mae: 45.9690\n",
      "Epoch 654/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.5411 - mae: 46.2112 - val_loss: 38.3831 - val_mae: 39.0434\n",
      "Epoch 655/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.3011 - mae: 43.9612 - val_loss: 38.9933 - val_mae: 39.6522\n",
      "Epoch 656/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.7438 - mae: 45.4072 - val_loss: 37.8532 - val_mae: 38.5072\n",
      "Epoch 657/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.6794 - mae: 46.3508 - val_loss: 40.3861 - val_mae: 41.0674\n",
      "Epoch 658/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.3080 - mae: 46.9850 - val_loss: 43.0244 - val_mae: 43.7134\n",
      "Epoch 659/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.2425 - mae: 45.9127 - val_loss: 42.6552 - val_mae: 43.3133\n",
      "Epoch 660/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.5239 - mae: 47.1942 - val_loss: 50.4214 - val_mae: 51.1110\n",
      "Epoch 661/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.6538 - mae: 48.3317 - val_loss: 37.9250 - val_mae: 38.5884\n",
      "Epoch 662/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.1796 - mae: 44.8468 - val_loss: 45.9856 - val_mae: 46.6714\n",
      "Epoch 663/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.1547 - mae: 45.8216 - val_loss: 40.1390 - val_mae: 40.7952\n",
      "Epoch 664/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.9213 - mae: 47.5981 - val_loss: 48.6670 - val_mae: 49.3455\n",
      "Epoch 665/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.6430 - mae: 48.3183 - val_loss: 47.4434 - val_mae: 48.1246\n",
      "Epoch 666/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9916 - mae: 45.6552 - val_loss: 38.5552 - val_mae: 39.2320\n",
      "Epoch 667/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.7321 - mae: 45.3954 - val_loss: 42.0618 - val_mae: 42.7448\n",
      "Epoch 668/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.6090 - mae: 47.2862 - val_loss: 37.4885 - val_mae: 38.1472\n",
      "Epoch 669/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5791 - mae: 44.2414 - val_loss: 42.1332 - val_mae: 42.8125\n",
      "Epoch 670/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.2761 - mae: 43.9403 - val_loss: 42.1588 - val_mae: 42.8161\n",
      "Epoch 671/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5858 - mae: 44.2440 - val_loss: 40.8203 - val_mae: 41.4907\n",
      "Epoch 672/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.7512 - mae: 43.4117 - val_loss: 41.2392 - val_mae: 41.9212\n",
      "Epoch 673/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.0880 - mae: 46.7624 - val_loss: 43.7070 - val_mae: 44.3972\n",
      "Epoch 674/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.5826 - mae: 46.2501 - val_loss: 38.7301 - val_mae: 39.4007\n",
      "Epoch 675/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.3646 - mae: 45.0321 - val_loss: 47.1392 - val_mae: 47.8247\n",
      "Epoch 676/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.0674 - mae: 46.7388 - val_loss: 44.4620 - val_mae: 45.1489\n",
      "Epoch 677/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.8894 - mae: 45.5617 - val_loss: 43.1897 - val_mae: 43.8744\n",
      "Epoch 678/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.2049 - mae: 47.8826 - val_loss: 41.5136 - val_mae: 42.1989\n",
      "Epoch 679/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.7879 - mae: 44.4570 - val_loss: 42.4648 - val_mae: 43.1531\n",
      "Epoch 680/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.8047 - mae: 44.4689 - val_loss: 39.7912 - val_mae: 40.4695\n",
      "Epoch 681/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.4569 - mae: 45.1279 - val_loss: 42.9653 - val_mae: 43.6468\n",
      "Epoch 682/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.4633 - mae: 45.1336 - val_loss: 46.4095 - val_mae: 47.0970\n",
      "Epoch 683/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9753 - mae: 45.6516 - val_loss: 37.7891 - val_mae: 38.4499\n",
      "Epoch 684/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.3900 - mae: 49.0673 - val_loss: 40.9312 - val_mae: 41.6102\n",
      "Epoch 685/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.6247 - mae: 45.2968 - val_loss: 44.6706 - val_mae: 45.3559\n",
      "Epoch 686/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.0336 - mae: 46.7122 - val_loss: 41.4301 - val_mae: 42.1129\n",
      "Epoch 687/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9044 - mae: 45.5819 - val_loss: 41.0591 - val_mae: 41.7435\n",
      "Epoch 688/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9838 - mae: 46.6580 - val_loss: 43.6279 - val_mae: 44.3122\n",
      "Epoch 689/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.4540 - mae: 47.1319 - val_loss: 37.0555 - val_mae: 37.7150\n",
      "Epoch 690/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1726 - mae: 43.8329 - val_loss: 41.6395 - val_mae: 42.2942\n",
      "Epoch 691/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.8757 - mae: 46.5384 - val_loss: 40.6331 - val_mae: 41.3065\n",
      "Epoch 692/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.3911 - mae: 45.0638 - val_loss: 37.6404 - val_mae: 38.3000\n",
      "Epoch 693/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.2344 - mae: 43.8965 - val_loss: 38.7559 - val_mae: 39.4351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.0787 - mae: 46.7534 - val_loss: 40.6863 - val_mae: 41.3669\n",
      "Epoch 695/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.4064 - mae: 44.0736 - val_loss: 37.9251 - val_mae: 38.5955\n",
      "Epoch 696/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 43.7342 - mae: 44.4002 - val_loss: 54.5090 - val_mae: 55.1888\n",
      "Epoch 697/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 50.1996 - mae: 50.8827 - val_loss: 45.7916 - val_mae: 46.4812\n",
      "Epoch 698/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.3376 - mae: 42.9972 - val_loss: 39.9008 - val_mae: 40.5793\n",
      "Epoch 699/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1285 - mae: 43.7972 - val_loss: 37.4345 - val_mae: 38.1075\n",
      "Epoch 700/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.9801 - mae: 44.6551 - val_loss: 40.2816 - val_mae: 40.9386\n",
      "Epoch 701/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 43.9189 - mae: 44.5814 - val_loss: 38.1071 - val_mae: 38.7686\n",
      "Epoch 702/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6155 - mae: 43.2810 - val_loss: 40.0224 - val_mae: 40.6891\n",
      "Epoch 703/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6443 - mae: 43.3021 - val_loss: 36.9906 - val_mae: 37.6420\n",
      "Epoch 704/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.1330 - mae: 42.7958 - val_loss: 39.7827 - val_mae: 40.4480\n",
      "Epoch 705/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9217 - mae: 46.5965 - val_loss: 46.0095 - val_mae: 46.6689\n",
      "Epoch 706/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 48.0464 - mae: 48.7291 - val_loss: 37.3869 - val_mae: 38.0417\n",
      "Epoch 707/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5734 - mae: 43.2374 - val_loss: 37.3774 - val_mae: 38.0347\n",
      "Epoch 708/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.3952 - mae: 45.0656 - val_loss: 41.7878 - val_mae: 42.4676\n",
      "Epoch 709/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.1539 - mae: 44.8230 - val_loss: 37.7636 - val_mae: 38.4230\n",
      "Epoch 710/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.7738 - mae: 45.4449 - val_loss: 36.6941 - val_mae: 37.3518\n",
      "Epoch 711/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1015 - mae: 43.7698 - val_loss: 37.0901 - val_mae: 37.7509\n",
      "Epoch 712/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.2112 - mae: 42.8694 - val_loss: 36.4707 - val_mae: 37.1268\n",
      "Epoch 713/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.8207 - mae: 44.4942 - val_loss: 37.2244 - val_mae: 37.8707\n",
      "Epoch 714/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0997 - mae: 42.7585 - val_loss: 37.7134 - val_mae: 38.3830\n",
      "Epoch 715/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6448 - mae: 43.3177 - val_loss: 40.3300 - val_mae: 41.0175\n",
      "Epoch 716/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1474 - mae: 43.8070 - val_loss: 40.2889 - val_mae: 40.9443\n",
      "Epoch 717/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.0358 - mae: 44.7041 - val_loss: 46.3092 - val_mae: 46.9789\n",
      "Epoch 718/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.3744 - mae: 47.0470 - val_loss: 43.0646 - val_mae: 43.7358\n",
      "Epoch 719/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9084 - mae: 46.5835 - val_loss: 37.8223 - val_mae: 38.5015\n",
      "Epoch 720/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.6020 - mae: 45.2795 - val_loss: 38.0588 - val_mae: 38.7280\n",
      "Epoch 721/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5351 - mae: 44.2026 - val_loss: 39.4903 - val_mae: 40.1734\n",
      "Epoch 722/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.2798 - mae: 44.9543 - val_loss: 44.0615 - val_mae: 44.7487\n",
      "Epoch 723/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.5328 - mae: 45.2033 - val_loss: 42.6828 - val_mae: 43.3432\n",
      "Epoch 724/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.5224 - mae: 45.1928 - val_loss: 43.7870 - val_mae: 44.4770\n",
      "Epoch 725/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.2625 - mae: 44.9392 - val_loss: 36.9669 - val_mae: 37.6210\n",
      "Epoch 726/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.0554 - mae: 44.7253 - val_loss: 41.0082 - val_mae: 41.6835\n",
      "Epoch 727/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.3694 - mae: 46.0476 - val_loss: 46.0294 - val_mae: 46.7074\n",
      "Epoch 728/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.0238 - mae: 46.7038 - val_loss: 50.3633 - val_mae: 51.0439\n",
      "Epoch 729/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.8137 - mae: 44.4833 - val_loss: 37.1180 - val_mae: 37.7817\n",
      "Epoch 730/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.8220 - mae: 45.4945 - val_loss: 39.0645 - val_mae: 39.7432\n",
      "Epoch 731/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.9112 - mae: 42.5700 - val_loss: 37.8634 - val_mae: 38.5118\n",
      "Epoch 732/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.6166 - mae: 44.2865 - val_loss: 37.4794 - val_mae: 38.1470\n",
      "Epoch 733/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6403 - mae: 43.3085 - val_loss: 36.6643 - val_mae: 37.3202\n",
      "Epoch 734/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.0048 - mae: 44.6794 - val_loss: 47.6676 - val_mae: 48.3590\n",
      "Epoch 735/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.8826 - mae: 43.5462 - val_loss: 37.8101 - val_mae: 38.4681\n",
      "Epoch 736/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.9518 - mae: 43.6206 - val_loss: 39.9680 - val_mae: 40.6480\n",
      "Epoch 737/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.9916 - mae: 46.6647 - val_loss: 39.8826 - val_mae: 40.5502\n",
      "Epoch 738/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.4696 - mae: 44.1436 - val_loss: 46.4777 - val_mae: 47.1593\n",
      "Epoch 739/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.4913 - mae: 44.1606 - val_loss: 36.7851 - val_mae: 37.4327\n",
      "Epoch 740/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.9749 - mae: 43.6481 - val_loss: 36.9931 - val_mae: 37.6589\n",
      "Epoch 741/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.6666 - mae: 44.3390 - val_loss: 41.0406 - val_mae: 41.7119\n",
      "Epoch 742/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5942 - mae: 44.2642 - val_loss: 40.8339 - val_mae: 41.5055\n",
      "Epoch 743/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.6468 - mae: 44.3198 - val_loss: 37.5422 - val_mae: 38.2125\n",
      "Epoch 744/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9660 - mae: 45.6410 - val_loss: 37.4789 - val_mae: 38.1529\n",
      "Epoch 745/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.7959 - mae: 42.4586 - val_loss: 36.2969 - val_mae: 36.9470\n",
      "Epoch 746/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.4049 - mae: 48.0797 - val_loss: 38.1575 - val_mae: 38.8359\n",
      "Epoch 747/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5737 - mae: 43.2346 - val_loss: 36.2530 - val_mae: 36.9042\n",
      "Epoch 748/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.0254 - mae: 44.7007 - val_loss: 53.6054 - val_mae: 54.2947\n",
      "Epoch 749/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.7597 - mae: 45.4350 - val_loss: 36.4695 - val_mae: 37.1224\n",
      "Epoch 750/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.9451 - mae: 44.6216 - val_loss: 42.4551 - val_mae: 43.1407\n",
      "Epoch 751/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0774 - mae: 42.7413 - val_loss: 36.4291 - val_mae: 37.0960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 752/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9307 - mae: 45.6041 - val_loss: 38.3367 - val_mae: 39.0185\n",
      "Epoch 753/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.2367 - mae: 42.9037 - val_loss: 40.4201 - val_mae: 41.1046\n",
      "Epoch 754/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.7508 - mae: 42.4191 - val_loss: 42.1592 - val_mae: 42.8478\n",
      "Epoch 755/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.0403 - mae: 43.7089 - val_loss: 37.5503 - val_mae: 38.2007\n",
      "Epoch 756/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1961 - mae: 43.8647 - val_loss: 42.1782 - val_mae: 42.8608\n",
      "Epoch 757/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6054 - mae: 43.2655 - val_loss: 36.1692 - val_mae: 36.8350\n",
      "Epoch 758/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.3288 - mae: 43.9971 - val_loss: 37.3099 - val_mae: 37.9878\n",
      "Epoch 759/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.1885 - mae: 45.8659 - val_loss: 41.6365 - val_mae: 42.3254\n",
      "Epoch 760/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6451 - mae: 43.3111 - val_loss: 37.9934 - val_mae: 38.6419\n",
      "Epoch 761/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 46.7402 - mae: 47.4193 - val_loss: 47.1296 - val_mae: 47.7772\n",
      "Epoch 762/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5555 - mae: 44.2221 - val_loss: 44.7521 - val_mae: 45.4412\n",
      "Epoch 763/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.3006 - mae: 43.9720 - val_loss: 36.8251 - val_mae: 37.4830\n",
      "Epoch 764/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.6367 - mae: 45.3103 - val_loss: 37.7618 - val_mae: 38.4387\n",
      "Epoch 765/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5869 - mae: 43.2526 - val_loss: 36.3564 - val_mae: 37.0090\n",
      "Epoch 766/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.9696 - mae: 43.6406 - val_loss: 41.7777 - val_mae: 42.4634\n",
      "Epoch 767/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.9801 - mae: 43.6493 - val_loss: 42.5951 - val_mae: 43.2780\n",
      "Epoch 768/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.4237 - mae: 42.0875 - val_loss: 37.0499 - val_mae: 37.7219\n",
      "Epoch 769/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.1504 - mae: 45.8191 - val_loss: 43.2281 - val_mae: 43.9145\n",
      "Epoch 770/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.8386 - mae: 45.5129 - val_loss: 43.0794 - val_mae: 43.7676\n",
      "Epoch 771/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.4897 - mae: 43.1553 - val_loss: 47.0173 - val_mae: 47.7078\n",
      "Epoch 772/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5032 - mae: 44.1783 - val_loss: 37.3619 - val_mae: 38.0363\n",
      "Epoch 773/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5808 - mae: 44.2536 - val_loss: 41.7042 - val_mae: 42.3882\n",
      "Epoch 774/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.2549 - mae: 43.9249 - val_loss: 38.2163 - val_mae: 38.8892\n",
      "Epoch 775/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.1485 - mae: 42.8173 - val_loss: 41.8379 - val_mae: 42.5248\n",
      "Epoch 776/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6573 - mae: 43.3287 - val_loss: 39.3938 - val_mae: 40.0555\n",
      "Epoch 777/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.5475 - mae: 42.2118 - val_loss: 38.3453 - val_mae: 39.0079\n",
      "Epoch 778/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.3138 - mae: 43.9847 - val_loss: 38.3311 - val_mae: 39.0108\n",
      "Epoch 779/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.9433 - mae: 43.6147 - val_loss: 43.4383 - val_mae: 44.1280\n",
      "Epoch 780/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.1573 - mae: 42.8218 - val_loss: 47.7813 - val_mae: 48.4420\n",
      "Epoch 781/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9137 - mae: 45.5908 - val_loss: 46.6809 - val_mae: 47.3634\n",
      "Epoch 782/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.3410 - mae: 45.0116 - val_loss: 38.4780 - val_mae: 39.1359\n",
      "Epoch 783/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0620 - mae: 42.7330 - val_loss: 38.7839 - val_mae: 39.4627\n",
      "Epoch 784/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5769 - mae: 43.2477 - val_loss: 37.3280 - val_mae: 37.9985\n",
      "Epoch 785/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.7397 - mae: 43.4116 - val_loss: 45.7199 - val_mae: 46.3911\n",
      "Epoch 786/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.8698 - mae: 44.5439 - val_loss: 39.2977 - val_mae: 39.9819\n",
      "Epoch 787/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.9255 - mae: 44.5991 - val_loss: 47.4210 - val_mae: 48.0955\n",
      "Epoch 788/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.1730 - mae: 42.8383 - val_loss: 44.6095 - val_mae: 45.2892\n",
      "Epoch 789/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.4729 - mae: 42.1409 - val_loss: 40.0544 - val_mae: 40.7211\n",
      "Epoch 790/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.8169 - mae: 41.4752 - val_loss: 38.7147 - val_mae: 39.3924\n",
      "Epoch 791/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.0567 - mae: 41.7185 - val_loss: 37.6051 - val_mae: 38.2507\n",
      "Epoch 792/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.5875 - mae: 46.2613 - val_loss: 42.0870 - val_mae: 42.7641\n",
      "Epoch 793/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.4189 - mae: 43.0891 - val_loss: 39.0073 - val_mae: 39.6916\n",
      "Epoch 794/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5748 - mae: 43.2489 - val_loss: 36.5643 - val_mae: 37.2407\n",
      "Epoch 795/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.2740 - mae: 42.9408 - val_loss: 36.3472 - val_mae: 36.9948\n",
      "Epoch 796/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.6847 - mae: 46.3638 - val_loss: 46.6103 - val_mae: 47.2983\n",
      "Epoch 797/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.0710 - mae: 43.7459 - val_loss: 37.9610 - val_mae: 38.6367\n",
      "Epoch 798/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.0446 - mae: 43.7139 - val_loss: 38.5301 - val_mae: 39.2165\n",
      "Epoch 799/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.2104 - mae: 41.8761 - val_loss: 36.4411 - val_mae: 37.1008\n",
      "Epoch 800/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6239 - mae: 43.2996 - val_loss: 37.5596 - val_mae: 38.2403\n",
      "Epoch 801/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5790 - mae: 43.2447 - val_loss: 41.2690 - val_mae: 41.9310\n",
      "Epoch 802/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5044 - mae: 44.1706 - val_loss: 36.5214 - val_mae: 37.1884\n",
      "Epoch 803/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.4830 - mae: 43.1520 - val_loss: 45.0038 - val_mae: 45.6844\n",
      "Epoch 804/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.9908 - mae: 43.6640 - val_loss: 36.4858 - val_mae: 37.1578\n",
      "Epoch 805/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1036 - mae: 43.7766 - val_loss: 36.3773 - val_mae: 37.0501\n",
      "Epoch 806/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.6855 - mae: 44.3575 - val_loss: 48.8865 - val_mae: 49.5759\n",
      "Epoch 807/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9845 - mae: 45.6601 - val_loss: 38.1297 - val_mae: 38.8069\n",
      "Epoch 808/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.0706 - mae: 43.7453 - val_loss: 46.0548 - val_mae: 46.7431\n",
      "Epoch 809/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.9527 - mae: 44.6290 - val_loss: 39.9422 - val_mae: 40.6279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 810/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.1079 - mae: 41.7738 - val_loss: 35.8458 - val_mae: 36.5008\n",
      "Epoch 811/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.8184 - mae: 43.4885 - val_loss: 35.3052 - val_mae: 35.9620\n",
      "Epoch 812/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 41.9522 - mae: 42.6164 - val_loss: 38.1482 - val_mae: 38.8078\n",
      "Epoch 813/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.8787 - mae: 42.5464 - val_loss: 39.7933 - val_mae: 40.4773\n",
      "Epoch 814/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5391 - mae: 44.2113 - val_loss: 36.7511 - val_mae: 37.4226\n",
      "Epoch 815/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.9824 - mae: 41.6444 - val_loss: 35.0550 - val_mae: 35.7160\n",
      "Epoch 816/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.4116 - mae: 42.0738 - val_loss: 40.7415 - val_mae: 41.4280\n",
      "Epoch 817/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.7533 - mae: 44.4249 - val_loss: 35.5227 - val_mae: 36.1804\n",
      "Epoch 818/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.9182 - mae: 42.5844 - val_loss: 37.6252 - val_mae: 38.2941\n",
      "Epoch 819/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.3777 - mae: 44.0471 - val_loss: 39.7902 - val_mae: 40.4777\n",
      "Epoch 820/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.7109 - mae: 43.3847 - val_loss: 38.7216 - val_mae: 39.4044\n",
      "Epoch 821/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.8537 - mae: 43.5240 - val_loss: 36.8643 - val_mae: 37.5383\n",
      "Epoch 822/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.1767 - mae: 40.8338 - val_loss: 36.0337 - val_mae: 36.7109\n",
      "Epoch 823/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.9104 - mae: 42.5795 - val_loss: 41.9148 - val_mae: 42.6048\n",
      "Epoch 824/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 45.0807 - mae: 45.7594 - val_loss: 39.0298 - val_mae: 39.7182\n",
      "Epoch 825/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.1324 - mae: 41.7957 - val_loss: 35.8967 - val_mae: 36.5660\n",
      "Epoch 826/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.7083 - mae: 41.3713 - val_loss: 39.6983 - val_mae: 40.3789\n",
      "Epoch 827/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.7062 - mae: 44.3828 - val_loss: 35.9127 - val_mae: 36.5632\n",
      "Epoch 828/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.3715 - mae: 43.0431 - val_loss: 42.0801 - val_mae: 42.7697\n",
      "Epoch 829/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9722 - mae: 45.6505 - val_loss: 43.8340 - val_mae: 44.5224\n",
      "Epoch 830/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.9454 - mae: 42.6151 - val_loss: 51.9375 - val_mae: 52.6226\n",
      "Epoch 831/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.3844 - mae: 43.0558 - val_loss: 38.7301 - val_mae: 39.4127\n",
      "Epoch 832/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5881 - mae: 43.2636 - val_loss: 35.5015 - val_mae: 36.1605\n",
      "Epoch 833/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.4643 - mae: 42.1320 - val_loss: 37.3491 - val_mae: 38.0173\n",
      "Epoch 834/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.3163 - mae: 41.9822 - val_loss: 37.6121 - val_mae: 38.2903\n",
      "Epoch 835/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.2629 - mae: 43.9347 - val_loss: 39.1124 - val_mae: 39.7847\n",
      "Epoch 836/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.9451 - mae: 41.6105 - val_loss: 41.4954 - val_mae: 42.1517\n",
      "Epoch 837/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.6881 - mae: 44.3617 - val_loss: 35.5838 - val_mae: 36.2348\n",
      "Epoch 838/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5838 - mae: 43.2555 - val_loss: 37.3381 - val_mae: 38.0144\n",
      "Epoch 839/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.5023 - mae: 41.1681 - val_loss: 43.7180 - val_mae: 44.3983\n",
      "Epoch 840/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.8546 - mae: 42.5245 - val_loss: 36.5791 - val_mae: 37.2508\n",
      "Epoch 841/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6819 - mae: 43.3535 - val_loss: 35.4838 - val_mae: 36.1484\n",
      "Epoch 842/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.9908 - mae: 42.6573 - val_loss: 36.8711 - val_mae: 37.5397\n",
      "Epoch 843/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.4355 - mae: 41.1006 - val_loss: 36.9344 - val_mae: 37.6104\n",
      "Epoch 844/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.2665 - mae: 41.9359 - val_loss: 38.1905 - val_mae: 38.8462\n",
      "Epoch 845/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.9550 - mae: 42.6254 - val_loss: 42.5573 - val_mae: 43.2253\n",
      "Epoch 846/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.5744 - mae: 42.2396 - val_loss: 48.3423 - val_mae: 49.0056\n",
      "Epoch 847/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.4323 - mae: 44.1083 - val_loss: 35.5813 - val_mae: 36.2492\n",
      "Epoch 848/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.7824 - mae: 44.4560 - val_loss: 39.1468 - val_mae: 39.8336\n",
      "Epoch 849/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.0960 - mae: 43.7735 - val_loss: 36.8497 - val_mae: 37.5136\n",
      "Epoch 850/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.8529 - mae: 42.5248 - val_loss: 35.6866 - val_mae: 36.3441\n",
      "Epoch 851/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.0522 - mae: 44.7187 - val_loss: 43.5573 - val_mae: 44.2478\n",
      "Epoch 852/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.0166 - mae: 43.6916 - val_loss: 35.7816 - val_mae: 36.4338\n",
      "Epoch 853/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.5651 - mae: 42.2321 - val_loss: 41.8121 - val_mae: 42.4714\n",
      "Epoch 854/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1972 - mae: 43.8724 - val_loss: 35.2925 - val_mae: 35.9608\n",
      "Epoch 855/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.3566 - mae: 42.0217 - val_loss: 38.9218 - val_mae: 39.5672\n",
      "Epoch 856/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.3360 - mae: 43.0020 - val_loss: 40.6280 - val_mae: 41.2890\n",
      "Epoch 857/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5656 - mae: 44.2355 - val_loss: 36.3973 - val_mae: 37.0667\n",
      "Epoch 858/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.1699 - mae: 43.8420 - val_loss: 43.8437 - val_mae: 44.5321\n",
      "Epoch 859/5000\n",
      "1972/1972 [==============================] - 5s 2ms/step - loss: 48.2015 - mae: 48.8834 - val_loss: 38.1713 - val_mae: 38.8517\n",
      "Epoch 860/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5318 - mae: 43.2027 - val_loss: 35.9597 - val_mae: 36.6075\n",
      "Epoch 861/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.4750 - mae: 43.1445 - val_loss: 39.2622 - val_mae: 39.9478\n",
      "Epoch 862/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.3979 - mae: 43.0689 - val_loss: 35.7701 - val_mae: 36.4320\n",
      "Epoch 863/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.4264 - mae: 43.0950 - val_loss: 37.2293 - val_mae: 37.8843\n",
      "Epoch 864/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 39.7801 - mae: 40.4390 - val_loss: 37.7458 - val_mae: 38.4066\n",
      "Epoch 865/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.7371 - mae: 45.4143 - val_loss: 35.9397 - val_mae: 36.6050\n",
      "Epoch 866/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.2141 - mae: 40.8742 - val_loss: 39.8622 - val_mae: 40.5174\n",
      "Epoch 867/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.1886 - mae: 44.8661 - val_loss: 37.1957 - val_mae: 37.8791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.6397 - mae: 42.3028 - val_loss: 43.8004 - val_mae: 44.4782\n",
      "Epoch 869/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.5863 - mae: 44.2588 - val_loss: 37.6535 - val_mae: 38.3201\n",
      "Epoch 870/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0083 - mae: 42.6714 - val_loss: 37.2240 - val_mae: 37.9068\n",
      "Epoch 871/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.3013 - mae: 42.9706 - val_loss: 35.8164 - val_mae: 36.4836\n",
      "Epoch 872/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.7534 - mae: 42.4284 - val_loss: 35.0614 - val_mae: 35.7259\n",
      "Epoch 873/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.7894 - mae: 42.4600 - val_loss: 37.0938 - val_mae: 37.7483\n",
      "Epoch 874/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9300 - mae: 45.6035 - val_loss: 37.2859 - val_mae: 37.9617\n",
      "Epoch 875/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.7669 - mae: 42.4326 - val_loss: 39.5391 - val_mae: 40.2129\n",
      "Epoch 876/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.9927 - mae: 44.6698 - val_loss: 37.5530 - val_mae: 38.2043\n",
      "Epoch 877/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 44.9392 - mae: 45.6166 - val_loss: 39.7421 - val_mae: 40.4197\n",
      "Epoch 878/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.9312 - mae: 41.6008 - val_loss: 37.9206 - val_mae: 38.5791\n",
      "Epoch 879/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.0707 - mae: 41.7397 - val_loss: 41.2769 - val_mae: 41.9632\n",
      "Epoch 880/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.0568 - mae: 41.7284 - val_loss: 36.5201 - val_mae: 37.1686\n",
      "Epoch 881/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.9570 - mae: 43.6261 - val_loss: 38.6069 - val_mae: 39.2792\n",
      "Epoch 882/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.4273 - mae: 43.1022 - val_loss: 37.1000 - val_mae: 37.7783\n",
      "Epoch 883/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.0075 - mae: 41.6737 - val_loss: 40.6871 - val_mae: 41.3688\n",
      "Epoch 884/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0070 - mae: 42.6820 - val_loss: 35.3170 - val_mae: 35.9787\n",
      "Epoch 885/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.9122 - mae: 41.5801 - val_loss: 35.6969 - val_mae: 36.3602\n",
      "Epoch 886/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.2595 - mae: 41.9289 - val_loss: 36.6113 - val_mae: 37.2614\n",
      "Epoch 887/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.6331 - mae: 42.3065 - val_loss: 36.1333 - val_mae: 36.7954\n",
      "Epoch 888/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 39.8668 - mae: 40.5272 - val_loss: 35.7685 - val_mae: 36.4204\n",
      "Epoch 889/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.8497 - mae: 41.5134 - val_loss: 41.1121 - val_mae: 41.7986\n",
      "Epoch 890/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.9364 - mae: 41.6066 - val_loss: 35.2641 - val_mae: 35.9132\n",
      "Epoch 891/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.7154 - mae: 42.3806 - val_loss: 36.5394 - val_mae: 37.2053\n",
      "Epoch 892/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.0200 - mae: 41.6883 - val_loss: 39.4016 - val_mae: 40.0848\n",
      "Epoch 893/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.6552 - mae: 41.3215 - val_loss: 39.8634 - val_mae: 40.5402\n",
      "Epoch 894/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.7410 - mae: 41.4054 - val_loss: 35.3119 - val_mae: 35.9648\n",
      "Epoch 895/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.0247 - mae: 40.6910 - val_loss: 35.1329 - val_mae: 35.7849\n",
      "Epoch 896/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 39.8078 - mae: 40.4717 - val_loss: 40.0586 - val_mae: 40.7470\n",
      "Epoch 897/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.4072 - mae: 42.0805 - val_loss: 36.5827 - val_mae: 37.2434\n",
      "Epoch 898/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0563 - mae: 42.7251 - val_loss: 39.1206 - val_mae: 39.8065\n",
      "Epoch 899/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 39.6087 - mae: 40.2664 - val_loss: 37.2162 - val_mae: 37.9016\n",
      "Epoch 900/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 40.7748 - mae: 41.4405 - val_loss: 39.1863 - val_mae: 39.8611\n",
      "Epoch 901/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.0676 - mae: 41.7374 - val_loss: 35.7511 - val_mae: 36.4208\n",
      "Epoch 902/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.8604 - mae: 44.5411 - val_loss: 43.0433 - val_mae: 43.7234\n",
      "Epoch 903/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.3237 - mae: 42.9940 - val_loss: 38.2036 - val_mae: 38.8767\n",
      "Epoch 904/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0444 - mae: 42.7114 - val_loss: 36.5773 - val_mae: 37.2443\n",
      "Epoch 905/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.2370 - mae: 41.9066 - val_loss: 35.9599 - val_mae: 36.6140\n",
      "Epoch 906/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.2072 - mae: 43.8789 - val_loss: 35.3767 - val_mae: 36.0420\n",
      "Epoch 907/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 47.8769 - mae: 48.5602 - val_loss: 48.1060 - val_mae: 48.7966\n",
      "Epoch 908/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.9582 - mae: 42.6321 - val_loss: 35.1930 - val_mae: 35.8465\n",
      "Epoch 909/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.1144 - mae: 42.7850 - val_loss: 40.6391 - val_mae: 41.3250\n",
      "Epoch 910/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 43.3219 - mae: 43.9979 - val_loss: 38.0373 - val_mae: 38.6974\n",
      "Epoch 911/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.6556 - mae: 43.3280 - val_loss: 40.6080 - val_mae: 41.2801\n",
      "Epoch 912/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.5286 - mae: 43.1938 - val_loss: 40.2074 - val_mae: 40.8910\n",
      "Epoch 913/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.2134 - mae: 41.8808 - val_loss: 35.1470 - val_mae: 35.8097\n",
      "Epoch 914/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 41.8522 - mae: 42.5232 - val_loss: 41.1854 - val_mae: 41.8759\n",
      "Epoch 915/5000\n",
      "1972/1972 [==============================] - 4s 2ms/step - loss: 42.0169 - mae: 42.6944 - val_loss: 35.1186 - val_mae: 35.7844\n",
      "Epoch 00915: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f2e1e7fdfd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=5000, batch_size=32, validation_data=(X_test,y_test), callbacks=[mcp_save,earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRZ1nHe0Gjy5"
   },
   "source": [
    "# **Testing Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyAUCY0FGwsM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "prediction_model = load_model('trained_models/LSTM_reg_seven_new.hdf5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "lT71_QwcHEof",
    "outputId": "674692de-7a3b-4e60-addc-39ce1d9a328d"
   },
   "outputs": [],
   "source": [
    "y_pred = np.ravel(prediction_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995161692423405"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2=r2_score(y_test,y_pred) #testing score/ r^2\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.716042185424314"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae=mean_absolute_error(y_test,y_pred) #mae\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.31697071794044"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred)) #rmse\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5003317888342855"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape=mean_absolute_percentage_error(y_test,y_pred) #mape\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>R^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.716</td>\n",
       "      <td>83.317</td>\n",
       "      <td>1.50033</td>\n",
       "      <td>0.999516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1        2         3\n",
       "0     MAE    RMSE     MAPE       R^2\n",
       "1  35.716  83.317  1.50033  0.999516"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(['MAE','RMSE','MAPE','R^2'],[mae,rmse,mape,r2])).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6912.000</td>\n",
       "      <td>6930.309570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6233.000</td>\n",
       "      <td>6215.681641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235.065</td>\n",
       "      <td>236.442825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>609.126</td>\n",
       "      <td>614.928223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453.641</td>\n",
       "      <td>455.907837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>852.382</td>\n",
       "      <td>832.241394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>342.284</td>\n",
       "      <td>338.540771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>344.899</td>\n",
       "      <td>347.315247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>644.487</td>\n",
       "      <td>628.036255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3804.000</td>\n",
       "      <td>3817.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6978.000</td>\n",
       "      <td>7070.170410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>96.000</td>\n",
       "      <td>92.714241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2571.000</td>\n",
       "      <td>2557.367432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9249.000</td>\n",
       "      <td>9182.739258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8206.000</td>\n",
       "      <td>8325.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>374.287</td>\n",
       "      <td>376.424713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>568.912</td>\n",
       "      <td>578.977722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5677.000</td>\n",
       "      <td>5669.422852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>350.835</td>\n",
       "      <td>347.052063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5882.000</td>\n",
       "      <td>5919.316895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5265.000</td>\n",
       "      <td>5258.202148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>437.341</td>\n",
       "      <td>439.496368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>642.185</td>\n",
       "      <td>653.310486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3415.000</td>\n",
       "      <td>3577.179443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8830.000</td>\n",
       "      <td>8832.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>504.405</td>\n",
       "      <td>500.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8797.000</td>\n",
       "      <td>8778.083008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>273.617</td>\n",
       "      <td>278.828522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>225.576</td>\n",
       "      <td>226.028214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>447.946</td>\n",
       "      <td>440.261902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>139.740</td>\n",
       "      <td>131.070541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>377.566</td>\n",
       "      <td>382.746582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1269.000</td>\n",
       "      <td>1275.541260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>9161.000</td>\n",
       "      <td>9285.103516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>481.482</td>\n",
       "      <td>485.849884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>8894.000</td>\n",
       "      <td>9083.071289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3422.000</td>\n",
       "      <td>3395.324707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>241.816</td>\n",
       "      <td>240.987961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>9499.000</td>\n",
       "      <td>9583.295898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>892.331</td>\n",
       "      <td>898.470520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>383.251</td>\n",
       "      <td>373.259705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>402.084</td>\n",
       "      <td>392.066254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>264.053</td>\n",
       "      <td>258.737823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>6592.000</td>\n",
       "      <td>6531.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>12645.000</td>\n",
       "      <td>12567.561523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>829.446</td>\n",
       "      <td>818.575256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>106.555</td>\n",
       "      <td>105.389008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>952.778</td>\n",
       "      <td>953.274841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>8265.000</td>\n",
       "      <td>8299.704102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>238.539</td>\n",
       "      <td>243.847260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>8236.000</td>\n",
       "      <td>8421.504883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>114.295</td>\n",
       "      <td>124.636009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>877.685</td>\n",
       "      <td>855.735962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>584.376</td>\n",
       "      <td>588.994568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>8204.000</td>\n",
       "      <td>8321.587891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>7383.000</td>\n",
       "      <td>7336.909668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>66.000</td>\n",
       "      <td>80.042831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>596.048</td>\n",
       "      <td>579.973145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>121.008</td>\n",
       "      <td>121.762978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>605.886</td>\n",
       "      <td>606.188782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1\n",
       "0     6912.000   6930.309570\n",
       "1     6233.000   6215.681641\n",
       "2      235.065    236.442825\n",
       "3      609.126    614.928223\n",
       "4      453.641    455.907837\n",
       "5      852.382    832.241394\n",
       "6      342.284    338.540771\n",
       "7      344.899    347.315247\n",
       "8      644.487    628.036255\n",
       "9     3804.000   3817.390625\n",
       "10    6978.000   7070.170410\n",
       "11      96.000     92.714241\n",
       "12    2571.000   2557.367432\n",
       "13    9249.000   9182.739258\n",
       "14    8206.000   8325.005859\n",
       "15     374.287    376.424713\n",
       "16     568.912    578.977722\n",
       "17    5677.000   5669.422852\n",
       "18     350.835    347.052063\n",
       "19    5882.000   5919.316895\n",
       "20    5265.000   5258.202148\n",
       "21     437.341    439.496368\n",
       "22     642.185    653.310486\n",
       "23    3415.000   3577.179443\n",
       "24    8830.000   8832.900391\n",
       "25     504.405    500.222900\n",
       "26    8797.000   8778.083008\n",
       "27     273.617    278.828522\n",
       "28     225.576    226.028214\n",
       "29     447.946    440.261902\n",
       "..         ...           ...\n",
       "464    139.740    131.070541\n",
       "465    377.566    382.746582\n",
       "466   1269.000   1275.541260\n",
       "467   9161.000   9285.103516\n",
       "468    481.482    485.849884\n",
       "469   8894.000   9083.071289\n",
       "470   3422.000   3395.324707\n",
       "471    241.816    240.987961\n",
       "472   9499.000   9583.295898\n",
       "473    892.331    898.470520\n",
       "474    383.251    373.259705\n",
       "475    402.084    392.066254\n",
       "476    264.053    258.737823\n",
       "477   6592.000   6531.542969\n",
       "478  12645.000  12567.561523\n",
       "479    829.446    818.575256\n",
       "480    106.555    105.389008\n",
       "481    952.778    953.274841\n",
       "482   8265.000   8299.704102\n",
       "483    238.539    243.847260\n",
       "484   8236.000   8421.504883\n",
       "485    114.295    124.636009\n",
       "486    877.685    855.735962\n",
       "487    584.376    588.994568\n",
       "488   8204.000   8321.587891\n",
       "489   7383.000   7336.909668\n",
       "490     66.000     80.042831\n",
       "491    596.048    579.973145\n",
       "492    121.008    121.762978\n",
       "493    605.886    606.188782\n",
       "\n",
       "[494 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([y_test,y_pred]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
