{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from commons import mean_absolute_percentage_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HH_FAAlRXx"
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"pca_75_clas.csv\"\n",
    "data = pd.read_csv(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.001517</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>-0.005667</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>-0.010697</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>-0.002006</td>\n",
       "      <td>0.026004</td>\n",
       "      <td>-0.041647</td>\n",
       "      <td>-0.026440</td>\n",
       "      <td>-0.032341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>-0.003534</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.023267</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>-0.044002</td>\n",
       "      <td>0.031887</td>\n",
       "      <td>-0.006552</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>-0.014834</td>\n",
       "      <td>-0.062396</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>-0.006987</td>\n",
       "      <td>0.016127</td>\n",
       "      <td>0.023316</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>-0.004412</td>\n",
       "      <td>0.024240</td>\n",
       "      <td>0.031210</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>-0.048610</td>\n",
       "      <td>0.050460</td>\n",
       "      <td>-0.013181</td>\n",
       "      <td>0.041860</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>-0.039115</td>\n",
       "      <td>-0.022125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>-0.012779</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>0.036883</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.048642</td>\n",
       "      <td>-0.019583</td>\n",
       "      <td>0.038553</td>\n",
       "      <td>-0.025563</td>\n",
       "      <td>-0.025147</td>\n",
       "      <td>-0.040361</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>-0.051794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>-0.018850</td>\n",
       "      <td>0.035473</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>0.042568</td>\n",
       "      <td>-0.009877</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.066595</td>\n",
       "      <td>-0.023154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068916</td>\n",
       "      <td>0.016655</td>\n",
       "      <td>-0.017083</td>\n",
       "      <td>0.023803</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.079328</td>\n",
       "      <td>-0.124902</td>\n",
       "      <td>0.056408</td>\n",
       "      <td>0.033167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0.059714</td>\n",
       "      <td>-0.022766</td>\n",
       "      <td>0.071768</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.044245</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>-0.010713</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>-0.022111</td>\n",
       "      <td>-0.005570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>-0.013301</td>\n",
       "      <td>-0.010306</td>\n",
       "      <td>-0.013449</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.004979</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.022381</td>\n",
       "      <td>-0.029720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0.062561</td>\n",
       "      <td>-0.024609</td>\n",
       "      <td>0.076510</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>0.044237</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>0.037674</td>\n",
       "      <td>-0.017731</td>\n",
       "      <td>-0.010232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001338</td>\n",
       "      <td>-0.011560</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>-0.005956</td>\n",
       "      <td>-0.019449</td>\n",
       "      <td>-0.021599</td>\n",
       "      <td>-0.030125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.065741</td>\n",
       "      <td>-0.027502</td>\n",
       "      <td>0.082347</td>\n",
       "      <td>-0.006237</td>\n",
       "      <td>0.043677</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>-0.006821</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.013686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009712</td>\n",
       "      <td>-0.011015</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>-0.025612</td>\n",
       "      <td>0.018794</td>\n",
       "      <td>-0.006123</td>\n",
       "      <td>-0.013441</td>\n",
       "      <td>-0.025138</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0.070020</td>\n",
       "      <td>-0.034585</td>\n",
       "      <td>0.089961</td>\n",
       "      <td>-0.018261</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.030655</td>\n",
       "      <td>-0.012727</td>\n",
       "      <td>-0.014486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008291</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>-0.030202</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>-0.021531</td>\n",
       "      <td>-0.022496</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.081079</td>\n",
       "      <td>-0.066968</td>\n",
       "      <td>0.096749</td>\n",
       "      <td>-0.051543</td>\n",
       "      <td>0.049822</td>\n",
       "      <td>-0.033322</td>\n",
       "      <td>0.036087</td>\n",
       "      <td>0.041596</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003878</td>\n",
       "      <td>0.013399</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>-0.009047</td>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>-0.019553</td>\n",
       "      <td>-0.002305</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.060240</td>\n",
       "      <td>-0.022976</td>\n",
       "      <td>0.072390</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.044530</td>\n",
       "      <td>0.010371</td>\n",
       "      <td>-0.010840</td>\n",
       "      <td>0.037570</td>\n",
       "      <td>-0.022380</td>\n",
       "      <td>-0.005227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>-0.013565</td>\n",
       "      <td>-0.009968</td>\n",
       "      <td>-0.013861</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>-0.023372</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>-0.029858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.062759</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>0.076606</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>0.044641</td>\n",
       "      <td>0.011555</td>\n",
       "      <td>-0.009754</td>\n",
       "      <td>0.037618</td>\n",
       "      <td>-0.018869</td>\n",
       "      <td>-0.008879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001807</td>\n",
       "      <td>-0.012378</td>\n",
       "      <td>-0.005614</td>\n",
       "      <td>-0.019321</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>-0.005374</td>\n",
       "      <td>-0.020275</td>\n",
       "      <td>-0.023088</td>\n",
       "      <td>-0.029492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.067661</td>\n",
       "      <td>-0.028587</td>\n",
       "      <td>0.084138</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>0.045619</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>-0.006408</td>\n",
       "      <td>0.037511</td>\n",
       "      <td>-0.016289</td>\n",
       "      <td>-0.011998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005801</td>\n",
       "      <td>-0.009355</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.024074</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>-0.004151</td>\n",
       "      <td>-0.018373</td>\n",
       "      <td>-0.024145</td>\n",
       "      <td>-0.024671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0.074736</td>\n",
       "      <td>-0.037279</td>\n",
       "      <td>0.094189</td>\n",
       "      <td>-0.017252</td>\n",
       "      <td>0.046975</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.036559</td>\n",
       "      <td>-0.017244</td>\n",
       "      <td>-0.012360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005885</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>-0.026190</td>\n",
       "      <td>0.019483</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>-0.019612</td>\n",
       "      <td>-0.022010</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0.086833</td>\n",
       "      <td>-0.066207</td>\n",
       "      <td>0.101207</td>\n",
       "      <td>-0.043891</td>\n",
       "      <td>0.057045</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.049079</td>\n",
       "      <td>-0.033664</td>\n",
       "      <td>-0.006868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006466</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>-0.008174</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.027689</td>\n",
       "      <td>-0.024543</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.059451</td>\n",
       "      <td>-0.022555</td>\n",
       "      <td>0.071234</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.044286</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>-0.010855</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>-0.022946</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>-0.013701</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>-0.012387</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.023915</td>\n",
       "      <td>-0.023172</td>\n",
       "      <td>-0.029508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.061313</td>\n",
       "      <td>-0.023744</td>\n",
       "      <td>0.074343</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.044367</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>-0.010565</td>\n",
       "      <td>0.037510</td>\n",
       "      <td>-0.019972</td>\n",
       "      <td>-0.007966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>-0.017904</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>-0.005370</td>\n",
       "      <td>-0.021701</td>\n",
       "      <td>-0.021676</td>\n",
       "      <td>-0.030261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.064059</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>0.079061</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.044294</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>-0.008957</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>-0.015857</td>\n",
       "      <td>-0.011392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004832</td>\n",
       "      <td>-0.012067</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.023286</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>-0.005558</td>\n",
       "      <td>-0.017181</td>\n",
       "      <td>-0.024011</td>\n",
       "      <td>-0.029282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.071002</td>\n",
       "      <td>-0.031809</td>\n",
       "      <td>0.089883</td>\n",
       "      <td>-0.011413</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.035897</td>\n",
       "      <td>-0.013518</td>\n",
       "      <td>-0.014640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010451</td>\n",
       "      <td>-0.006146</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>-0.027754</td>\n",
       "      <td>0.022309</td>\n",
       "      <td>-0.004416</td>\n",
       "      <td>-0.016864</td>\n",
       "      <td>-0.024335</td>\n",
       "      <td>-0.017783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.079887</td>\n",
       "      <td>-0.052789</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>-0.037088</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>-0.015319</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>-0.025270</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>-0.021092</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.034265</td>\n",
       "      <td>-0.019690</td>\n",
       "      <td>-0.009236</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>-0.008210</td>\n",
       "      <td>0.046193</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>-0.027140</td>\n",
       "      <td>-0.016864</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>-0.057126</td>\n",
       "      <td>0.058250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046452</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>-0.041561</td>\n",
       "      <td>0.030569</td>\n",
       "      <td>-0.038973</td>\n",
       "      <td>0.029876</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.020718</td>\n",
       "      <td>-0.007928</td>\n",
       "      <td>0.076076</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>-0.017502</td>\n",
       "      <td>-0.044616</td>\n",
       "      <td>0.060857</td>\n",
       "      <td>-0.070786</td>\n",
       "      <td>0.026453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087428</td>\n",
       "      <td>-0.009082</td>\n",
       "      <td>-0.018439</td>\n",
       "      <td>-0.049445</td>\n",
       "      <td>-0.025923</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>-0.017438</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>-0.009566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.028307</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.085359</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>-0.046766</td>\n",
       "      <td>0.061517</td>\n",
       "      <td>-0.046280</td>\n",
       "      <td>-0.020887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009100</td>\n",
       "      <td>-0.038498</td>\n",
       "      <td>-0.030078</td>\n",
       "      <td>-0.037316</td>\n",
       "      <td>0.045896</td>\n",
       "      <td>-0.010680</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>-0.004036</td>\n",
       "      <td>-0.042129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.037853</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>0.092685</td>\n",
       "      <td>-0.032133</td>\n",
       "      <td>0.023206</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>0.041530</td>\n",
       "      <td>-0.025852</td>\n",
       "      <td>-0.059650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094277</td>\n",
       "      <td>-0.025775</td>\n",
       "      <td>-0.069761</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.064205</td>\n",
       "      <td>-0.032427</td>\n",
       "      <td>-0.014403</td>\n",
       "      <td>-0.042446</td>\n",
       "      <td>-0.038377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>-0.006204</td>\n",
       "      <td>0.044093</td>\n",
       "      <td>0.100720</td>\n",
       "      <td>0.094469</td>\n",
       "      <td>-0.099727</td>\n",
       "      <td>-0.040275</td>\n",
       "      <td>0.083619</td>\n",
       "      <td>-0.011030</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>-0.010828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034215</td>\n",
       "      <td>-0.017310</td>\n",
       "      <td>-0.035562</td>\n",
       "      <td>0.076933</td>\n",
       "      <td>0.082773</td>\n",
       "      <td>0.017684</td>\n",
       "      <td>-0.009587</td>\n",
       "      <td>0.025187</td>\n",
       "      <td>-0.006111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005505</td>\n",
       "      <td>-0.008910</td>\n",
       "      <td>-0.007578</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>-0.001986</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>-0.010930</td>\n",
       "      <td>-0.017358</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>-0.005217</td>\n",
       "      <td>-0.007573</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>-0.027302</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>-0.007063</td>\n",
       "      <td>-0.031591</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>-0.029823</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>-0.026642</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>-0.007336</td>\n",
       "      <td>0.025614</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.018645</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>-0.025905</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-0.020159</td>\n",
       "      <td>-0.039136</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>-0.046050</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>-0.030014</td>\n",
       "      <td>-0.010509</td>\n",
       "      <td>-0.031013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>-0.002372</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>-0.029658</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>-0.007749</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015140</td>\n",
       "      <td>-0.047221</td>\n",
       "      <td>-0.006887</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>-0.050761</td>\n",
       "      <td>0.013317</td>\n",
       "      <td>-0.003278</td>\n",
       "      <td>-0.069426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.033733</td>\n",
       "      <td>-0.028576</td>\n",
       "      <td>-0.005532</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>-0.011571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>-0.008940</td>\n",
       "      <td>-0.033364</td>\n",
       "      <td>-0.050284</td>\n",
       "      <td>-0.017399</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>-0.008121</td>\n",
       "      <td>-0.007514</td>\n",
       "      <td>-0.049078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.024296</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>-0.003050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018356</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>-0.017944</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>-0.002756</td>\n",
       "      <td>0.036321</td>\n",
       "      <td>-0.016490</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.027602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>0.024214</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.046149</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>0.020308</td>\n",
       "      <td>-0.006762</td>\n",
       "      <td>0.017894</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026263</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>-0.015413</td>\n",
       "      <td>-0.000587</td>\n",
       "      <td>-0.016636</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.023083</td>\n",
       "      <td>-0.029920</td>\n",
       "      <td>0.059645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0.028918</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.054741</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.030458</td>\n",
       "      <td>0.021041</td>\n",
       "      <td>-0.007679</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>-0.007738</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011814</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>-0.057210</td>\n",
       "      <td>0.042824</td>\n",
       "      <td>-0.003733</td>\n",
       "      <td>0.066128</td>\n",
       "      <td>0.051586</td>\n",
       "      <td>-0.057046</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.029689</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.024915</td>\n",
       "      <td>-0.006709</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.007564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047718</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>-0.036266</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>0.044783</td>\n",
       "      <td>0.041299</td>\n",
       "      <td>0.018362</td>\n",
       "      <td>0.046739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.045743</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.094863</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.019896</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>-0.008456</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027035</td>\n",
       "      <td>-0.034568</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>-0.014268</td>\n",
       "      <td>0.030480</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>-0.053282</td>\n",
       "      <td>0.025722</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>-0.003629</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>-0.004745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>-0.017223</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>-0.010541</td>\n",
       "      <td>0.025489</td>\n",
       "      <td>-0.012395</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.029717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.008596</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>0.019619</td>\n",
       "      <td>-0.009484</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>-0.007553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008876</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>-0.022287</td>\n",
       "      <td>0.045841</td>\n",
       "      <td>0.019096</td>\n",
       "      <td>-0.015339</td>\n",
       "      <td>0.060414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.011420</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.023098</td>\n",
       "      <td>-0.010926</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>-0.013706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.004122</td>\n",
       "      <td>-0.047980</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>0.063870</td>\n",
       "      <td>0.055155</td>\n",
       "      <td>-0.042613</td>\n",
       "      <td>0.023337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>-0.012407</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.011782</td>\n",
       "      <td>-0.017150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022863</td>\n",
       "      <td>-0.014862</td>\n",
       "      <td>-0.026180</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>-0.015694</td>\n",
       "      <td>0.040829</td>\n",
       "      <td>0.052726</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.025240</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>-0.022442</td>\n",
       "      <td>0.029825</td>\n",
       "      <td>0.032648</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>-0.029089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>-0.020743</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>-0.018542</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>-0.005185</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.016495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>-0.036685</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>-0.116770</td>\n",
       "      <td>-0.035671</td>\n",
       "      <td>0.127647</td>\n",
       "      <td>-0.152962</td>\n",
       "      <td>0.207051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>-0.068047</td>\n",
       "      <td>0.065216</td>\n",
       "      <td>0.069132</td>\n",
       "      <td>-0.023994</td>\n",
       "      <td>-0.048667</td>\n",
       "      <td>0.068573</td>\n",
       "      <td>-0.095627</td>\n",
       "      <td>-0.016556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.046472</td>\n",
       "      <td>-0.036970</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.056750</td>\n",
       "      <td>-0.090095</td>\n",
       "      <td>-0.050705</td>\n",
       "      <td>0.113332</td>\n",
       "      <td>-0.126209</td>\n",
       "      <td>0.142041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103935</td>\n",
       "      <td>-0.041809</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>-0.006050</td>\n",
       "      <td>0.025039</td>\n",
       "      <td>-0.044788</td>\n",
       "      <td>0.029935</td>\n",
       "      <td>-0.027097</td>\n",
       "      <td>-0.037054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>-0.030080</td>\n",
       "      <td>0.110998</td>\n",
       "      <td>0.034435</td>\n",
       "      <td>-0.061756</td>\n",
       "      <td>-0.058058</td>\n",
       "      <td>0.090585</td>\n",
       "      <td>-0.097161</td>\n",
       "      <td>0.088124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>-0.029633</td>\n",
       "      <td>-0.055118</td>\n",
       "      <td>-0.039396</td>\n",
       "      <td>0.088209</td>\n",
       "      <td>-0.074124</td>\n",
       "      <td>-0.002696</td>\n",
       "      <td>-0.009039</td>\n",
       "      <td>-0.037828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.050212</td>\n",
       "      <td>-0.016697</td>\n",
       "      <td>0.106781</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>-0.044572</td>\n",
       "      <td>-0.050386</td>\n",
       "      <td>0.065377</td>\n",
       "      <td>-0.071037</td>\n",
       "      <td>0.040459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026289</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>-0.089512</td>\n",
       "      <td>-0.054026</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>-0.072297</td>\n",
       "      <td>-0.024055</td>\n",
       "      <td>-0.001947</td>\n",
       "      <td>-0.025142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.051739</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>0.101062</td>\n",
       "      <td>-0.022715</td>\n",
       "      <td>-0.047094</td>\n",
       "      <td>-0.026596</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>-0.050774</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022029</td>\n",
       "      <td>0.023196</td>\n",
       "      <td>-0.061890</td>\n",
       "      <td>-0.049784</td>\n",
       "      <td>0.116391</td>\n",
       "      <td>-0.006934</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>-0.018945</td>\n",
       "      <td>-0.004059</td>\n",
       "      <td>0.023289</td>\n",
       "      <td>-0.034051</td>\n",
       "      <td>0.045466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>0.019234</td>\n",
       "      <td>-0.015686</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>-0.022880</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.034638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>-0.000482</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>-0.005308</td>\n",
       "      <td>0.045214</td>\n",
       "      <td>0.029381</td>\n",
       "      <td>-0.022539</td>\n",
       "      <td>-0.015378</td>\n",
       "      <td>0.037575</td>\n",
       "      <td>-0.056491</td>\n",
       "      <td>0.048989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046377</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>-0.049100</td>\n",
       "      <td>0.037189</td>\n",
       "      <td>-0.024766</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.050899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>0.058595</td>\n",
       "      <td>0.029469</td>\n",
       "      <td>-0.016261</td>\n",
       "      <td>-0.029251</td>\n",
       "      <td>0.047632</td>\n",
       "      <td>-0.061140</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057394</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>-0.031700</td>\n",
       "      <td>-0.040838</td>\n",
       "      <td>0.071087</td>\n",
       "      <td>-0.020349</td>\n",
       "      <td>0.044031</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.058395</td>\n",
       "      <td>0.016572</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>-0.029393</td>\n",
       "      <td>0.044192</td>\n",
       "      <td>-0.043543</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012934</td>\n",
       "      <td>-0.031553</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>-0.004029</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>-0.008662</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>-0.005010</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.064323</td>\n",
       "      <td>-0.018245</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.036151</td>\n",
       "      <td>-0.030524</td>\n",
       "      <td>-0.030618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021374</td>\n",
       "      <td>-0.014693</td>\n",
       "      <td>-0.031063</td>\n",
       "      <td>0.035066</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>0.037447</td>\n",
       "      <td>-0.028164</td>\n",
       "      <td>0.045411</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "685 -0.000100 -0.000076 -0.001517  0.007486  0.016120 -0.005667  0.010421   \n",
       "686 -0.000326  0.001042 -0.002971  0.009924  0.016879 -0.003534  0.001243   \n",
       "687  0.000590  0.003160 -0.006987  0.016127  0.023316  0.001033 -0.004412   \n",
       "688  0.002498  0.008524 -0.012779  0.023769  0.036883  0.019590  0.003803   \n",
       "689  0.008981  0.025272 -0.018850  0.035473  0.018963  0.042568 -0.009877   \n",
       "690  0.059714 -0.022766  0.071768  0.002174  0.044245  0.010318 -0.010713   \n",
       "691  0.062561 -0.024609  0.076510 -0.000815  0.044237  0.012129 -0.010247   \n",
       "692  0.065741 -0.027502  0.082347 -0.006237  0.043677  0.012969 -0.006821   \n",
       "693  0.070020 -0.034585  0.089961 -0.018261  0.042081  0.006469  0.004801   \n",
       "694  0.081079 -0.066968  0.096749 -0.051543  0.049822 -0.033322  0.036087   \n",
       "695  0.060240 -0.022976  0.072390  0.002147  0.044530  0.010371 -0.010840   \n",
       "696  0.062759 -0.024758  0.076606 -0.000731  0.044641  0.011555 -0.009754   \n",
       "697  0.067661 -0.028587  0.084138 -0.005976  0.045619  0.011484 -0.006408   \n",
       "698  0.074736 -0.037279  0.094189 -0.017252  0.046975  0.004950  0.003273   \n",
       "699  0.086833 -0.066207  0.101207 -0.043891  0.057045 -0.018247  0.022606   \n",
       "700  0.059451 -0.022555  0.071234  0.002614  0.044286  0.010025 -0.010855   \n",
       "701  0.061313 -0.023744  0.074343  0.000707  0.044367  0.011279 -0.010565   \n",
       "702  0.064059 -0.025803  0.079061 -0.002817  0.044294  0.012481 -0.008957   \n",
       "703  0.071002 -0.031809  0.089883 -0.011413  0.045409  0.011059 -0.002360   \n",
       "704  0.079887 -0.052789  0.099804 -0.037088  0.047105 -0.015319  0.022894   \n",
       "705 -0.000106  0.010391 -0.008210  0.046193  0.033445 -0.027140 -0.016864   \n",
       "706  0.000191  0.020718 -0.007928  0.076076  0.031703 -0.017502 -0.044616   \n",
       "707  0.000400  0.028307  0.002719  0.085359  0.008531  0.008979 -0.046766   \n",
       "708  0.000147  0.037853  0.026366  0.092685 -0.032133  0.023206 -0.012615   \n",
       "709 -0.006204  0.044093  0.100720  0.094469 -0.099727 -0.040275  0.083619   \n",
       "710  0.000228  0.002070 -0.003863  0.008996  0.005673 -0.004739 -0.002991   \n",
       "711  0.000585  0.003923 -0.005976  0.015981  0.010265 -0.005217 -0.007573   \n",
       "712  0.001372  0.007633 -0.007336  0.025614  0.014448  0.000239 -0.018645   \n",
       "713  0.002755  0.013174 -0.002372  0.030498  0.013690  0.018916 -0.029658   \n",
       "714  0.008651  0.029944  0.019971  0.036825  0.003345  0.033733 -0.028576   \n",
       "715  0.016631  0.009349  0.032390  0.004185  0.024296  0.013848 -0.000027   \n",
       "716  0.024214  0.011375  0.046149  0.002125  0.026133  0.020308 -0.006762   \n",
       "717  0.028918  0.011890  0.054741  0.000672  0.030458  0.021041 -0.007679   \n",
       "718  0.029689  0.010922  0.056919 -0.002384  0.030258  0.024915 -0.006709   \n",
       "719  0.045743  0.012537  0.094863 -0.028053  0.033517  0.018417  0.019896   \n",
       "720  0.004908  0.006511  0.012606  0.004083  0.011393  0.010605 -0.003629   \n",
       "721  0.008596  0.011076  0.022689  0.004288  0.015468  0.019619 -0.009484   \n",
       "722  0.011420  0.014287  0.029968  0.004775  0.020703  0.023098 -0.010926   \n",
       "723  0.011590  0.015235  0.031990  0.004120  0.021954  0.027885 -0.012407   \n",
       "724  0.025240  0.029439  0.079479 -0.022442  0.029825  0.032648  0.013430   \n",
       "725  0.002420  0.045545 -0.036685  0.119403  0.070751 -0.116770 -0.035671   \n",
       "726  0.003939  0.046472 -0.036970  0.116883  0.056750 -0.090095 -0.050705   \n",
       "727  0.004597  0.047521 -0.030080  0.110998  0.034435 -0.061756 -0.058058   \n",
       "728  0.005299  0.050212 -0.016697  0.106781  0.006687 -0.044572 -0.050386   \n",
       "729  0.005917  0.051739  0.007892  0.101062 -0.022715 -0.047094 -0.026596   \n",
       "730 -0.000294  0.005887 -0.004245  0.028484  0.022864 -0.018945 -0.004059   \n",
       "731 -0.000482  0.009959 -0.005308  0.045214  0.029381 -0.022539 -0.015378   \n",
       "732 -0.000724  0.014015 -0.003349  0.058595  0.029469 -0.016261 -0.029251   \n",
       "733 -0.001427  0.015398  0.004493  0.058395  0.016572  0.002721 -0.029393   \n",
       "734 -0.005010  0.016138  0.024714  0.064323 -0.018245  0.011407  0.015563   \n",
       "\n",
       "            7         8         9  ...        41        42        43  \\\n",
       "685 -0.001159  0.015629  0.006827  ...  0.016176  0.018198 -0.010697   \n",
       "686  0.012249  0.023267  0.014074  ...  0.017619  0.025803 -0.044002   \n",
       "687  0.024240  0.031210  0.011504  ...  0.007046  0.004042 -0.048610   \n",
       "688  0.010918  0.041857  0.011904  ...  0.006508  0.048642 -0.019583   \n",
       "689  0.012988  0.066595 -0.023154  ... -0.068916  0.016655 -0.017083   \n",
       "690  0.037065 -0.022111 -0.005570  ...  0.002248 -0.013301 -0.010306   \n",
       "691  0.037674 -0.017731 -0.010232  ... -0.001338 -0.011560 -0.006098   \n",
       "692  0.036610 -0.012546 -0.013686  ... -0.009712 -0.011015  0.005504   \n",
       "693  0.030655 -0.012727 -0.014486  ... -0.008291  0.003511  0.000809   \n",
       "694  0.041596 -0.036804  0.006675  ... -0.003878  0.013399  0.011163   \n",
       "695  0.037570 -0.022380 -0.005227  ...  0.000836 -0.013565 -0.009968   \n",
       "696  0.037618 -0.018869 -0.008879  ... -0.001807 -0.012378 -0.005614   \n",
       "697  0.037511 -0.016289 -0.011998  ... -0.005801 -0.009355 -0.000592   \n",
       "698  0.036559 -0.017244 -0.012360  ... -0.005885  0.001046  0.002089   \n",
       "699  0.049079 -0.033664 -0.006868  ... -0.006466  0.017456  0.011766   \n",
       "700  0.037268 -0.022946 -0.004464  ...  0.001461 -0.013701 -0.010594   \n",
       "701  0.037510 -0.019972 -0.007966  ...  0.000633 -0.012426 -0.008476   \n",
       "702  0.037476 -0.015857 -0.011392  ... -0.004832 -0.012067 -0.001082   \n",
       "703  0.035897 -0.013518 -0.014640  ... -0.010451 -0.006146  0.003341   \n",
       "704  0.035538 -0.025270 -0.004245  ... -0.000873  0.016454  0.002640   \n",
       "705  0.037259 -0.057126  0.058250  ...  0.046452  0.008450  0.009693   \n",
       "706  0.060857 -0.070786  0.026453  ...  0.087428 -0.009082 -0.018439   \n",
       "707  0.061517 -0.046280 -0.020887  ... -0.009100 -0.038498 -0.030078   \n",
       "708  0.041530 -0.025852 -0.059650  ... -0.094277 -0.025775 -0.069761   \n",
       "709 -0.011030 -0.017119 -0.010828  ...  0.034215 -0.017310 -0.035562   \n",
       "710  0.005489 -0.018176  0.018481  ... -0.005505 -0.008910 -0.007578   \n",
       "711  0.007825 -0.027302  0.019579  ...  0.018939 -0.007063 -0.031591   \n",
       "712  0.016689 -0.025905  0.016730  ...  0.027075 -0.020159 -0.039136   \n",
       "713  0.020220 -0.007749  0.003748  ... -0.015140 -0.047221 -0.006887   \n",
       "714 -0.005532  0.013063 -0.011571  ...  0.017724 -0.008940 -0.033364   \n",
       "715  0.007872  0.002873 -0.003050  ... -0.018356  0.005823 -0.017944   \n",
       "716  0.017894 -0.002271 -0.001207  ... -0.026263  0.015728 -0.015413   \n",
       "717  0.020618 -0.007738 -0.005143  ... -0.011814  0.000464 -0.057210   \n",
       "718  0.020431 -0.002067 -0.007564  ... -0.047718  0.003153 -0.036266   \n",
       "719  0.004218 -0.008456 -0.003289  ... -0.027035 -0.034568  0.003888   \n",
       "720  0.004918  0.005397 -0.004745  ...  0.003205  0.007264 -0.017223   \n",
       "721  0.011109  0.007530 -0.007553  ... -0.008876  0.008507 -0.007027   \n",
       "722  0.011292  0.003258 -0.013706  ... -0.001813 -0.004122 -0.047980   \n",
       "723  0.014894  0.011782 -0.017150  ... -0.022863 -0.014862 -0.026180   \n",
       "724  0.000669  0.018887 -0.029089  ...  0.012735 -0.020743  0.009845   \n",
       "725  0.127647 -0.152962  0.207051  ...  0.011522 -0.068047  0.065216   \n",
       "726  0.113332 -0.126209  0.142041  ...  0.103935 -0.041809  0.001812   \n",
       "727  0.090585 -0.097161  0.088124  ...  0.081998 -0.029633 -0.055118   \n",
       "728  0.065377 -0.071037  0.040459  ...  0.026289 -0.001845 -0.089512   \n",
       "729  0.037265 -0.050774  0.012703  ...  0.022029  0.023196 -0.061890   \n",
       "730  0.023289 -0.034051  0.045466  ... -0.000988  0.003325  0.020581   \n",
       "731  0.037575 -0.056491  0.048989  ...  0.046377  0.013293  0.004515   \n",
       "732  0.047632 -0.061140  0.028825  ...  0.057394 -0.000443 -0.010084   \n",
       "733  0.044192 -0.043543 -0.004391  ... -0.012934 -0.031553  0.002551   \n",
       "734  0.036151 -0.030524 -0.030618  ... -0.021374 -0.014693 -0.031063   \n",
       "\n",
       "           44        45        46        47        48        49  priceUSD  \n",
       "685  0.016323 -0.002006  0.026004 -0.041647 -0.026440 -0.032341         0  \n",
       "686  0.031887 -0.006552  0.013670 -0.014834 -0.062396  0.011838         1  \n",
       "687  0.050460 -0.013181  0.041860  0.014401 -0.039115 -0.022125         1  \n",
       "688  0.038553 -0.025563 -0.025147 -0.040361 -0.003057 -0.051794         0  \n",
       "689  0.023803  0.000946  0.079328 -0.124902  0.056408  0.033167         1  \n",
       "690 -0.013449  0.000871 -0.004979 -0.023549 -0.022381 -0.029720         1  \n",
       "691 -0.022105  0.004471 -0.005956 -0.019449 -0.021599 -0.030125         0  \n",
       "692 -0.025612  0.018794 -0.006123 -0.013441 -0.025138 -0.026332         0  \n",
       "693 -0.030202  0.022954  0.003304 -0.021531 -0.022496 -0.000875         1  \n",
       "694 -0.009047  0.016514  0.031237 -0.019553 -0.002305  0.013790         0  \n",
       "695 -0.013861  0.001560 -0.004852 -0.023372 -0.023125 -0.029858         0  \n",
       "696 -0.019321  0.006169 -0.005374 -0.020275 -0.023088 -0.029492         1  \n",
       "697 -0.024074  0.013886 -0.004151 -0.018373 -0.024145 -0.024671         1  \n",
       "698 -0.026190  0.019483  0.007646 -0.019612 -0.022010 -0.009624         0  \n",
       "699 -0.008174  0.016478  0.027689 -0.024543 -0.006108  0.014607         1  \n",
       "700 -0.012387  0.000927 -0.004723 -0.023915 -0.023172 -0.029508         1  \n",
       "701 -0.017904  0.002431 -0.005370 -0.021701 -0.021676 -0.030261         1  \n",
       "702 -0.023286  0.010706 -0.005558 -0.017181 -0.024011 -0.029282         0  \n",
       "703 -0.027754  0.022309 -0.004416 -0.016864 -0.024335 -0.017783         1  \n",
       "704 -0.021092  0.017839  0.034265 -0.019690 -0.009236  0.010727         1  \n",
       "705  0.014483 -0.041561  0.030569 -0.038973  0.029876  0.040905         1  \n",
       "706 -0.049445 -0.025923  0.063234 -0.017438  0.049350 -0.009566         1  \n",
       "707 -0.037316  0.045896 -0.010680  0.002264 -0.004036 -0.042129         1  \n",
       "708  0.003173  0.064205 -0.032427 -0.014403 -0.042446 -0.038377         1  \n",
       "709  0.076933  0.082773  0.017684 -0.009587  0.025187 -0.006111         1  \n",
       "710  0.022133 -0.001986  0.002379 -0.010930 -0.017358  0.004267         0  \n",
       "711  0.031606 -0.029823  0.001049 -0.026642  0.002274 -0.002014         0  \n",
       "712  0.011936 -0.046050  0.008986 -0.030014 -0.010509 -0.031013         1  \n",
       "713  0.014377 -0.002655 -0.050761  0.013317 -0.003278 -0.069426         1  \n",
       "714 -0.050284 -0.017399  0.020734 -0.008121 -0.007514 -0.049078         0  \n",
       "715  0.008852 -0.002756  0.036321 -0.016490 -0.000259  0.027602         0  \n",
       "716 -0.000587 -0.016636  0.050980  0.023083 -0.029920  0.059645         0  \n",
       "717  0.042824 -0.003733  0.066128  0.051586 -0.057046  0.035339         1  \n",
       "718  0.021637 -0.013853  0.044783  0.041299  0.018362  0.046739         0  \n",
       "719 -0.014268  0.030480  0.004859 -0.053282  0.025722  0.033592         1  \n",
       "720  0.006485 -0.010541  0.025489 -0.012395  0.004177  0.029717         1  \n",
       "721 -0.001448 -0.022287  0.045841  0.019096 -0.015339  0.060414         0  \n",
       "722  0.036282 -0.003409  0.063870  0.055155 -0.042613  0.023337         0  \n",
       "723  0.010076 -0.015694  0.040829  0.052726  0.016358  0.022234         1  \n",
       "724 -0.018542  0.025506  0.001116 -0.005185  0.002319  0.016495         0  \n",
       "725  0.069132 -0.023994 -0.048667  0.068573 -0.095627 -0.016556         1  \n",
       "726 -0.006050  0.025039 -0.044788  0.029935 -0.027097 -0.037054         0  \n",
       "727 -0.039396  0.088209 -0.074124 -0.002696 -0.009039 -0.037828         1  \n",
       "728 -0.054026  0.120181 -0.072297 -0.024055 -0.001947 -0.025142         1  \n",
       "729 -0.049784  0.116391 -0.006934  0.007855  0.003460  0.011808         0  \n",
       "730  0.019234 -0.015686 -0.000933 -0.022880 -0.002095  0.034638         1  \n",
       "731  0.008637 -0.049100  0.037189 -0.024766  0.035241  0.050899         1  \n",
       "732 -0.031700 -0.040838  0.071087 -0.020349  0.044031  0.023599         0  \n",
       "733 -0.008612 -0.004029  0.021835 -0.008662  0.017243  0.003944         1  \n",
       "734  0.035066  0.048421  0.037447 -0.028164  0.045411 -0.002069         1  \n",
       "\n",
       "[50 rows x 51 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 51)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSzHTpuzmScU"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=0.2, train_size=0.8, shuffle=False, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(['robust',RobustScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(['mixmax',MinMaxScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=Pipeline(estimators,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDojXgA7mpWa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing robust, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing mixmax, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "X_train=scale.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wNcl2z_JKkM"
   },
   "outputs": [],
   "source": [
    "y_train=y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique1, id1 = np.unique(y_train, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(id1,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.reshape(y_train, (y_train.shape[0],1,y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVCJxdebqmOr"
   },
   "source": [
    "# **Model Architecture + Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "adam=optimizers.adam(lr=lr_schedule(0),amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(80, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True, activation='relu')))\n",
    "#model.add(Bidirectional(LSTM(40, return_sequences=True, activation='relu')))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6"
   },
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('trained_models/LSTM_cls_interval3.hdf5', save_best_only=True, monitor='val_loss', mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIJPsArMr8cs",
    "outputId": "91137564-8bb8-496c-c827-829e240a789a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 529 samples, validate on 59 samples\n",
      "Epoch 1/1500\n",
      "529/529 [==============================] - 1s 3ms/step - loss: 0.6967 - accuracy: 0.5331 - val_loss: 0.7010 - val_accuracy: 0.4576\n",
      "Epoch 2/1500\n",
      "529/529 [==============================] - 0s 271us/step - loss: 0.6916 - accuracy: 0.5331 - val_loss: 0.6981 - val_accuracy: 0.4576\n",
      "Epoch 3/1500\n",
      "529/529 [==============================] - 0s 294us/step - loss: 0.6919 - accuracy: 0.5331 - val_loss: 0.6974 - val_accuracy: 0.4576\n",
      "Epoch 4/1500\n",
      "529/529 [==============================] - 0s 233us/step - loss: 0.6919 - accuracy: 0.5331 - val_loss: 0.6974 - val_accuracy: 0.4576\n",
      "Epoch 5/1500\n",
      "529/529 [==============================] - 0s 319us/step - loss: 0.6918 - accuracy: 0.5331 - val_loss: 0.6971 - val_accuracy: 0.4576\n",
      "Epoch 6/1500\n",
      "529/529 [==============================] - 0s 308us/step - loss: 0.6920 - accuracy: 0.5331 - val_loss: 0.6975 - val_accuracy: 0.4576\n",
      "Epoch 7/1500\n",
      "529/529 [==============================] - 0s 306us/step - loss: 0.6916 - accuracy: 0.5331 - val_loss: 0.6970 - val_accuracy: 0.4576\n",
      "Epoch 8/1500\n",
      "529/529 [==============================] - 0s 297us/step - loss: 0.6924 - accuracy: 0.5331 - val_loss: 0.6976 - val_accuracy: 0.4576\n",
      "Epoch 9/1500\n",
      "529/529 [==============================] - 0s 307us/step - loss: 0.6913 - accuracy: 0.5331 - val_loss: 0.6973 - val_accuracy: 0.4576\n",
      "Epoch 10/1500\n",
      "529/529 [==============================] - 0s 299us/step - loss: 0.6915 - accuracy: 0.5331 - val_loss: 0.6974 - val_accuracy: 0.4576\n",
      "Epoch 11/1500\n",
      "529/529 [==============================] - 0s 316us/step - loss: 0.6910 - accuracy: 0.5331 - val_loss: 0.6973 - val_accuracy: 0.4576\n",
      "Epoch 12/1500\n",
      "529/529 [==============================] - 0s 308us/step - loss: 0.6912 - accuracy: 0.5331 - val_loss: 0.6979 - val_accuracy: 0.4576\n",
      "Epoch 13/1500\n",
      "529/529 [==============================] - 0s 292us/step - loss: 0.6908 - accuracy: 0.5331 - val_loss: 0.6978 - val_accuracy: 0.4576\n",
      "Epoch 14/1500\n",
      "529/529 [==============================] - 0s 320us/step - loss: 0.6900 - accuracy: 0.5369 - val_loss: 0.6972 - val_accuracy: 0.4576\n",
      "Epoch 15/1500\n",
      "529/529 [==============================] - 0s 310us/step - loss: 0.6915 - accuracy: 0.5444 - val_loss: 0.6991 - val_accuracy: 0.4576\n",
      "Epoch 16/1500\n",
      "529/529 [==============================] - 0s 322us/step - loss: 0.6884 - accuracy: 0.5369 - val_loss: 0.6962 - val_accuracy: 0.4576\n",
      "Epoch 17/1500\n",
      "529/529 [==============================] - 0s 310us/step - loss: 0.6905 - accuracy: 0.5482 - val_loss: 0.6974 - val_accuracy: 0.4576\n",
      "Epoch 18/1500\n",
      "529/529 [==============================] - 0s 296us/step - loss: 0.6888 - accuracy: 0.5577 - val_loss: 0.6986 - val_accuracy: 0.4576\n",
      "Epoch 19/1500\n",
      "529/529 [==============================] - 0s 327us/step - loss: 0.6886 - accuracy: 0.5520 - val_loss: 0.6976 - val_accuracy: 0.4576\n",
      "Epoch 20/1500\n",
      "529/529 [==============================] - 0s 310us/step - loss: 0.6894 - accuracy: 0.5388 - val_loss: 0.6976 - val_accuracy: 0.4407\n",
      "Epoch 21/1500\n",
      "529/529 [==============================] - 0s 324us/step - loss: 0.6884 - accuracy: 0.5293 - val_loss: 0.6987 - val_accuracy: 0.4407\n",
      "Epoch 22/1500\n",
      "529/529 [==============================] - 0s 310us/step - loss: 0.6835 - accuracy: 0.5577 - val_loss: 0.6981 - val_accuracy: 0.4407\n",
      "Epoch 23/1500\n",
      "529/529 [==============================] - 0s 314us/step - loss: 0.6797 - accuracy: 0.5709 - val_loss: 0.6901 - val_accuracy: 0.5254\n",
      "Epoch 24/1500\n",
      "529/529 [==============================] - 0s 307us/step - loss: 0.6996 - accuracy: 0.4972 - val_loss: 0.6991 - val_accuracy: 0.4407\n",
      "Epoch 25/1500\n",
      "529/529 [==============================] - 0s 319us/step - loss: 0.6806 - accuracy: 0.5520 - val_loss: 0.6948 - val_accuracy: 0.4576\n",
      "Epoch 26/1500\n",
      "529/529 [==============================] - 0s 308us/step - loss: 0.6776 - accuracy: 0.5558 - val_loss: 0.6916 - val_accuracy: 0.6102\n",
      "Epoch 27/1500\n",
      "529/529 [==============================] - 0s 320us/step - loss: 0.6799 - accuracy: 0.5577 - val_loss: 0.6894 - val_accuracy: 0.5763\n",
      "Epoch 28/1500\n",
      "529/529 [==============================] - 0s 322us/step - loss: 0.6832 - accuracy: 0.5614 - val_loss: 0.6900 - val_accuracy: 0.5424\n",
      "Epoch 29/1500\n",
      "529/529 [==============================] - 0s 329us/step - loss: 0.6878 - accuracy: 0.5009 - val_loss: 0.7016 - val_accuracy: 0.4407\n",
      "Epoch 30/1500\n",
      "529/529 [==============================] - 0s 305us/step - loss: 0.6654 - accuracy: 0.5879 - val_loss: 0.6922 - val_accuracy: 0.6102\n",
      "Epoch 31/1500\n",
      "529/529 [==============================] - 0s 298us/step - loss: 0.6630 - accuracy: 0.5747 - val_loss: 0.6910 - val_accuracy: 0.5254\n",
      "Epoch 32/1500\n",
      "529/529 [==============================] - 0s 301us/step - loss: 0.6715 - accuracy: 0.5728 - val_loss: 0.6930 - val_accuracy: 0.5593\n",
      "Epoch 33/1500\n",
      "529/529 [==============================] - 0s 322us/step - loss: 0.6648 - accuracy: 0.5822 - val_loss: 0.6933 - val_accuracy: 0.5593\n",
      "Epoch 34/1500\n",
      "529/529 [==============================] - 0s 331us/step - loss: 0.6568 - accuracy: 0.5879 - val_loss: 0.6996 - val_accuracy: 0.5424\n",
      "Epoch 35/1500\n",
      "529/529 [==============================] - 0s 299us/step - loss: 0.6536 - accuracy: 0.5747 - val_loss: 0.6959 - val_accuracy: 0.5424\n",
      "Epoch 36/1500\n",
      "529/529 [==============================] - 0s 321us/step - loss: 0.6497 - accuracy: 0.5917 - val_loss: 0.6979 - val_accuracy: 0.5254\n",
      "Epoch 37/1500\n",
      "529/529 [==============================] - 0s 319us/step - loss: 0.6483 - accuracy: 0.5992 - val_loss: 0.7012 - val_accuracy: 0.5932\n",
      "Epoch 38/1500\n",
      "529/529 [==============================] - 0s 308us/step - loss: 0.6484 - accuracy: 0.5766 - val_loss: 0.6998 - val_accuracy: 0.5254\n",
      "Epoch 39/1500\n",
      "529/529 [==============================] - 0s 338us/step - loss: 0.6486 - accuracy: 0.5917 - val_loss: 0.7011 - val_accuracy: 0.6271\n",
      "Epoch 40/1500\n",
      "529/529 [==============================] - 0s 316us/step - loss: 0.6430 - accuracy: 0.6049 - val_loss: 0.7075 - val_accuracy: 0.5932\n",
      "Epoch 41/1500\n",
      "529/529 [==============================] - 0s 334us/step - loss: 0.6382 - accuracy: 0.5955 - val_loss: 0.7142 - val_accuracy: 0.6102\n",
      "Epoch 42/1500\n",
      "529/529 [==============================] - 0s 309us/step - loss: 0.6338 - accuracy: 0.6087 - val_loss: 0.7159 - val_accuracy: 0.5424\n",
      "Epoch 43/1500\n",
      "529/529 [==============================] - 0s 286us/step - loss: 0.6355 - accuracy: 0.6144 - val_loss: 0.7227 - val_accuracy: 0.5254\n",
      "Epoch 44/1500\n",
      "529/529 [==============================] - 0s 292us/step - loss: 0.6347 - accuracy: 0.6011 - val_loss: 0.7204 - val_accuracy: 0.5254\n",
      "Epoch 45/1500\n",
      "529/529 [==============================] - 0s 271us/step - loss: 0.6277 - accuracy: 0.6106 - val_loss: 0.7461 - val_accuracy: 0.4576\n",
      "Epoch 46/1500\n",
      "529/529 [==============================] - 0s 307us/step - loss: 0.6301 - accuracy: 0.6144 - val_loss: 0.7362 - val_accuracy: 0.4915\n",
      "Epoch 47/1500\n",
      "529/529 [==============================] - 0s 310us/step - loss: 0.6257 - accuracy: 0.6144 - val_loss: 0.7654 - val_accuracy: 0.4576\n",
      "Epoch 48/1500\n",
      "529/529 [==============================] - 0s 324us/step - loss: 0.6304 - accuracy: 0.6200 - val_loss: 0.7578 - val_accuracy: 0.4746\n",
      "Epoch 49/1500\n",
      "529/529 [==============================] - 0s 341us/step - loss: 0.6219 - accuracy: 0.6181 - val_loss: 0.7617 - val_accuracy: 0.4407\n",
      "Epoch 50/1500\n",
      "529/529 [==============================] - 0s 359us/step - loss: 0.6173 - accuracy: 0.6295 - val_loss: 0.7535 - val_accuracy: 0.4915\n",
      "Epoch 51/1500\n",
      "529/529 [==============================] - 0s 296us/step - loss: 0.6131 - accuracy: 0.6408 - val_loss: 0.7541 - val_accuracy: 0.5254\n",
      "Epoch 52/1500\n",
      "529/529 [==============================] - 0s 337us/step - loss: 0.6084 - accuracy: 0.6446 - val_loss: 0.7538 - val_accuracy: 0.4407\n",
      "Epoch 53/1500\n",
      "529/529 [==============================] - 0s 331us/step - loss: 0.6052 - accuracy: 0.6465 - val_loss: 0.7573 - val_accuracy: 0.5254\n",
      "Epoch 54/1500\n",
      "529/529 [==============================] - 0s 326us/step - loss: 0.6039 - accuracy: 0.6465 - val_loss: 0.7590 - val_accuracy: 0.4068\n",
      "Epoch 55/1500\n",
      "529/529 [==============================] - 0s 325us/step - loss: 0.5981 - accuracy: 0.6673 - val_loss: 0.7729 - val_accuracy: 0.5085\n",
      "Epoch 56/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/529 [==============================] - 0s 274us/step - loss: 0.5949 - accuracy: 0.6560 - val_loss: 0.7948 - val_accuracy: 0.4746\n",
      "Epoch 57/1500\n",
      "529/529 [==============================] - 0s 317us/step - loss: 0.5952 - accuracy: 0.6692 - val_loss: 0.7696 - val_accuracy: 0.4915\n",
      "Epoch 58/1500\n",
      "529/529 [==============================] - 0s 297us/step - loss: 0.5884 - accuracy: 0.6730 - val_loss: 0.7878 - val_accuracy: 0.4915\n",
      "Epoch 59/1500\n",
      "529/529 [==============================] - 0s 261us/step - loss: 0.5884 - accuracy: 0.6786 - val_loss: 0.7966 - val_accuracy: 0.5254\n",
      "Epoch 60/1500\n",
      "529/529 [==============================] - 0s 261us/step - loss: 0.5854 - accuracy: 0.6711 - val_loss: 0.7920 - val_accuracy: 0.5254\n",
      "Epoch 61/1500\n",
      "529/529 [==============================] - 0s 259us/step - loss: 0.5813 - accuracy: 0.6843 - val_loss: 0.8049 - val_accuracy: 0.4746\n",
      "Epoch 62/1500\n",
      "529/529 [==============================] - 0s 255us/step - loss: 0.5810 - accuracy: 0.6843 - val_loss: 0.8045 - val_accuracy: 0.4746\n",
      "Epoch 63/1500\n",
      "529/529 [==============================] - 0s 263us/step - loss: 0.5820 - accuracy: 0.6730 - val_loss: 0.7848 - val_accuracy: 0.5424\n",
      "Epoch 64/1500\n",
      "529/529 [==============================] - 0s 253us/step - loss: 0.5782 - accuracy: 0.6805 - val_loss: 0.8013 - val_accuracy: 0.4746\n",
      "Epoch 65/1500\n",
      "529/529 [==============================] - 0s 258us/step - loss: 0.5793 - accuracy: 0.6862 - val_loss: 0.8132 - val_accuracy: 0.4746\n",
      "Epoch 66/1500\n",
      "529/529 [==============================] - 0s 260us/step - loss: 0.5728 - accuracy: 0.7013 - val_loss: 0.8567 - val_accuracy: 0.4746\n",
      "Epoch 67/1500\n",
      "529/529 [==============================] - 0s 253us/step - loss: 0.5748 - accuracy: 0.7127 - val_loss: 0.7924 - val_accuracy: 0.5085\n",
      "Epoch 68/1500\n",
      "529/529 [==============================] - 0s 262us/step - loss: 0.5648 - accuracy: 0.6994 - val_loss: 0.8500 - val_accuracy: 0.4576\n",
      "Epoch 69/1500\n",
      "529/529 [==============================] - 0s 256us/step - loss: 0.5619 - accuracy: 0.7146 - val_loss: 0.8905 - val_accuracy: 0.4746\n",
      "Epoch 70/1500\n",
      "529/529 [==============================] - 0s 272us/step - loss: 0.5656 - accuracy: 0.7051 - val_loss: 0.8451 - val_accuracy: 0.4746\n",
      "Epoch 71/1500\n",
      "529/529 [==============================] - 0s 274us/step - loss: 0.5573 - accuracy: 0.7146 - val_loss: 0.8183 - val_accuracy: 0.4915\n",
      "Epoch 72/1500\n",
      "529/529 [==============================] - 0s 258us/step - loss: 0.5561 - accuracy: 0.7051 - val_loss: 0.8443 - val_accuracy: 0.4576\n",
      "Epoch 73/1500\n",
      "529/529 [==============================] - 0s 261us/step - loss: 0.5576 - accuracy: 0.7089 - val_loss: 0.9078 - val_accuracy: 0.4237\n",
      "Epoch 74/1500\n",
      "529/529 [==============================] - 0s 264us/step - loss: 0.5642 - accuracy: 0.6994 - val_loss: 0.7742 - val_accuracy: 0.5085\n",
      "Epoch 75/1500\n",
      "529/529 [==============================] - 0s 266us/step - loss: 0.5552 - accuracy: 0.7070 - val_loss: 0.8808 - val_accuracy: 0.4237\n",
      "Epoch 76/1500\n",
      "529/529 [==============================] - 0s 267us/step - loss: 0.5542 - accuracy: 0.6957 - val_loss: 0.7975 - val_accuracy: 0.4237\n",
      "Epoch 77/1500\n",
      "529/529 [==============================] - 0s 269us/step - loss: 0.5636 - accuracy: 0.6957 - val_loss: 0.8459 - val_accuracy: 0.4407\n",
      "Epoch 78/1500\n",
      "529/529 [==============================] - 0s 271us/step - loss: 0.5648 - accuracy: 0.7070 - val_loss: 0.7828 - val_accuracy: 0.5593\n",
      "Epoch 79/1500\n",
      "529/529 [==============================] - 0s 260us/step - loss: 0.5723 - accuracy: 0.6862 - val_loss: 0.8483 - val_accuracy: 0.5085\n",
      "Epoch 80/1500\n",
      "529/529 [==============================] - 0s 269us/step - loss: 0.5602 - accuracy: 0.7278 - val_loss: 0.8294 - val_accuracy: 0.4407\n",
      "Epoch 81/1500\n",
      "529/529 [==============================] - 0s 271us/step - loss: 0.5655 - accuracy: 0.6843 - val_loss: 0.8343 - val_accuracy: 0.5254\n",
      "Epoch 82/1500\n",
      "529/529 [==============================] - 0s 254us/step - loss: 0.5814 - accuracy: 0.6560 - val_loss: 0.7680 - val_accuracy: 0.5254\n",
      "Epoch 83/1500\n",
      "529/529 [==============================] - 0s 274us/step - loss: 0.6063 - accuracy: 0.6125 - val_loss: 0.8085 - val_accuracy: 0.5593\n",
      "Epoch 84/1500\n",
      "529/529 [==============================] - 0s 259us/step - loss: 0.5758 - accuracy: 0.6919 - val_loss: 0.8026 - val_accuracy: 0.5254\n",
      "Epoch 85/1500\n",
      "529/529 [==============================] - 0s 259us/step - loss: 0.5556 - accuracy: 0.7146 - val_loss: 0.8477 - val_accuracy: 0.5932\n",
      "Epoch 86/1500\n",
      "529/529 [==============================] - 0s 267us/step - loss: 0.5492 - accuracy: 0.6994 - val_loss: 0.8263 - val_accuracy: 0.5593\n",
      "Epoch 87/1500\n",
      "529/529 [==============================] - 0s 275us/step - loss: 0.5427 - accuracy: 0.7221 - val_loss: 0.8409 - val_accuracy: 0.5763\n",
      "Epoch 88/1500\n",
      "529/529 [==============================] - 0s 267us/step - loss: 0.5549 - accuracy: 0.6900 - val_loss: 0.8586 - val_accuracy: 0.4915\n",
      "Epoch 89/1500\n",
      "529/529 [==============================] - 0s 263us/step - loss: 0.5535 - accuracy: 0.6938 - val_loss: 0.7882 - val_accuracy: 0.5763\n",
      "Epoch 90/1500\n",
      "529/529 [==============================] - 0s 260us/step - loss: 0.5515 - accuracy: 0.7032 - val_loss: 0.8721 - val_accuracy: 0.5424\n",
      "Epoch 91/1500\n",
      "529/529 [==============================] - 0s 267us/step - loss: 0.5363 - accuracy: 0.7221 - val_loss: 0.8311 - val_accuracy: 0.5593\n",
      "Epoch 92/1500\n",
      "529/529 [==============================] - 0s 264us/step - loss: 0.5403 - accuracy: 0.7278 - val_loss: 0.8586 - val_accuracy: 0.4915\n",
      "Epoch 93/1500\n",
      "529/529 [==============================] - 0s 256us/step - loss: 0.5423 - accuracy: 0.7146 - val_loss: 0.8599 - val_accuracy: 0.5593\n",
      "Epoch 94/1500\n",
      "529/529 [==============================] - 0s 270us/step - loss: 0.5432 - accuracy: 0.6881 - val_loss: 0.8992 - val_accuracy: 0.5763\n",
      "Epoch 95/1500\n",
      "529/529 [==============================] - 0s 267us/step - loss: 0.5432 - accuracy: 0.7051 - val_loss: 0.8317 - val_accuracy: 0.4237\n",
      "Epoch 96/1500\n",
      "529/529 [==============================] - 0s 263us/step - loss: 0.5262 - accuracy: 0.7221 - val_loss: 0.9053 - val_accuracy: 0.4915\n",
      "Epoch 97/1500\n",
      "529/529 [==============================] - 0s 265us/step - loss: 0.5551 - accuracy: 0.6881 - val_loss: 0.8626 - val_accuracy: 0.5254\n",
      "Epoch 98/1500\n",
      "529/529 [==============================] - 0s 259us/step - loss: 0.5418 - accuracy: 0.6881 - val_loss: 0.8739 - val_accuracy: 0.4746\n",
      "Epoch 99/1500\n",
      "529/529 [==============================] - 0s 278us/step - loss: 0.5606 - accuracy: 0.6730 - val_loss: 0.8512 - val_accuracy: 0.5763\n",
      "Epoch 100/1500\n",
      "529/529 [==============================] - 0s 255us/step - loss: 0.5451 - accuracy: 0.7127 - val_loss: 0.8920 - val_accuracy: 0.5424\n",
      "Epoch 101/1500\n",
      "529/529 [==============================] - 0s 273us/step - loss: 0.5480 - accuracy: 0.6749 - val_loss: 0.9063 - val_accuracy: 0.5593\n",
      "Epoch 102/1500\n",
      "529/529 [==============================] - 0s 264us/step - loss: 0.5258 - accuracy: 0.7164 - val_loss: 0.8845 - val_accuracy: 0.5932\n",
      "Epoch 103/1500\n",
      "529/529 [==============================] - 0s 278us/step - loss: 0.5227 - accuracy: 0.7221 - val_loss: 0.9507 - val_accuracy: 0.5424\n",
      "Epoch 104/1500\n",
      "529/529 [==============================] - 0s 274us/step - loss: 0.5154 - accuracy: 0.7391 - val_loss: 0.8717 - val_accuracy: 0.5932\n",
      "Epoch 105/1500\n",
      "529/529 [==============================] - 0s 267us/step - loss: 0.5225 - accuracy: 0.7297 - val_loss: 0.8844 - val_accuracy: 0.5424\n",
      "Epoch 106/1500\n",
      "529/529 [==============================] - 0s 253us/step - loss: 0.5113 - accuracy: 0.7335 - val_loss: 1.0592 - val_accuracy: 0.4915\n",
      "Epoch 107/1500\n",
      "529/529 [==============================] - 0s 270us/step - loss: 0.5640 - accuracy: 0.6919 - val_loss: 0.7863 - val_accuracy: 0.5932\n",
      "Epoch 108/1500\n",
      "529/529 [==============================] - 0s 275us/step - loss: 0.5681 - accuracy: 0.6786 - val_loss: 0.9973 - val_accuracy: 0.4407\n",
      "Epoch 109/1500\n",
      "529/529 [==============================] - 0s 264us/step - loss: 0.5446 - accuracy: 0.7108 - val_loss: 0.8555 - val_accuracy: 0.5254\n",
      "Epoch 110/1500\n",
      "529/529 [==============================] - 0s 272us/step - loss: 0.5302 - accuracy: 0.7164 - val_loss: 0.9010 - val_accuracy: 0.5424\n",
      "Epoch 111/1500\n",
      "529/529 [==============================] - 0s 270us/step - loss: 0.5187 - accuracy: 0.7316 - val_loss: 0.9150 - val_accuracy: 0.5085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1500\n",
      "529/529 [==============================] - 0s 261us/step - loss: 0.5037 - accuracy: 0.7561 - val_loss: 0.9368 - val_accuracy: 0.5254\n",
      "Epoch 113/1500\n",
      "529/529 [==============================] - 0s 250us/step - loss: 0.5046 - accuracy: 0.7391 - val_loss: 0.9771 - val_accuracy: 0.5254\n",
      "Epoch 114/1500\n",
      "529/529 [==============================] - 0s 251us/step - loss: 0.4995 - accuracy: 0.7561 - val_loss: 0.9075 - val_accuracy: 0.4915\n",
      "Epoch 115/1500\n",
      "529/529 [==============================] - 0s 249us/step - loss: 0.5096 - accuracy: 0.7297 - val_loss: 0.9366 - val_accuracy: 0.5254\n",
      "Epoch 116/1500\n",
      "529/529 [==============================] - 0s 258us/step - loss: 0.5064 - accuracy: 0.7391 - val_loss: 0.9781 - val_accuracy: 0.5424\n",
      "Epoch 117/1500\n",
      "529/529 [==============================] - 0s 252us/step - loss: 0.4997 - accuracy: 0.7561 - val_loss: 0.9164 - val_accuracy: 0.5085\n",
      "Epoch 118/1500\n",
      "529/529 [==============================] - 0s 252us/step - loss: 0.4957 - accuracy: 0.7467 - val_loss: 0.9135 - val_accuracy: 0.5085\n",
      "Epoch 119/1500\n",
      "529/529 [==============================] - 0s 250us/step - loss: 0.4961 - accuracy: 0.7599 - val_loss: 0.9926 - val_accuracy: 0.5254\n",
      "Epoch 120/1500\n",
      "529/529 [==============================] - 0s 244us/step - loss: 0.4908 - accuracy: 0.7467 - val_loss: 0.9249 - val_accuracy: 0.5254\n",
      "Epoch 121/1500\n",
      "529/529 [==============================] - 0s 257us/step - loss: 0.4928 - accuracy: 0.7467 - val_loss: 0.9942 - val_accuracy: 0.5593\n",
      "Epoch 122/1500\n",
      "529/529 [==============================] - 0s 260us/step - loss: 0.4848 - accuracy: 0.7486 - val_loss: 0.9882 - val_accuracy: 0.5593\n",
      "Epoch 123/1500\n",
      "529/529 [==============================] - 0s 250us/step - loss: 0.5012 - accuracy: 0.7353 - val_loss: 0.9927 - val_accuracy: 0.5763\n",
      "Epoch 124/1500\n",
      "529/529 [==============================] - 0s 248us/step - loss: 0.4956 - accuracy: 0.7410 - val_loss: 0.9697 - val_accuracy: 0.5085\n",
      "Epoch 125/1500\n",
      "529/529 [==============================] - 0s 251us/step - loss: 0.4929 - accuracy: 0.7391 - val_loss: 0.9972 - val_accuracy: 0.5593\n",
      "Epoch 126/1500\n",
      "529/529 [==============================] - 0s 253us/step - loss: 0.5033 - accuracy: 0.7278 - val_loss: 1.0451 - val_accuracy: 0.5254\n",
      "Epoch 127/1500\n",
      "529/529 [==============================] - 0s 249us/step - loss: 0.4874 - accuracy: 0.7410 - val_loss: 0.9680 - val_accuracy: 0.5593\n",
      "Epoch 128/1500\n",
      "529/529 [==============================] - 0s 252us/step - loss: 0.5053 - accuracy: 0.7259 - val_loss: 0.9952 - val_accuracy: 0.5254\n",
      "Epoch 129/1500\n",
      "529/529 [==============================] - 0s 260us/step - loss: 0.5152 - accuracy: 0.7089 - val_loss: 0.9496 - val_accuracy: 0.5593\n",
      "Epoch 130/1500\n",
      "529/529 [==============================] - 0s 284us/step - loss: 0.5116 - accuracy: 0.7278 - val_loss: 1.0163 - val_accuracy: 0.5593\n",
      "Epoch 131/1500\n",
      "529/529 [==============================] - 0s 261us/step - loss: 0.5074 - accuracy: 0.7108 - val_loss: 1.0133 - val_accuracy: 0.5424\n",
      "Epoch 132/1500\n",
      "529/529 [==============================] - 0s 249us/step - loss: 0.5214 - accuracy: 0.7183 - val_loss: 0.8993 - val_accuracy: 0.5424\n",
      "Epoch 133/1500\n",
      "529/529 [==============================] - 0s 266us/step - loss: 0.5547 - accuracy: 0.6824 - val_loss: 0.9782 - val_accuracy: 0.5085\n",
      "Epoch 134/1500\n",
      "529/529 [==============================] - 0s 278us/step - loss: 0.5282 - accuracy: 0.6957 - val_loss: 0.9719 - val_accuracy: 0.5085\n",
      "Epoch 135/1500\n",
      "529/529 [==============================] - 0s 262us/step - loss: 0.5162 - accuracy: 0.7221 - val_loss: 0.9127 - val_accuracy: 0.5763\n",
      "Epoch 136/1500\n",
      "529/529 [==============================] - 0s 258us/step - loss: 0.5162 - accuracy: 0.7164 - val_loss: 1.0603 - val_accuracy: 0.5254\n",
      "Epoch 137/1500\n",
      "529/529 [==============================] - 0s 282us/step - loss: 0.5143 - accuracy: 0.7372 - val_loss: 0.9039 - val_accuracy: 0.5424\n",
      "Epoch 138/1500\n",
      "529/529 [==============================] - 0s 298us/step - loss: 0.5120 - accuracy: 0.7278 - val_loss: 1.0194 - val_accuracy: 0.5254\n",
      "Epoch 139/1500\n",
      "529/529 [==============================] - 0s 317us/step - loss: 0.4931 - accuracy: 0.7278 - val_loss: 0.9978 - val_accuracy: 0.4915\n",
      "Epoch 140/1500\n",
      "529/529 [==============================] - 0s 288us/step - loss: 0.4892 - accuracy: 0.7467 - val_loss: 1.0014 - val_accuracy: 0.5254\n",
      "Epoch 141/1500\n",
      "529/529 [==============================] - 0s 273us/step - loss: 0.4724 - accuracy: 0.7505 - val_loss: 1.1109 - val_accuracy: 0.4407\n",
      "Epoch 142/1500\n",
      "529/529 [==============================] - 0s 318us/step - loss: 0.4707 - accuracy: 0.7467 - val_loss: 0.9198 - val_accuracy: 0.5424\n",
      "Epoch 143/1500\n",
      "529/529 [==============================] - 0s 296us/step - loss: 0.4781 - accuracy: 0.7561 - val_loss: 1.0710 - val_accuracy: 0.4746\n",
      "Epoch 144/1500\n",
      "529/529 [==============================] - 0s 341us/step - loss: 0.4664 - accuracy: 0.7543 - val_loss: 1.0974 - val_accuracy: 0.4407\n",
      "Epoch 145/1500\n",
      "529/529 [==============================] - 0s 296us/step - loss: 0.4588 - accuracy: 0.7580 - val_loss: 1.0802 - val_accuracy: 0.4746\n",
      "Epoch 146/1500\n",
      "529/529 [==============================] - 0s 324us/step - loss: 0.4681 - accuracy: 0.7599 - val_loss: 1.0244 - val_accuracy: 0.4576\n",
      "Epoch 147/1500\n",
      "529/529 [==============================] - 0s 295us/step - loss: 0.4659 - accuracy: 0.7524 - val_loss: 0.9375 - val_accuracy: 0.5254\n",
      "Epoch 148/1500\n",
      "529/529 [==============================] - 0s 320us/step - loss: 0.4738 - accuracy: 0.7543 - val_loss: 1.2013 - val_accuracy: 0.4915\n",
      "Epoch 149/1500\n",
      "529/529 [==============================] - 0s 319us/step - loss: 0.4782 - accuracy: 0.7410 - val_loss: 0.9505 - val_accuracy: 0.5085\n",
      "Epoch 150/1500\n",
      "529/529 [==============================] - 0s 325us/step - loss: 0.4759 - accuracy: 0.7561 - val_loss: 1.0416 - val_accuracy: 0.4915\n",
      "Epoch 151/1500\n",
      "529/529 [==============================] - 0s 329us/step - loss: 0.4719 - accuracy: 0.7467 - val_loss: 1.0544 - val_accuracy: 0.4915\n",
      "Epoch 152/1500\n",
      "529/529 [==============================] - 0s 322us/step - loss: 0.4635 - accuracy: 0.7524 - val_loss: 1.0359 - val_accuracy: 0.5254\n",
      "Epoch 153/1500\n",
      "529/529 [==============================] - 0s 311us/step - loss: 0.4981 - accuracy: 0.7410 - val_loss: 1.0279 - val_accuracy: 0.5254\n",
      "Epoch 154/1500\n",
      "529/529 [==============================] - 0s 344us/step - loss: 0.4713 - accuracy: 0.7637 - val_loss: 1.1938 - val_accuracy: 0.4576\n",
      "Epoch 155/1500\n",
      "529/529 [==============================] - 0s 356us/step - loss: 0.4715 - accuracy: 0.7429 - val_loss: 0.9731 - val_accuracy: 0.5085\n",
      "Epoch 156/1500\n",
      "529/529 [==============================] - 0s 354us/step - loss: 0.4724 - accuracy: 0.7391 - val_loss: 1.1190 - val_accuracy: 0.4576\n",
      "Epoch 157/1500\n",
      "529/529 [==============================] - 0s 393us/step - loss: 0.4862 - accuracy: 0.7391 - val_loss: 1.0141 - val_accuracy: 0.4915\n",
      "Epoch 158/1500\n",
      "529/529 [==============================] - 0s 340us/step - loss: 0.5062 - accuracy: 0.7486 - val_loss: 1.0440 - val_accuracy: 0.4576\n",
      "Epoch 159/1500\n",
      "529/529 [==============================] - 0s 389us/step - loss: 0.4918 - accuracy: 0.7372 - val_loss: 0.9245 - val_accuracy: 0.4915\n",
      "Epoch 160/1500\n",
      "529/529 [==============================] - 0s 352us/step - loss: 0.5050 - accuracy: 0.7089 - val_loss: 0.9675 - val_accuracy: 0.5593\n",
      "Epoch 161/1500\n",
      "529/529 [==============================] - 0s 380us/step - loss: 0.4871 - accuracy: 0.7372 - val_loss: 1.0749 - val_accuracy: 0.4746\n",
      "Epoch 162/1500\n",
      "529/529 [==============================] - 0s 380us/step - loss: 0.4851 - accuracy: 0.7278 - val_loss: 0.8781 - val_accuracy: 0.5254\n",
      "Epoch 163/1500\n",
      "529/529 [==============================] - 0s 333us/step - loss: 0.5099 - accuracy: 0.7202 - val_loss: 1.0334 - val_accuracy: 0.5254\n",
      "Epoch 164/1500\n",
      "529/529 [==============================] - 0s 293us/step - loss: 0.4766 - accuracy: 0.7410 - val_loss: 0.9755 - val_accuracy: 0.5593\n",
      "Epoch 165/1500\n",
      "529/529 [==============================] - 0s 302us/step - loss: 0.4666 - accuracy: 0.7713 - val_loss: 0.9996 - val_accuracy: 0.5254\n",
      "Epoch 166/1500\n",
      "529/529 [==============================] - 0s 295us/step - loss: 0.4567 - accuracy: 0.7637 - val_loss: 1.0218 - val_accuracy: 0.5085\n",
      "Epoch 167/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/529 [==============================] - 0s 299us/step - loss: 0.4375 - accuracy: 0.7713 - val_loss: 1.1217 - val_accuracy: 0.5085\n",
      "Epoch 168/1500\n",
      "529/529 [==============================] - 0s 263us/step - loss: 0.4411 - accuracy: 0.7561 - val_loss: 1.1113 - val_accuracy: 0.4746\n",
      "Epoch 169/1500\n",
      "529/529 [==============================] - 0s 285us/step - loss: 0.4377 - accuracy: 0.7713 - val_loss: 1.1139 - val_accuracy: 0.4915\n",
      "Epoch 170/1500\n",
      "529/529 [==============================] - 0s 321us/step - loss: 0.4558 - accuracy: 0.7524 - val_loss: 0.9837 - val_accuracy: 0.5085\n",
      "Epoch 171/1500\n",
      "529/529 [==============================] - 0s 293us/step - loss: 0.4603 - accuracy: 0.7543 - val_loss: 1.0418 - val_accuracy: 0.5593\n",
      "Epoch 172/1500\n",
      "529/529 [==============================] - 0s 305us/step - loss: 0.4765 - accuracy: 0.7410 - val_loss: 1.0284 - val_accuracy: 0.4915\n",
      "Epoch 173/1500\n",
      "529/529 [==============================] - 0s 306us/step - loss: 0.4816 - accuracy: 0.7391 - val_loss: 1.0149 - val_accuracy: 0.4915\n",
      "Epoch 174/1500\n",
      "529/529 [==============================] - 0s 296us/step - loss: 0.4535 - accuracy: 0.7618 - val_loss: 1.0435 - val_accuracy: 0.5085\n",
      "Epoch 175/1500\n",
      "529/529 [==============================] - 0s 317us/step - loss: 0.4637 - accuracy: 0.7599 - val_loss: 1.0826 - val_accuracy: 0.5424\n",
      "Epoch 176/1500\n",
      "529/529 [==============================] - 0s 292us/step - loss: 0.4932 - accuracy: 0.7183 - val_loss: 1.1738 - val_accuracy: 0.5932\n",
      "Epoch 177/1500\n",
      "529/529 [==============================] - 0s 281us/step - loss: 0.4995 - accuracy: 0.7297 - val_loss: 0.9031 - val_accuracy: 0.5085\n",
      "Epoch 178/1500\n",
      "529/529 [==============================] - 0s 292us/step - loss: 0.4595 - accuracy: 0.7599 - val_loss: 0.9742 - val_accuracy: 0.5254\n",
      "Epoch 179/1500\n",
      "529/529 [==============================] - 0s 298us/step - loss: 0.4490 - accuracy: 0.7656 - val_loss: 1.0657 - val_accuracy: 0.5424\n",
      "Epoch 180/1500\n",
      "529/529 [==============================] - 0s 318us/step - loss: 0.4434 - accuracy: 0.7656 - val_loss: 0.9728 - val_accuracy: 0.5424\n",
      "Epoch 181/1500\n",
      "529/529 [==============================] - 0s 325us/step - loss: 0.4389 - accuracy: 0.7599 - val_loss: 1.1011 - val_accuracy: 0.4746\n",
      "Epoch 182/1500\n",
      "529/529 [==============================] - 0s 336us/step - loss: 0.4430 - accuracy: 0.7561 - val_loss: 0.9731 - val_accuracy: 0.5254\n",
      "Epoch 183/1500\n",
      "529/529 [==============================] - 0s 312us/step - loss: 0.4384 - accuracy: 0.7675 - val_loss: 1.3463 - val_accuracy: 0.4576\n",
      "Epoch 184/1500\n",
      "529/529 [==============================] - 0s 325us/step - loss: 0.4592 - accuracy: 0.7524 - val_loss: 0.9062 - val_accuracy: 0.5085\n",
      "Epoch 185/1500\n",
      "529/529 [==============================] - 0s 313us/step - loss: 0.4501 - accuracy: 0.7826 - val_loss: 1.1579 - val_accuracy: 0.4915\n",
      "Epoch 186/1500\n",
      "529/529 [==============================] - 0s 327us/step - loss: 0.5046 - accuracy: 0.7202 - val_loss: 0.9954 - val_accuracy: 0.4915\n",
      "Epoch 187/1500\n",
      "529/529 [==============================] - 0s 328us/step - loss: 0.4942 - accuracy: 0.7448 - val_loss: 1.2141 - val_accuracy: 0.5085\n",
      "Epoch 188/1500\n",
      "529/529 [==============================] - 0s 314us/step - loss: 0.4895 - accuracy: 0.7353 - val_loss: 1.0288 - val_accuracy: 0.5424\n",
      "Epoch 189/1500\n",
      "529/529 [==============================] - 0s 351us/step - loss: 0.4828 - accuracy: 0.7580 - val_loss: 1.0411 - val_accuracy: 0.4915\n",
      "Epoch 190/1500\n",
      "529/529 [==============================] - 0s 309us/step - loss: 0.4579 - accuracy: 0.7410 - val_loss: 1.1480 - val_accuracy: 0.5424\n",
      "Epoch 191/1500\n",
      "529/529 [==============================] - 0s 340us/step - loss: 0.4721 - accuracy: 0.7353 - val_loss: 1.0549 - val_accuracy: 0.5085\n",
      "Epoch 192/1500\n",
      "529/529 [==============================] - 0s 340us/step - loss: 0.4550 - accuracy: 0.7769 - val_loss: 1.1134 - val_accuracy: 0.5085\n",
      "Epoch 193/1500\n",
      "529/529 [==============================] - 0s 357us/step - loss: 0.4322 - accuracy: 0.7675 - val_loss: 1.0747 - val_accuracy: 0.4576\n",
      "Epoch 194/1500\n",
      "529/529 [==============================] - 0s 326us/step - loss: 0.4309 - accuracy: 0.7750 - val_loss: 1.1008 - val_accuracy: 0.4746\n",
      "Epoch 195/1500\n",
      "529/529 [==============================] - 0s 335us/step - loss: 0.4217 - accuracy: 0.7732 - val_loss: 1.1404 - val_accuracy: 0.4576\n",
      "Epoch 196/1500\n",
      "529/529 [==============================] - 0s 336us/step - loss: 0.4131 - accuracy: 0.7694 - val_loss: 1.1130 - val_accuracy: 0.5254\n",
      "Epoch 197/1500\n",
      "529/529 [==============================] - 0s 302us/step - loss: 0.4054 - accuracy: 0.7750 - val_loss: 1.2038 - val_accuracy: 0.4746\n",
      "Epoch 198/1500\n",
      "529/529 [==============================] - 0s 357us/step - loss: 0.4066 - accuracy: 0.7864 - val_loss: 1.1203 - val_accuracy: 0.5254\n",
      "Epoch 199/1500\n",
      "529/529 [==============================] - 0s 334us/step - loss: 0.4057 - accuracy: 0.7883 - val_loss: 1.1819 - val_accuracy: 0.4576\n",
      "Epoch 200/1500\n",
      "529/529 [==============================] - 0s 343us/step - loss: 0.4067 - accuracy: 0.7788 - val_loss: 1.1214 - val_accuracy: 0.4915\n",
      "Epoch 201/1500\n",
      "529/529 [==============================] - 0s 334us/step - loss: 0.4301 - accuracy: 0.7750 - val_loss: 1.3322 - val_accuracy: 0.4068\n",
      "Epoch 202/1500\n",
      "529/529 [==============================] - 0s 326us/step - loss: 0.4368 - accuracy: 0.7656 - val_loss: 1.1100 - val_accuracy: 0.5424\n",
      "Epoch 203/1500\n",
      "529/529 [==============================] - 0s 343us/step - loss: 0.4618 - accuracy: 0.7486 - val_loss: 1.1504 - val_accuracy: 0.5254\n",
      "Epoch 204/1500\n",
      "529/529 [==============================] - 0s 334us/step - loss: 0.4549 - accuracy: 0.7561 - val_loss: 1.1241 - val_accuracy: 0.4915\n",
      "Epoch 205/1500\n",
      "529/529 [==============================] - 0s 332us/step - loss: 0.4526 - accuracy: 0.7656 - val_loss: 1.1244 - val_accuracy: 0.5593\n",
      "Epoch 206/1500\n",
      "529/529 [==============================] - 0s 328us/step - loss: 0.4456 - accuracy: 0.7599 - val_loss: 1.0661 - val_accuracy: 0.5085\n",
      "Epoch 207/1500\n",
      "529/529 [==============================] - 0s 351us/step - loss: 0.4548 - accuracy: 0.7410 - val_loss: 1.0647 - val_accuracy: 0.5593\n",
      "Epoch 208/1500\n",
      "529/529 [==============================] - 0s 327us/step - loss: 0.4639 - accuracy: 0.7467 - val_loss: 1.0448 - val_accuracy: 0.4237\n",
      "Epoch 209/1500\n",
      "529/529 [==============================] - 0s 298us/step - loss: 0.4588 - accuracy: 0.7467 - val_loss: 1.1525 - val_accuracy: 0.5085\n",
      "Epoch 210/1500\n",
      "529/529 [==============================] - 0s 311us/step - loss: 0.4564 - accuracy: 0.7694 - val_loss: 0.9935 - val_accuracy: 0.5593\n",
      "Epoch 211/1500\n",
      "529/529 [==============================] - 0s 332us/step - loss: 0.4247 - accuracy: 0.7845 - val_loss: 1.1308 - val_accuracy: 0.4746\n",
      "Epoch 212/1500\n",
      "529/529 [==============================] - 0s 324us/step - loss: 0.4145 - accuracy: 0.7713 - val_loss: 0.9857 - val_accuracy: 0.5085\n",
      "Epoch 213/1500\n",
      "529/529 [==============================] - 0s 334us/step - loss: 0.4062 - accuracy: 0.7958 - val_loss: 1.0685 - val_accuracy: 0.4915\n",
      "Epoch 214/1500\n",
      "529/529 [==============================] - 0s 314us/step - loss: 0.4095 - accuracy: 0.7826 - val_loss: 1.1457 - val_accuracy: 0.5763\n",
      "Epoch 215/1500\n",
      "529/529 [==============================] - 0s 300us/step - loss: 0.4040 - accuracy: 0.7996 - val_loss: 1.1255 - val_accuracy: 0.4915\n",
      "Epoch 216/1500\n",
      "529/529 [==============================] - 0s 298us/step - loss: 0.4063 - accuracy: 0.8072 - val_loss: 1.0853 - val_accuracy: 0.5763\n",
      "Epoch 217/1500\n",
      "529/529 [==============================] - 0s 296us/step - loss: 0.4147 - accuracy: 0.7845 - val_loss: 1.1171 - val_accuracy: 0.4746\n",
      "Epoch 218/1500\n",
      "529/529 [==============================] - 0s 309us/step - loss: 0.4071 - accuracy: 0.7769 - val_loss: 1.1475 - val_accuracy: 0.5254\n",
      "Epoch 219/1500\n",
      "529/529 [==============================] - 0s 300us/step - loss: 0.4141 - accuracy: 0.7958 - val_loss: 1.1861 - val_accuracy: 0.5763\n",
      "Epoch 220/1500\n",
      "529/529 [==============================] - 0s 302us/step - loss: 0.4105 - accuracy: 0.7883 - val_loss: 1.0341 - val_accuracy: 0.5085\n",
      "Epoch 221/1500\n",
      "529/529 [==============================] - 0s 299us/step - loss: 0.4491 - accuracy: 0.7524 - val_loss: 1.2396 - val_accuracy: 0.5424\n",
      "Epoch 222/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/529 [==============================] - 0s 304us/step - loss: 0.4821 - accuracy: 0.7353 - val_loss: 1.1489 - val_accuracy: 0.5763\n",
      "Epoch 223/1500\n",
      "529/529 [==============================] - 0s 255us/step - loss: 0.5005 - accuracy: 0.7240 - val_loss: 1.0614 - val_accuracy: 0.5254\n",
      "Epoch 224/1500\n",
      "529/529 [==============================] - 0s 250us/step - loss: 0.4612 - accuracy: 0.7505 - val_loss: 1.0974 - val_accuracy: 0.5254\n",
      "Epoch 225/1500\n",
      "529/529 [==============================] - 0s 269us/step - loss: 0.4269 - accuracy: 0.7769 - val_loss: 1.1861 - val_accuracy: 0.4746\n",
      "Epoch 226/1500\n",
      "529/529 [==============================] - 0s 254us/step - loss: 0.4115 - accuracy: 0.7845 - val_loss: 1.0865 - val_accuracy: 0.4576\n",
      "Epoch 227/1500\n",
      "529/529 [==============================] - 0s 254us/step - loss: 0.4196 - accuracy: 0.7826 - val_loss: 1.0522 - val_accuracy: 0.5085\n",
      "Epoch 228/1500\n",
      "529/529 [==============================] - 0s 280us/step - loss: 0.4231 - accuracy: 0.7807 - val_loss: 1.0973 - val_accuracy: 0.5085\n",
      "Epoch 229/1500\n",
      "529/529 [==============================] - 0s 318us/step - loss: 0.3897 - accuracy: 0.8015 - val_loss: 1.1535 - val_accuracy: 0.4915\n",
      "Epoch 230/1500\n",
      "529/529 [==============================] - 0s 291us/step - loss: 0.3855 - accuracy: 0.7921 - val_loss: 1.2182 - val_accuracy: 0.4576\n",
      "Epoch 231/1500\n",
      "529/529 [==============================] - 0s 305us/step - loss: 0.3885 - accuracy: 0.7902 - val_loss: 1.1302 - val_accuracy: 0.4576\n",
      "Epoch 232/1500\n",
      "529/529 [==============================] - 0s 314us/step - loss: 0.3840 - accuracy: 0.8129 - val_loss: 1.1562 - val_accuracy: 0.4746\n",
      "Epoch 233/1500\n",
      "529/529 [==============================] - 0s 304us/step - loss: 0.4111 - accuracy: 0.8015 - val_loss: 1.0442 - val_accuracy: 0.4915\n",
      "Epoch 00233: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f01e5676518>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=1500, batch_size=32, validation_split=0.1,validation_freq=1, shuffle=False,use_multiprocessing=True, callbacks=[mcp_save,earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyAUCY0FGwsM"
   },
   "outputs": [],
   "source": [
    "prediction_model = load_model('trained_models/LSTM_cls_interval3.hdf5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = prediction_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46938775510204084"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=accuracy_score(y_test,y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1=f1_score(y_test,y_pred,average='binary')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4706263899184582"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc=roc_auc_score(y_test,y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob=[prediction_model.predict(X_test).max() for i in range(len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    decrease       0.64      0.18      0.28       246\n",
      "    increase       0.53      0.90      0.66       248\n",
      "\n",
      "    accuracy                           0.54       494\n",
      "   macro avg       0.58      0.54      0.47       494\n",
      "weighted avg       0.58      0.54      0.48       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred,labels=[0,1], target_names=['decrease','increase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=pd.DataFrame(zip(np.ravel(y_test),np.ravel(y_pred)),columns=['y_test','y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0         0       1\n",
       "1         1       1\n",
       "2         1       1\n",
       "3         1       1\n",
       "4         0       1\n",
       "5         1       1\n",
       "6         1       1\n",
       "7         1       1\n",
       "8         1       1\n",
       "9         1       1\n",
       "10        0       1\n",
       "11        0       1\n",
       "12        1       1\n",
       "13        0       1\n",
       "14        0       1\n",
       "15        0       0\n",
       "16        1       0\n",
       "17        0       1\n",
       "18        1       1\n",
       "19        1       1\n",
       "20        1       1\n",
       "21        0       1\n",
       "22        0       1\n",
       "23        0       1\n",
       "24        1       1\n",
       "25        1       1\n",
       "26        1       1\n",
       "27        1       1\n",
       "28        0       1\n",
       "29        0       1\n",
       "..      ...     ...\n",
       "464       1       1\n",
       "465       0       1\n",
       "466       1       0\n",
       "467       1       1\n",
       "468       1       1\n",
       "469       0       1\n",
       "470       0       1\n",
       "471       0       1\n",
       "472       0       1\n",
       "473       0       1\n",
       "474       1       1\n",
       "475       0       1\n",
       "476       0       1\n",
       "477       0       1\n",
       "478       0       1\n",
       "479       0       1\n",
       "480       1       1\n",
       "481       1       1\n",
       "482       0       1\n",
       "483       1       1\n",
       "484       1       0\n",
       "485       0       1\n",
       "486       0       0\n",
       "487       0       1\n",
       "488       0       0\n",
       "489       1       1\n",
       "490       1       1\n",
       "491       0       1\n",
       "492       0       1\n",
       "493       0       1\n",
       "\n",
       "[494 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
